[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"","code":""},{"path":"index.html","id":"course-motivation","chapter":"Overview","heading":"Course motivation","text":"Ecological modeling within USACE primarily spreadsheet-based activity featuring deterministic habitat models. However, ecological modeling capacity USACE biologists can greatly improved incorporating modern data science practices, especially uptake R, programming language used majority ecological research conducted today. R promotes research well-documented, reproducible, interdisciplinary, extensible. R also works kinds data, produces high-quality graphics, broad supportive network users, easier learn ever . training series focus teaching USACE biologists practitioners use R ecological modeling.","code":""},{"path":"index.html","id":"intended-audience","chapter":"Overview","heading":"Intended audience","text":"Modeling experience: considering “modelers” projects, familiarity ecological modeling, wanting expand modeling toolbox. open learning use code.Career trajectory: USACE biologists geospatial analysts; course may also benefit ecological/environmental engineers.Institutional context: USACE team members; partners working closely USACE.Pre-requisites: None! Although familiarity ecological models used USACE may useful. Similarly, experience numerical modeling, coding, data analysis may also help required.","code":""},{"path":"index.html","id":"learning-objectives","chapter":"Overview","heading":"Learning objectives","text":"Become familiar R coding basics, RStudio environment, benefits using R conducting analyses.Learn important building blocks data “wrangling” visualization R.Learn key methods seeking help R coding problems.Increase familiarity existing habitat modeling tools.Develop ability conduct basic non-habitat ecological modeling compare traditional habitat models.","code":""},{"path":"index.html","id":"module-format","chapter":"Overview","heading":"Module format","text":"Asynchronous, self-directed modules accompanied full R scripts carry analyses. format selected :\n* Durable (.e., tutorials persist online)\n* Flexible learners\n* potential impact beyond USACE","code":""},{"path":"index.html","id":"module-structure","chapter":"Overview","heading":"Module structure","text":"Background context (5-10 minutes)Coding mechanics (10-20 minutes)Application code real problem (10-20 minutes)","code":""},{"path":"index.html","id":"additional-resources-to-be-provided-by-instructors","chapter":"Overview","heading":"Additional resources to be provided by instructors","text":"Potential zoom “office hours” assist trainees coding data troubleshootingLinks vetted resources working R, RStudio, ecological models","code":""},{"path":"index.html","id":"course-subject-matter","chapter":"Overview","heading":"Course subject matter","text":"training course include modules introduce users coding R, followed modules focus different ecological modeling topics. Users already proficient R RStudio wish learn ecological modeling may skip directly specific modules relevant goals.Modules basics using R RStudio adapted open-source course entitled “Data Analysis Visualization R Ecologists,”created Carpentries, community instructors trainers teach foundational data science skills researchers. course designed ~6 hour workshop, also adapted multiple standalone videos (e.g., [] (https://www.youtube.com/watch?v=AJKd8Av6uoQ&list=PLwFqvDRX_4sJ0HnNGXlWjd8A7vFi2k0wp&index=8)); divide workshop materials four modules (Table 1). also create introductory video describing get set-training series, including download R R studio.","code":""},{"path":"required-set-up-for-the-course.html","id":"required-set-up-for-the-course","chapter":"Required set-up for the course","heading":"Required set-up for the course","text":"","code":""},{"path":"required-set-up-for-the-course.html","id":"preparations","chapter":"Required set-up for the course","heading":"0.1 Preparations","text":"modules designed learners carry computing follow material. Consequently, learners must R RStudio installed computers. also need able install number R packages, create directories, download files.avoid troubleshooting lesson, learners follow \ninstructions download install everything beforehand.USACE user’s ACE-machines may need assistance departments download R R Studio install packages. Therefore, give ample time get set-R R Studio potential training sessions.","code":""},{"path":"required-set-up-for-the-course.html","id":"install-r-and-rstudio","chapter":"Required set-up for the course","heading":"0.1.1 Install R and RStudio","text":"R RStudio two separate pieces software:R programming language software used run code written R.RStudio integrated development environment (IDE) makes using R easier. course use RStudio interact R.don’t already R RStudio installed, follow instructions operating system .\ninstall R install RStudio.","code":""},{"path":"required-set-up-for-the-course.html","id":"for-windows","chapter":"Required set-up for the course","heading":"0.2 For Windows","text":"Download R CRAN website.Run .exe file just downloadedGo RStudio download pageUnder Installers select RStudio x.yy.zzz - Windows Vista/7/8/10 (x, y, z represent version numbers)Double click file install itOnce ’s installed, open RStudio make sure works don’t get error messages.","code":""},{"path":"required-set-up-for-the-course.html","id":"for-macos","chapter":"Required set-up for the course","heading":"0.3 For MacOS","text":"Download R CRAN website.Select .pkg file latest R versionDouble click downloaded file install RIt also good idea install XQuartz (needed packages)Go RStudio download pageUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (x, y, z represent version numbers)Double click file install RStudioOnce ’s installed, open RStudio make sure works don’t get error messages.","code":""},{"path":"required-set-up-for-the-course.html","id":"for-linux","chapter":"Required set-up for the course","heading":"0.4 For Linux","text":"Download R CRAN website.Select .pkg file latest R versionDouble click downloaded file install RIt also good idea install XQuartz (needed packages)Go RStudio download pageUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (x, y, z represent version numbers)Double click file install RStudioOnce ’s installed, open RStudio make sure works don’t get error messages.","code":""},{"path":"required-set-up-for-the-course.html","id":"update-r-and-rstudio","chapter":"Required set-up for the course","heading":"0.4.1 Update R and RStudio","text":"already R RStudio installed, first check R version date:open RStudio R version printed console bottom left. Alternatively, can type sessionInfo() console. R version 4.0.0 later, don’t need update R lesson. version R older , download install latest version R R project website Windows, MacOS, LinuxIt necessary remove old versions R system, wish can check uninstall R?installing new version R, reinstall packages new version. Windows, package called installr can help upgrading R version migrate package library. similar package called pacman can help updating R packages across\nupdate RStudio latest version, open RStudio click \nHelp > Check Updates. new version available follow \ninstruction screen. default, RStudio also automatically notify \nnew versions every .","code":""},{"path":"required-set-up-for-the-course.html","id":"install-required-r-packages","chapter":"Required set-up for the course","heading":"0.4.2 Install required R packages","text":"training modules use various R packages, useful R code written people supplement code included base R language. Several modules use R packages specific analyses covered modules; instances, users prompted download load required packages. first four lessons covering introduction R, use packages tidyverse, lubridate, ratdat, learners planning complete intro R install packages.try install packages, open RStudio copy paste following command console window (look blinking cursor bottom left), press Enter (Windows Linux) Return (MacOS) execute command.Alternatively, can install packages using RStudio’s graphical user interface going Tools > Install Packages typing names packages separated comma.R tries download install packages machine.installation finished, can try load packages pasting following code console:see error like package called ‘...’ good go!","code":"\ninstall.packages(c(\"tidyverse\", \"lubridate\", \"ratdat\"))\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ratdat)"},{"path":"required-set-up-for-the-course.html","id":"updating-r-packages","chapter":"Required set-up for the course","heading":"0.4.3 Updating R packages","text":"Generally, recommended keep R version packages date, new versions bring improvements important bugfixes. update packages installed, click Update Packages tab bottom right panel RStudio, go Tools > Check Package Updates...update packages required course, even installed relatively recently.","code":""},{"path":"required-set-up-for-the-course.html","id":"download-the-data","chapter":"Required set-up for the course","heading":"0.4.4 Download the data","text":"download data directly R modules. However, expecting problems network, may better download data beforehand store machine.data files lesson can downloaded manually:cleaned data andzip file raw data.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"introduction-to-r-and-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1 Introduction to R and RStudio","text":"","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"learning-objectives-1","chapter":"1 Introduction to R and RStudio","heading":"Learning Objectives:","text":"Understand R can benefit USACE biologistsUnderstand basic workflow using R RStudioUnderstand get help R problems several ways","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"what-are-r-and-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1.1 What are R and RStudio?","text":"R refers programming language well software runs R code.RStudio software interface can make easier write R scripts interact R software. ’s popular platform, RStudio also maintains tidyverse series packages use lesson.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"why-learn-r","chapter":"1 Introduction to R and RStudio","heading":"1.2 Why learn R?","text":"","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"r-does-not-involve-lots-of-pointing-and-clicking-and-thats-a-good-thing","chapter":"1 Introduction to R and RStudio","heading":"1.2.1 R does not involve lots of pointing and clicking, and that’s a good thing","text":"Since R programming language, results analysis rely remembering succession pointing clicking, instead series written commands, ’s good thing! , want redo analysis collected data, don’t remember button clicked order obtain results; just run script .Working scripts makes steps used analysis clear, code write can inspected someone else can give feedback spot mistakes.Working scripts forces deeper understanding , facilitates learning comprehension methods use.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"r-code-is-great-for-reproducibility","chapter":"1 Introduction to R and RStudio","heading":"1.2.2 R code is great for reproducibility","text":"Reproducibility someone else (including future self) can obtain results dataset using analysis.R integrates tools generate manuscripts code. collect data, fix mistake dataset, figures statistical tests manuscript updated automatically.increasing number journals funding agencies expect analyses reproducible, knowing R give edge requirements.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"r-is-interdisciplinary-and-extensible","chapter":"1 Introduction to R and RStudio","heading":"1.2.3 R is interdisciplinary and extensible","text":"tens thousands packages can installed extend capabilities, R provides framework allows combine statistical approaches many scientific disciplines best suit analytical framework need analyze data. instance, R packages image analysis, GIS, time series, population genetics, lot .","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"r-works-on-data-of-all-shapes-and-sizes","chapter":"1 Introduction to R and RStudio","heading":"1.2.4 R works on data of all shapes and sizes","text":"skills learn R scale easily size dataset. Whether dataset hundreds millions lines, won’t make much difference .R designed data analysis. comes special data structures data types make handling missing data statistical factors convenient.R can read data many different file types, including geospatial data, connect local remote databases.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"r-produces-high-quality-graphics","chapter":"1 Introduction to R and RStudio","heading":"1.2.5 R produces high-quality graphics","text":"R well-developed plotting capabilities, ggplot2 package one , powerful pieces plotting software available today. begin learning use ggplot2 next episode.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"r-has-a-large-and-welcoming-community","chapter":"1 Introduction to R and RStudio","heading":"1.2.6 R has a large and welcoming community","text":"Thousands people use R daily. Many willing help mailing lists websites Stack Overflow, RStudio community.Since R popular among researchers, help communities learning materials aimed towards researchers. Python similar language R, can accomplish many tasks, widely used software developers software engineers, Python resources communities oriented towards researchers.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"not-only-is-r-free-but-it-is-also-open-source-and-cross-platform","chapter":"1 Introduction to R and RStudio","heading":"1.2.7 Not only is R free, but it is also open-source and cross-platform","text":"Anyone can inspect source code see R works. transparency, less chance mistakes, (someone else) find , can report fix bugs.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"navigating-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1.3 Navigating RStudio","text":"use RStudio integrated development environment (IDE) write code scripts, run code R, navigate files computer, inspect objects create R, look plots make. RStudio many features can help things like version control, developing R packages, writing Shiny apps, won’t cover workshop.screenshot, can see 4 “panes” default layout:Top-Left: Source pane displays scripts files.\n3 panes, Console pane top left, press Shift+Cmd+N (Mac) Shift+Ctrl+N (Windows) open blank R script, make Source pane appear.\n3 panes, Console pane top left, press Shift+Cmd+N (Mac) Shift+Ctrl+N (Windows) open blank R script, make Source pane appear.Top-Right: Environment/History pane, shows objects current R session (Environment) command history (History)\ntabs , including Connections, Build, Tutorial, possibly Git\nwon’t cover tabs, RStudio lots useful features\ntabs , including Connections, Build, Tutorial, possibly Gitwe won’t cover tabs, RStudio lots useful featuresBottom-Left: Console pane, can interact directly R console, interprets R commands prints results\nalso tabs Terminal Jobs\nalso tabs Terminal JobsBottom-Right: Files/Plots/Help/Viewer pane navigate files view plots help pagesYou can customize layout panes, well many settings RStudio color scheme, font, even keyboard shortcuts. can access settings going menu bar, clicking Tools → Global Options.RStudio puts things need work R single window, also includes features like keyboard shortcuts, autocompletion code, syntax highlighting (different types code colored differently, making easier navigate code).","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"getting-set-up-in-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1.4 Getting set up in RStudio","text":"good practice organize projects self-contained folders right start, start building habit now. well-organized project easier navigate, reproducible, easier share others. project start top-level folder contains everything necessary project, including data, scripts, images, organized sub-folders.RStudio provides “Projects” feature can make easier work individual projects R. create project keep everything workshop.Start RStudio (see view similar screenshot ).top right, see blue 3D cube words “Project: (None)”. Click icon.Click New Project dropdown menu.Click New Directory, New Project.Type name project, recommend R-Ecology-Workshop.Put convenient location using “Create project subdirectory :” section. recommend Desktop. can always move project somewhere else later, self-contained.Click Create Project new project open.Next time open RStudio, can click 3D cube icon, see options open existing projects, like one just made.One benefits using RStudio Projects automatically set working directory top-level folder project. working directory folder R working, views location files (including data scripts) relative working directory. may come across scripts include something like setwd(\"/Users/YourUserName/MyCoolProject\"), directly sets working directory. usually much less portable, since specific directory might found someone else’s computer (probably don’t username ). Using RStudio Projects means don’t deal manually setting working directory.settings need adjust improve reproducibility work. Go menu bar, click Tools → Global Options open Options window.Make sure settings match highlighted yellow. don’t want RStudio store current status R session reload next time start R. might sound convenient, sake reproducibility, want start clean, empty R session every time work. means record everything scripts, save data need files, store outputs like images files. want get used everything generate single R session disposable. want scripts able regenerate things need, “raw materials” like data.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"organizing-your-project-directory","chapter":"1 Introduction to R and RStudio","heading":"1.5 Organizing your project directory","text":"teaching remotely sharing RStudio window, new windows pop creating folders shared via Zoom. can switch sharing entire screen, allow learners see popup windows.Using consistent folder structure across new projects help keep growing project organized, make easy find files future. especially beneficial working multiple projects, since know look particular kinds files.use basic structure workshop, often good place start, can extended meet specific needs. diagram describing structure:Within project folder (R-Ecology-Workshop), first scripts folder hold scripts write. also data folder containing cleaned raw subfolders. general, want keep raw data completely untouched, put data folder, modify . Instead, read R, make modifications, write modified file cleaned folder. also images folder plots make, documents folder documents might produce.Let’s start making new folders. Go Files pane (bottom right), check current directory, highlighted yellow . directory project just made, case R-Ecology-Workshop. shouldn’t see folders yet.Next, click New Folder button, type scripts generate scripts folder. appear Files list now. Repeat process make data, images, documents folders. , click data folder Files pane. take data folder, empty. Use New Folder button create raw cleaned folders. return R-Ecology-Workshop folder, click file path, highlighted yellow previous image. ’s worth noting Files pane helps create, find, open files, moving files won’t change working directory project .","code":"R-Ecology-Workshop\n│\n└── scripts\n│\n└── data\n│    └── cleaned\n│    └── raw\n│\n└─── images\n│\n└─── documents"},{"path":"introduction-to-r-and-rstudio.html","id":"working-in-r-and-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1.6 Working in R and RStudio","text":"basis programming write instructions computer follow, tell computer follow instructions. write instructions form code, common language understood computer humans (practice). call instructions commands, tell computer follow instructions running (also called executing) commands.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"console-vs.-script","chapter":"1 Introduction to R and RStudio","heading":"1.6.1 Console vs. script","text":"can run commands directly R console, can write R script. may help think working console vs. working script something like cooking. console like making new recipe, writing anything . can carry series steps produce nice, tasty dish end. However, didn’t write anything , ’s harder figure exactly , order.Writing script like taking nice notes cooking- can tweak edit recipe want, can come back 6 months try , don’t try remember went well didn’t. ’s actually even easier cooking, since can hit one button computer “cooks” whole recipe !additional benefit scripts can leave comments others read. Lines start # considered comments interpreted R code.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"console","chapter":"1 Introduction to R and RStudio","heading":"1.6.1.1 Console","text":"R console code run/executedThe prompt, > symbol, can type commandsBy pressing Enter, R execute commands print result.can work , history saved History pane, can’t access future","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"script","chapter":"1 Introduction to R and RStudio","heading":"1.6.1.2 Script","text":"script record commands send R, preserved plain text file .R extensionYou can make new R script clicking File → New File → R Script, clicking green + button top left corner RStudio, pressing Shift+Cmd+N (Mac) Shift+Ctrl+N (Windows). unsaved, called “Untitled1”type lines R code script, can send R console evaluated\nCmd+Enter (Mac) Ctrl+Enter (Windows) run line code cursor \nhighlight multiple lines code, can run pressing Cmd+Enter (Mac) Ctrl+Enter (Windows)\npreserving commands script, can edit rerun quickly, save later, share others\ncan leave comments starting line #\nCmd+Enter (Mac) Ctrl+Enter (Windows) run line code cursor onIf highlight multiple lines code, can run pressing Cmd+Enter (Mac) Ctrl+Enter (Windows)preserving commands script, can edit rerun quickly, save later, share othersYou can leave comments starting line #","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"example","chapter":"1 Introduction to R and RStudio","heading":"1.6.1.3 Example","text":"Let’s try running code console script. First, click Console pane, type 1+1. Hit Enter run code. see code echoed, value 2 returned.Now click blank script, type 1+1. cursor line, hit Cmd+Enter (Mac) Ctrl+Enter (Windows) run code. see code sent script console, returned value 2, just like ran code directly console.R programming language software used run commands languageRStudio software make easier write run code RUse R Projects keep work organized self-containedWrite code scripts reproducibility portability","code":""},{"path":"data-visualization-with-ggplot2.html","id":"data-visualization-with-ggplot2","chapter":"2 Data Visualization with ggplot2","heading":"2 Data Visualization with ggplot2","text":"module teach use ggplot package R efficiently generate customizable complex plots like :ggplot() function initiates plot, geom_ functions add representations datause aes() mapping variable data part plotuse scale_ functions modify scales used represent variablesuse premade theme_ functions broadly change appearance, theme() function fine-tunestart simple build plots iteratively","code":""},{"path":"data-visualization-with-ggplot2.html","id":"learning-objectives-2","chapter":"2 Data Visualization with ggplot2","heading":"2.1 Learning objectives","text":"Produce scatter plots boxplots using ggplot2.Represent data variables plot components.Modify scales plot components.Iteratively build modify ggplot2 plots adding layers.Change appearance existing ggplot2 plots using premade customized themes.Describe faceting apply faceting ggplot2.Save plots image files.::::::::::::::::::::::::::::::::::::::::::::::::","code":""},{"path":"data-visualization-with-ggplot2.html","id":"setup","chapter":"2 Data Visualization with ggplot2","heading":"2.2 Setup","text":"going using functions ggplot2 package visualize data. Functions predefined bits code automate complicated actions. R many built-functions, can access many loading packages functions data R.don’t blank, untitled script open yet, go ahead open one Shift+Cmd+N (Mac) Shift+Ctrl+N (Windows). save file scripts/ folder, title workshop_code.R.Earlier, install tidyverse series packages, includes ggplot2 package running install.packages(\"tidyverse\"). installed package onto computer R can access . order use current session, load package using library() function.ggplot2 installed, can run install.packages(\"tidyverse\") console.good practice put install.packages() script. every time run whole script, package reinstalled, typically unnecessary. want install package computer , load library() script need use .Later learn read data external files R, now going use clean ready--use dataset provided ratdat data package. make dataset available, need load package .ratdat package contains data Portal Project, long-term dataset Portal, Arizona, Chihuahuan desert.using dataset called complete_old, contains older years mammal survey data. Let’s try learn little bit data. can use ? front name dataset, bring help page data.can read descriptions variable data.actually take look data, can use View() function open interactive viewer, behaves like simplified version spreadsheet program. ’s handy function, somewhat limited trying view large datasets.hover tab interactive View(), can click “x” appears, close tab.can find dataset using str() function examine structure data.str() tell us many observations/rows (obs) variables/columns , well information variables. see name variable (year), followed kind variable (int integer, chr character), first 10 entries variable. talk different data types structures later .","code":"\nlibrary(tidyverse)\nlibrary(ratdat)\n?complete_old\nView(complete_old)\nstr(complete_old)## tibble [16,878 × 13] (S3: tbl_df/tbl/data.frame)\n##  $ record_id      : int [1:16878] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ month          : int [1:16878] 7 7 7 7 7 7 7 7 7 7 ...\n##  $ day            : int [1:16878] 16 16 16 16 16 16 16 16 16 16 ...\n##  $ year           : int [1:16878] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 ...\n##  $ plot_id        : int [1:16878] 2 3 2 7 3 1 2 1 1 6 ...\n##  $ species_id     : chr [1:16878] \"NL\" \"NL\" \"DM\" \"DM\" ...\n##  $ sex            : chr [1:16878] \"M\" \"M\" \"F\" \"M\" ...\n##  $ hindfoot_length: int [1:16878] 32 33 37 36 35 14 NA 37 34 20 ...\n##  $ weight         : int [1:16878] NA NA NA NA NA NA NA NA NA NA ...\n##  $ genus          : chr [1:16878] \"Neotoma\" \"Neotoma\" \"Dipodomys\" \"Dipodomys\" ...\n##  $ species        : chr [1:16878] \"albigula\" \"albigula\" \"merriami\" \"merriami\" ...\n##  $ taxa           : chr [1:16878] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n##  $ plot_type      : chr [1:16878] \"Control\" \"Long-term Krat Exclosure\" \"Control\" \"Rodent Exclosure\" ..."},{"path":"data-visualization-with-ggplot2.html","id":"plotting-with-ggplot2","chapter":"2 Data Visualization with ggplot2","heading":"2.3 Plotting with ggplot2","text":"ggplot2 powerful package allows create complex plots tabular data (data table format rows columns). package uses consistent vocabulary create plots widely varying types. Therefore, need small changes code underlying data changes decide make box plot instead scatter plot. approach helps create publication-quality plots minimal adjusting tweaking.ggplot2 part tidyverse series packages, tend like data “long” “tidy” format, means column represents single variable, row represents single observation. Well-structured data save lots time making figures ggplot2. now, use data already format. start learning R using ggplot2 relies concepts need talk data transformation next lessons.ggplot plots built step step adding new layers, allows extensive flexibility customization plots.languages, like Python, require certain spacing indentation code run properly. isn’t case R, see spaces indentation code lesson, improve readability.build plot, use basic template can used different types plots:use ggplot() function create plot. order tell data use, need specify data argument. argument input function takes, set arguments using = sign.get blank plot haven’t told ggplot() variables want correspond parts plot. can specify “mapping” variables plot elements, x/y coordinates, size, shape, using aes() function. ’ll also add comment, line starting #. ’s good idea use comments organize code clarify .Now ’ve got plot x y axes corresponding variables complete_old. However, haven’t specified want data displayed. using geom_ functions, specify type geometry want, points, lines, bars. can add geom_point() layer plot using + sign. indent onto new line make easier read, end first line + sign.may notice warning missing values removed. variable necessary make plot missing given row data (case, hindfoot_length weight), can’t plotted. ggplot2 just uses warning message let us know rows couldn’t plotted.Warning messages one ways R communicate . Warnings can thought “heads ”. Nothing necessarily went wrong, author function wanted draw attention something. case, ’s worth knowing rows data plotted missing data.serious type message error. ’s example:can see, get error message, plot, something actually gone wrong. particular error message fairly common, happened misspelled point poit. function named geom_poit(), R tells us can’t find function name.","code":"ggplot(data = <DATA>, mapping = aes(<MAPPINGS>)) + <GEOM_FUNCTION>()\nggplot(data = complete_old)\n# adding a mapping to x and y axes\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length))\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_point()## Warning: Removed 3081 rows containing missing values or values outside the scale range\n## (`geom_point()`).\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_poit()## Error in geom_poit(): could not find function \"geom_poit\""},{"path":"data-visualization-with-ggplot2.html","id":"changing-aesthetics","chapter":"2 Data Visualization with ggplot2","heading":"2.4 Changing aesthetics","text":"Building ggplot plots often iterative process, ’ll continue developing scatter plot just made. may noticed parts scatter plot many overlapping points, making difficult see data. can adjust transparency points using alpha argument, takes value 0 1:can also change color points:Two common issues might run working R forgetting closing bracket closing quote. Let’s take look one .Try running following code:see + appear console. R telling expects input order finish running code. missing closing bracket end geom_point function call. can hit Esc console reset .Something similar happen run following code:missing quote end blue means rest code treated part quote, bit easier see since RStudio displays character strings different color.get different error message run following code:time extra closing ), R doesn’t know . tells unexpected ), doesn’t pinpoint exactly . enough time working R, get better spotting mismatched brackets.","code":"\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_point(alpha = 0.2)\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_point(alpha = 0.2, color = \"blue\")ggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_point(color = \"blue\", alpha = 0.2ggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_point(color = \"blue, alpha = 0.2)ggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length)) +\n  geom_point(color = \"blue\", alpha = 0.2))"},{"path":"data-visualization-with-ggplot2.html","id":"adding-another-variable","chapter":"2 Data Visualization with ggplot2","heading":"2.4.1 Adding another variable","text":"Let’s try coloring points according sampling plot type (plot refers physical area rodents sampled nothing making graphs). Since ’re now mapping variable (plot_type) component ggplot2 plot (color), need put argument inside aes():","code":"\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length, color = plot_type)) +\n  geom_point(alpha = 0.2)"},{"path":"data-visualization-with-ggplot2.html","id":"challenge-1-modifying-plots","chapter":"2 Data Visualization with ggplot2","heading":"2.5 Challenge 1: Modifying plots","text":"Try modifying plot shape point varies sex. set shape way set color.think good way represent sex data?Solution. Now try changing plot color points vary year. notice difference color scale compared changing color plot type? think happened?Solution. Part 2, color scale different compared using color = plot_type plot_type year different variable types. plot_type categorical variable, ggplot2 defaults use discrete color scale, whereas year numeric variable, ggplot2 uses continuous color scale.","code":"\nggplot(data = complete_old, \n       mapping = aes(x = weight, y = hindfoot_length, shape = sex)) +\n  geom_point(alpha = 0.2)\nggplot(data = complete_old, \n       mapping = aes(x = weight, y = hindfoot_length, color = year)) +\n  geom_point(alpha = 0.2)"},{"path":"data-visualization-with-ggplot2.html","id":"changing-scales","chapter":"2 Data Visualization with ggplot2","heading":"2.6 Changing scales","text":"default discrete color scale isn’t always ideal: isn’t friendly viewers colorblindness doesn’t translate well grayscale. However, ggplot2 comes quite color scales, including fantastic viridis scales, designed colorblind grayscale friendly. can change scales adding scale_ functions plots:Scales don’t just apply colors- plot component put inside aes() can modified scale_ functions. Just modified scale used map plot_type color, can modify way weight mapped x axis using scale_x_log10() function:One nice thing ggplot tidyverse general groups functions similar things given similar names. function modifies ggplot scale starts scale_, making easier search right function.","code":"\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length, color = plot_type)) +\n  geom_point(alpha = 0.2) +\n  scale_color_viridis_d()\nggplot(data = complete_old, mapping = aes(x = weight, y = hindfoot_length, color = plot_type)) +\n  geom_point(alpha = 0.2) +\n  scale_x_log10()"},{"path":"data-visualization-with-ggplot2.html","id":"boxplot","chapter":"2 Data Visualization with ggplot2","heading":"2.7 Boxplot","text":"Let’s try making different type plot altogether. ’ll start basic building blocks using ggplot() aes().time, let’s try making boxplot, plot_type x axis hindfoot_length y axis. can adding geom_boxplot() ggplot():Just colored points , can color boxplot plot_type well:looks like color affected outlines boxplot, rectangular portions. color impacts 1-dimensional parts ggplot: points lines. change color 2-dimensional parts plot, use fill:One thing may notice axis labels overlapping , depending wide plot viewer . One way help make legible wrap text. can modifying labels x axis scale.use scale_x_discrete() function discrete axis, modify labels argument. function label_wrap_gen() wrap text labels make legible.","code":"\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length))\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot()## Warning: Removed 2733 rows containing non-finite outside the scale range\n## (`stat_boxplot()`).\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length, color = plot_type)) +\n  geom_boxplot()\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length, fill = plot_type)) +\n  geom_boxplot()\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length, fill = plot_type)) +\n  geom_boxplot() +\n  scale_x_discrete(labels = label_wrap_gen(width = 10))"},{"path":"data-visualization-with-ggplot2.html","id":"adding-geoms","chapter":"2 Data Visualization with ggplot2","heading":"2.8 Adding geoms","text":"One powerful aspects ggplot way can add components plot successive layers. boxplots can useful summarizing data, often helpful show raw data well. ggplot, can easily add another geom_ plot show raw data.Let’s add geom_point() visualize raw data. modify alpha argument help overplotting.Uh oh… points given x axis category fall exactly line, isn’t useful. can shift using geom_jitter(), add points bit random noise added positions prevent happening.may noticed data points now appearing plot twice: outliers plotted black points geom_boxplot(), also plotted geom_jitter(). Since don’t want represent data multiple times form (points), can stop geom_boxplot() plotting . setting outlier.shape argument NA, means outliers don’t shape plotted.Just , can map plot_type color putting inside aes().Notice color points color boxplot lines changed. time specify aes() mapping inside initial ggplot() function, mapping apply geoms.want limit mapping single geom, can put mapping specific geom_ function, like :Now points colored according plot_type, boxplots color. One thing might notice even alpha = 0.2, points obscure parts boxplot. geom_point() layer comes geom_boxplot() layer, means points plotted top boxes. put boxplots top, switch order layers:Now opposite problem! white fill boxplots completely obscures points. address problem, can remove fill boxplots altogether, leaving black lines. , set fill NA:Now can see raw data boxplots top.","code":"\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot() +\n  geom_point(alpha = 0.2)\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.2)\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(alpha = 0.2)\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length, color = plot_type)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(alpha = 0.2)\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(aes(color = plot_type), alpha = 0.2)\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_jitter(aes(color = plot_type), alpha = 0.2) +\n  geom_boxplot(outlier.shape = NA)\nggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_jitter(aes(color = plot_type), alpha = 0.2) +\n  geom_boxplot(outlier.shape = NA, fill = NA)"},{"path":"data-visualization-with-ggplot2.html","id":"challenge-2-change-geoms","chapter":"2 Data Visualization with ggplot2","heading":"2.9 Challenge 2: Change geoms","text":"Violin plots similar boxplots- try making one using plot_type hindfoot_length x y variables. Remember geom functions start geom_, followed type geom.might also place test search engine skills. often useful search R package_name stuff want search. example might search R ggplot2 violin plot.Solution. extra challenge, , make color points outlines violins vary plot_type, set fill violins white. Try playing order layers see looks best.Solution. ","code":"\nggplot(data = complete_old, \n       mapping = aes(x = plot_type, \n                     y = hindfoot_length,\n                     color = plot_type)) +\n  geom_jitter(alpha = 0.2) +\n  geom_violin(fill = \"white\")\nggplot(data = complete_old, \n       mapping = aes(x = plot_type, \n                     y = hindfoot_length,\n                     color = plot_type)) +\n  geom_jitter(alpha = 0.2) +\n  geom_violin(fill = \"white\")"},{"path":"data-visualization-with-ggplot2.html","id":"changing-themes","chapter":"2 Data Visualization with ggplot2","heading":"2.10 Changing themes","text":"far ’ve changing appearance parts plot related data geom_ functions, can also change many non-data components plot.point, pretty happy basic layout plot, can assign plot named object. using assignment arrow <-. taking result code right side arrow, assigning object whose name left side arrow.create object called myplot. run name ggplot2 object, show plot, just like ran code .process assigning something object specific ggplot2, rather general feature R. using lot rest lesson. can now work myplot object block ggplot2 code, means can use + add new components .can change overall appearance using theme_ functions. Let’s try black--white theme adding theme_bw() plot:can see, number parts plot changed. theme_ functions usually control many aspects plot’s appearance , sake convenience. individually change parts plot, can use theme() function, can take many different arguments change things text, grid lines, background color, . Let’s try changing size text axis titles. can specifying axis.title element_text() size set 14.Another change might want make remove vertical grid lines. Since x axis categorical, grid lines aren’t useful. , inside theme(), change panel.grid.major.x element_blank().Another useful change might remove color legend, since information already x axis. one, set legend.position “none”.many possible arguments theme() function, can sometimes hard find right one. tips figuring modify plot element:type theme(), put cursor parentheses, hit Tab bring list arguments\ncan scroll arguments, start typing, shorten list potential matches\ncan scroll arguments, start typing, shorten list potential matcheslike many things tidyverse, similar argument start similar names\naxis, legend, panel, plot, strip arguments\naxis, legend, panel, plot, strip argumentsarguments hierarchy\ntext controls text whole plot\naxis.title controls text axis titles\naxis.title.x controls text x axis title\ntext controls text whole plotaxis.title controls text axis titlesaxis.title.x controls text x axis titleYou may noticed used 3 different approaches getting rid something ggplot:outlier.shape = NA remove outliers boxplotpanel.grid.major.x = element_blank() remove x grid lineslegend.position = \"none\" remove legendWhy many ways seems like thing?? common frustration working R, programming language. couple reasons :Different people contribute different packages functions, may choose things differently.Code may appear thing, details actually quite different. inner workings ggplot2 actually quite complex, since turns making plots complicated process! , things seem (removing parts plot), may actually operating different components stages final plot.Developing packages highly iterative process, sometimes things change. However, changing much stuff can make old code break. Let’s say removing legend introduced feature ggplot2, lot time passed someone added feature letting remove outliers geom_boxplot(). Changing way remove legend, ’s boxplot approach, break code written meantime, developers may opt keep old approach place.","code":"\nmyplot <- ggplot(data = complete_old, mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_jitter(aes(color = plot_type), alpha = 0.2) +\n  geom_boxplot(outlier.shape = NA, fill = NA)\n\nmyplot## Warning: Removed 2733 rows containing non-finite outside the scale range\n## (`stat_boxplot()`).## Warning: Removed 2733 rows containing missing values or values outside the scale range\n## (`geom_point()`).\nmyplot + theme_bw()\nmyplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14))\nmyplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), \n        panel.grid.major.x = element_blank())\nmyplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), \n        panel.grid.major.x = element_blank(), \n        legend.position = \"none\")"},{"path":"data-visualization-with-ggplot2.html","id":"changing-labels","chapter":"2 Data Visualization with ggplot2","heading":"2.11 Changing labels","text":"plot really shaping now. However, probably want make axis titles nicer, perhaps add main title plot. can using labs() function:removed legend plot, can also change titles various legends using labs(). example, labs(color = \"Plot type\") change title color scale legend “Plot type”.","code":"\nmyplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), \n        legend.position = \"none\") +\n  labs(title = \"Rodent size by plot type\",\n       x = \"Plot type\",\n       y = \"Hindfoot length (mm)\")"},{"path":"data-visualization-with-ggplot2.html","id":"challenge-3-customizing-a-plot","chapter":"2 Data Visualization with ggplot2","heading":"2.12 Challenge 3: Customizing a plot","text":"Modify previous plot adding descriptive subtitle. Increase font size plot title make bold.Hint: “bold” referred font “face”Solution. ","code":"\nmyplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), legend.position = \"none\",\n        plot.title = element_text(face = \"bold\", size = 20)) +\n  labs(title = \"Rodent size by plot type\",\n       subtitle = \"Long-term dataset from Portal, AZ\",\n       x = \"Plot type\",\n       y = \"Hindfoot length (mm)\")"},{"path":"data-visualization-with-ggplot2.html","id":"faceting","chapter":"2 Data Visualization with ggplot2","heading":"2.13 Faceting","text":"One powerful features ggplot ability quickly split plot multiple smaller plots based categorical variable, called faceting.far ’ve mapped variables x axis, y axis, color, trying add 4th variable becomes difficult. Changing shape point might work, categories, even , can hard tell differences shapes small points.Instead cramming one variable single plot, use facet_wrap() function generate series smaller plots, split sex. also use ncol specify want arranged single column:Faceting comes handy many scenarios. can useful :categorical variable many levels differentiate color (dataset 20 countries)data overlap heavily, obscuring categoriesyou want show 3 variables onceyou want see category isolation allowing general comparisons categories","code":"\nmyplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), \n        legend.position = \"none\", \n        panel.grid.major.x = element_blank()) +\n  labs(title = \"Rodent size by plot type\",\n       x = \"Plot type\",\n       y = \"Hindfoot length (mm)\",\n       color = \"Plot type\") +\n  facet_wrap(vars(sex), ncol = 1)"},{"path":"data-visualization-with-ggplot2.html","id":"exporting-plots","chapter":"2 Data Visualization with ggplot2","heading":"2.14 Exporting plots","text":"happy final plot, can assign whole thing new object, can call finalplot., can run ggsave() save plot. first argument give path file want save, including correct file extension. code make image called rodent_size_plots.jpg images/ folder current project. making .jpg, can save .pdf, .tiff, file formats. Next, tell name plot object want save. can also specify things like width height plot inches.","code":"\nfinalplot <- myplot +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), \n        legend.position = \"none\", \n        panel.grid.major.x = element_blank()) +\n  labs(title = \"Rodent size by plot type\",\n       x = \"Plot type\",\n       y = \"Hindfoot length (mm)\",\n       color = \"Plot type\") +\n  facet_wrap(vars(sex), ncol = 1)\n\n\n\ncomplete_old %>%\nfilter(sex %in% c(\"M\", \"F\")) %>%\nmutate(sex = case_when(sex == \"M\" ~ \"Male\", TRUE ~ \"Female\")) %>%\nggplot(mapping = aes(x = plot_type, y = hindfoot_length)) +\n  geom_jitter(aes(color = plot_type), alpha = 0.2) +\n  geom_boxplot(outlier.shape = NA, fill = NA) +\n  theme_bw() +\n  theme(axis.title = element_text(size = 14), \n        legend.position = \"none\", \n        panel.grid.major.x = element_blank()) +\n  labs(title = \"Rodent size by plot type\",\n       x = \"Plot type\",\n       y = \"Hindfoot length (mm)\",\n       color = \"Plot type\") +\n  facet_wrap(vars(sex), ncol = 1)## Warning: Removed 1460 rows containing non-finite outside the scale range\n## (`stat_boxplot()`).## Warning: Removed 1460 rows containing missing values or values outside the scale range\n## (`geom_point()`).\nggsave(filename = \"images/rodent_size_plots.jpg\",\n       height = 6, width = 8)"},{"path":"data-visualization-with-ggplot2.html","id":"challenge-4-make-your-own-plot","chapter":"2 Data Visualization with ggplot2","heading":"2.15 Challenge 4: Make your own plot","text":"Try making plot! can run str(complete_old) ?complete_old explore variables might use new plot. Feel free use variables already seen, haven’t explored yet.couple ideas get started:make histogram one numeric variablestry using different color scale_try changing size points thickness lines geom","code":""},{"path":"exploring-and-understanding-data.html","id":"exploring-and-understanding-data","chapter":"3 Exploring and understanding data","heading":"3 Exploring and understanding data","text":"Coercion something often intentionally; rather, combining vectors reading data R, stray character missed may change entire numeric vector character vector. good idea check class() results frequently, particularly running confusing error messages.Understanding ’s going help avoid lot confusion working R. assign something object, first thing happens righthand side gets evaluated. thing happens run something console: type x console hit Enter, R returns value x. first ran line y <- x, x first gets evaluated value 5, gets assigned y. objects x y actually linked way, change value x 10, y unaffected.also means can run multiple nested operations, store intermediate values separate objects, overwrite values:naming objects R, common naming rules conventions:make names clear without long\nwkg probably short\nweight_in_kilograms probably long\nweight_kg good\nwkg probably shortweight_in_kilograms probably longweight_kg goodnames start numbernames case sensitiveyou use names fundamental functions R, like , else, \ngeneral, avoid using names common functions like c, mean, etc.\ngeneral, avoid using names common functions like c, mean, etc.avoid dots . names, special meaning R, may confusing otherstwo common formats snake_case camelCasebe consistent, least within script, ideally within whole projectyou can use style guide like Google’s \ntidyverse’sfunctions like head(), str(), summary() useful exploring data.framesmost things R vectors, vectors stitched together, functionsmake sure use class() check vector types, especially using new functionsfactors can useful, behave differently character vectors","code":"\nx <- 5\n\n# first, x gets evaluated to 5\n# then 5/2 gets evaluated to 2.5\n# then sqrt(2.5) is evaluated\nsqrt(x/2)## [1] 1.581139\n# we can also store the evaluated value of x/2 \n# in an object y before passing it to sqrt()\ny <- x/2\n\nsqrt(y)## [1] 1.581139\n# first, the x on the righthand side gets evaluated to 5\n# then 5 gets squared\n# then the resulting value is assigned to the object x\n\nx <- x^2\n\nx## [1] 25"},{"path":"exploring-and-understanding-data.html","id":"learning-objectives-3","chapter":"3 Exploring and understanding data","heading":"3.1 Learning Objectives","text":"Explore structure content data.framesUnderstand vector types missing dataUse vectors function argumentsCreate convert factorsUnderstand R assigns values objects","code":""},{"path":"exploring-and-understanding-data.html","id":"setup-1","chapter":"3 Exploring and understanding data","heading":"3.2 Setup","text":"","code":"\nlibrary(tidyverse)\nlibrary(ratdat)"},{"path":"exploring-and-understanding-data.html","id":"the-data.frame","chapter":"3 Exploring and understanding data","heading":"3.3 The data.frame","text":"just spent quite bit time learning create visualizations complete_old data, talk much complete_old thing . ’s important understand R thinks , represents, stores data order us productive working relationship R.complete_old data stored R data.frame, common way R represents tabular data (data can stored table format, like spreadsheet). can check complete_old using class() function:can view first rows head() function, last rows tail() function:used functions just one argument, object complete_old, didn’t give argument name, like often ggplot2. R, function’s arguments come particular order, put correct order, don’t need name . case, name argument x, can name want, since know ’s first argument, don’t need .learn function, can type ? front name function, bring official documentation function:Function documentation written authors functions, can vary pretty widely style readability. first section, Description, gives concise description function , may always enough. Arguments section defines arguments function usually worth reading thoroughly. Finally, Examples section end often helpful examples can run get sense function .Another great source information package vignettes. Many packages vignettes, like tutorials introduce package, specific functions, general methods. can run vignette(package = \"package_name\") see list vignettes package. name, can run vignette(\"vignette_name\", \"package_name\") view vignette. can also use web browser go https://cran.r-project.org/web/packages/package_name/vignettes/ find list links vignette. packages websites, often nicely formatted vignettes tutorials.Finally, learning search help probably useful skill R user. key skill figuring actually search . ’s often good idea start search R R programming. name package want use, start R package_name.Many answers find website called Stack Overflow, people ask programming questions others provide answers. generally poor form ask duplicate questions, decide post , thorough searching see answered (likely ). decide post question Stack Overflow, help forum, want create reproducible example reprex. asking complicated question requiring data whole bunch code, people probably won’t able willing help . However, can hone specific thing want help , create minimal example using smaller, fake data, much easier others help . search make reproducible example R, find great resources help .arguments optional. example, n argument head() specifies number rows print. defaults 6, can override specifying different number:order correctly, don’t name either:Additionally, name , can put order want:Generally, ’s good practice start required arguments, like data.frame whose rows want see, name optional arguments. ever unsure, never hurts explicitly name argument.Let’s get back investigating complete_old data.frame. can get useful summaries variable using summary() function:, already done, can use str() look structure object:get quite bit useful information . First, told data.frame 16878 observations, rows, 13 variables, columns.Next, get bit information variable, including type (int chr) quick peek first 10 values. might ask $ front variable. $ operator allows us select individual columns data.frame.$ operator also allows use tab-completion quickly select variable want given data.frame. example, get year variable, can type complete_old$ hit Tab. get list variables can move arrow keys. Hit Enter reach year, finish code:get back whole bunch numbers, entries year column printed order.","code":"\nclass(complete_old)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nhead(complete_old)## # A tibble: 6 × 13\n##   record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##       <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n## 1         1     7    16  1977       2 NL         M                  32     NA\n## 2         2     7    16  1977       3 NL         M                  33     NA\n## 3         3     7    16  1977       2 DM         F                  37     NA\n## 4         4     7    16  1977       7 DM         M                  36     NA\n## 5         5     7    16  1977       3 DM         M                  35     NA\n## 6         6     7    16  1977       1 PF         M                  14     NA\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\ntail(complete_old)## # A tibble: 6 × 13\n##   record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##       <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n## 1     16873    12     5  1989       8 DO         M                  37     51\n## 2     16874    12     5  1989      16 RM         F                  18     15\n## 3     16875    12     5  1989       5 RM         M                  17      9\n## 4     16876    12     5  1989       4 DM         M                  37     31\n## 5     16877    12     5  1989      11 DM         M                  37     50\n## 6     16878    12     5  1989       8 DM         F                  37     42\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\n?head\nhead(complete_old, n = 10)## # A tibble: 10 × 13\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\nhead(complete_old, 10)## # A tibble: 10 × 13\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\nhead(n = 10, x = complete_old)## # A tibble: 10 × 13\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\nsummary(complete_old)##    record_id         month             day            year         plot_id     \n##  Min.   :    1   Min.   : 1.000   Min.   : 1.0   Min.   :1977   Min.   : 1.00  \n##  1st Qu.: 4220   1st Qu.: 3.000   1st Qu.: 9.0   1st Qu.:1981   1st Qu.: 5.00  \n##  Median : 8440   Median : 6.000   Median :15.0   Median :1983   Median :11.00  \n##  Mean   : 8440   Mean   : 6.382   Mean   :15.6   Mean   :1984   Mean   :11.47  \n##  3rd Qu.:12659   3rd Qu.: 9.000   3rd Qu.:23.0   3rd Qu.:1987   3rd Qu.:17.00  \n##  Max.   :16878   Max.   :12.000   Max.   :31.0   Max.   :1989   Max.   :24.00  \n##                                                                                \n##   species_id            sex            hindfoot_length     weight      \n##  Length:16878       Length:16878       Min.   : 6.00   Min.   :  4.00  \n##  Class :character   Class :character   1st Qu.:21.00   1st Qu.: 24.00  \n##  Mode  :character   Mode  :character   Median :35.00   Median : 42.00  \n##                                        Mean   :31.98   Mean   : 53.22  \n##                                        3rd Qu.:37.00   3rd Qu.: 53.00  \n##                                        Max.   :70.00   Max.   :278.00  \n##                                        NA's   :2733    NA's   :1692    \n##     genus             species              taxa            plot_type        \n##  Length:16878       Length:16878       Length:16878       Length:16878      \n##  Class :character   Class :character   Class :character   Class :character  \n##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n##                                                                             \n##                                                                             \n##                                                                             \n## \nstr(complete_old)## tibble [16,878 × 13] (S3: tbl_df/tbl/data.frame)\n##  $ record_id      : int [1:16878] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ month          : int [1:16878] 7 7 7 7 7 7 7 7 7 7 ...\n##  $ day            : int [1:16878] 16 16 16 16 16 16 16 16 16 16 ...\n##  $ year           : int [1:16878] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 ...\n##  $ plot_id        : int [1:16878] 2 3 2 7 3 1 2 1 1 6 ...\n##  $ species_id     : chr [1:16878] \"NL\" \"NL\" \"DM\" \"DM\" ...\n##  $ sex            : chr [1:16878] \"M\" \"M\" \"F\" \"M\" ...\n##  $ hindfoot_length: int [1:16878] 32 33 37 36 35 14 NA 37 34 20 ...\n##  $ weight         : int [1:16878] NA NA NA NA NA NA NA NA NA NA ...\n##  $ genus          : chr [1:16878] \"Neotoma\" \"Neotoma\" \"Dipodomys\" \"Dipodomys\" ...\n##  $ species        : chr [1:16878] \"albigula\" \"albigula\" \"merriami\" \"merriami\" ...\n##  $ taxa           : chr [1:16878] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n##  $ plot_type      : chr [1:16878] \"Control\" \"Long-term Krat Exclosure\" \"Control\" \"Rodent Exclosure\" ...\ncomplete_old$year##   [1] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [16] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [31] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [46] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [61] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [76] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [91] 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977\n##  [ reached getOption(\"max.print\") -- omitted 16778 entries ]"},{"path":"exploring-and-understanding-data.html","id":"vectors-the-building-block-of-data","chapter":"3 Exploring and understanding data","heading":"3.4 Vectors: the building block of data","text":"might noticed last result looked different printed complete_old data.frame . ’s data.frame, vector. vector 1-dimensional series values, case vector numbers representing years.Data.frames made vectors; column data.frame vector. Vectors basic building blocks data R. Basically, everything R vector, bunch vectors stitched together way, function. Understanding vectors work crucial understanding R treats data, spend time learning .4 main types vectors (also known atomic vectors):\"character\" strings characters, like genus sex columns. entry character vector wrapped quotes. programming languages, type data may referred “strings”.\"character\" strings characters, like genus sex columns. entry character vector wrapped quotes. programming languages, type data may referred “strings”.\"integer\" integers. numeric values complete_old integers. may sometimes see integers represented like 2L 20L. L indicates R integer, instead next data type, \"numeric\".\"integer\" integers. numeric values complete_old integers. may sometimes see integers represented like 2L 20L. L indicates R integer, instead next data type, \"numeric\".\"numeric\", aka \"double\", vectors can contain numbers including decimals. languages may refer “float” “floating point” numbers.\"numeric\", aka \"double\", vectors can contain numbers including decimals. languages may refer “float” “floating point” numbers.\"logical\" TRUE FALSE, can also represented T F. contexts, may referred “Boolean” data.\"logical\" TRUE FALSE, can also represented T F. contexts, may referred “Boolean” data.Vectors can single type. Since column data.frame vector, means accidental character following number, like 29, can change type whole vector. Mixing vector types one common mistakes R, can tricky figure . ’s often useful check types vectors.create vector scratch, can use c() function, putting values inside, separated commas.can see, values get printed console, just like complete_old$year. store vector can continue work , need assign object.can check kind object num class() function.see num numeric vector.Let’s try making character vector:Remember entry, like \"apple\", needs surrounded quotes, entries separated commas. something like \"apple, pear, grape\", single entry containing whole string.Finally, let’s make logical vector:","code":"\nc(1, 2, 5, 12, 4)## [1]  1  2  5 12  4\nnum <- c(1, 2, 5, 12, 4)\nclass(num)## [1] \"numeric\"\nchar <- c(\"apple\", \"pear\", \"grape\")\nclass(char)## [1] \"character\"\nlogi <- c(TRUE, FALSE, TRUE, TRUE)\nclass(logi)## [1] \"logical\""},{"path":"exploring-and-understanding-data.html","id":"challenge-1-coercion","chapter":"3 Exploring and understanding data","heading":"3.5 Challenge 1: Coercion","text":"Since vectors can hold one type data, something done try combine different types data one vector.type vectors ? Try guess without running code first, run code use class() verify answers.Solution. R automatically convert values vector type, process called coercion.many values combined_logical \"TRUE\" (character)?Solution. one value \"TRUE\". Coercion happens vector created, TRUE num_logi becomes 1, TRUE char_logi becomes \"TRUE\". two vectors combined, R doesn’t remember 1 num_logi used TRUE, just coerce 1 \"1\".Now ’ve seen examples coercion, might started see rules types get converted. hierarchy coercion. Can draw diagram represents hierarchy types get converted types?Solution. logical → integer → numeric → characterLogical vectors can take two values: TRUE FALSE. Integer vectors can contain integers, TRUE FALSE can coerced 1 0. Numeric vectors can contain numbers decimals, integers can coerced , say, 6 6.0 (though R still display numeric 6 6.). Finally, string characters can represented character vector, types can coerced character vector.","code":"\nnum_logi <- c(1, 4, 6, TRUE)\nnum_char <- c(1, 3, \"10\", 6)\nchar_logi <- c(\"a\", \"b\", TRUE)\n\n\ntricky <- c(\"a\", \"b\", \"1\", FALSE)\nclass(num_logi)## [1] \"numeric\"\nclass(num_char)## [1] \"character\"\nclass(char_logi)## [1] \"character\"\nclass(tricky)## [1] \"character\"\ncombined_logical <- c(num_logi, char_logi)\ncombined_logical## [1] \"1\"    \"4\"    \"6\"    \"1\"    \"a\"    \"b\"    \"TRUE\"\nclass(combined_logical)## [1] \"character\""},{"path":"exploring-and-understanding-data.html","id":"missing-data","chapter":"3 Exploring and understanding data","heading":"3.6 Missing data","text":"One great things R handles missing data, can tricky programming languages. R represents missing data NA, without quotes, vectors type. Let’s make numeric vector NA value:R doesn’t make assumptions want handle missing data, pass vector numeric function like min(), won’t know , returns NA:good thing, since won’t accidentally forget consider missing data. decide exclude missing values, many basic math functions argument remove :","code":"\nweights <- c(25, 34, 12, NA, 42)\nmin(weights)## [1] NA\nmin(weights, na.rm = TRUE)## [1] 12"},{"path":"exploring-and-understanding-data.html","id":"vectors-as-arguments","chapter":"3 Exploring and understanding data","heading":"3.7 Vectors as arguments","text":"common reason create vector scratch use function argument. quantile() function calculate quantile given vector numeric values. set quantile using probs argument. also need set na.rm = TRUE, since NA values weight column.Now get back 25% quantile value weights. However, often want know one quantile. Luckily, probs argument vectorized, meaning can take whole vector values. Let’s try getting 25%, 50% (median), 75% quantiles .c() function flexible, doesn’t necessarily scale well. want generate long vector scratch, probably don’t want type everything manually. functions can help generate vectors.First, putting : two numbers generate vector integers starting first number ending last. seq() function allows generate similar sequences, changing amount.Finally, rep() function allows repeat value, even whole vector, many times want, works type vector.","code":"\nquantile(complete_old$weight, probs = 0.25, na.rm = TRUE)## 25% \n##  24\nquantile(complete_old$weight, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)## 25% 50% 75% \n##  24  42  53\n# generates a sequence of integers\n1:10##  [1]  1  2  3  4  5  6  7  8  9 10\n# with seq() you can generate sequences with a combination of:\n# from: starting value\n# to: ending value\n# by: how much should each entry increase\n# length.out: how long should the resulting vector be\nseq(from = 0, to = 1, by = 0.1)##  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\nseq(from = 0, to = 1, length.out = 50)##  [1] 0.00000000 0.02040816 0.04081633 0.06122449 0.08163265 0.10204082\n##  [7] 0.12244898 0.14285714 0.16326531 0.18367347 0.20408163 0.22448980\n## [13] 0.24489796 0.26530612 0.28571429 0.30612245 0.32653061 0.34693878\n## [19] 0.36734694 0.38775510 0.40816327 0.42857143 0.44897959 0.46938776\n## [25] 0.48979592 0.51020408 0.53061224 0.55102041 0.57142857 0.59183673\n## [31] 0.61224490 0.63265306 0.65306122 0.67346939 0.69387755 0.71428571\n## [37] 0.73469388 0.75510204 0.77551020 0.79591837 0.81632653 0.83673469\n## [43] 0.85714286 0.87755102 0.89795918 0.91836735 0.93877551 0.95918367\n## [49] 0.97959184 1.00000000\nseq(from = 0, by = 0.01, length.out = 20)##  [1] 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14\n## [16] 0.15 0.16 0.17 0.18 0.19\n# repeats \"a\" 12 times\nrep(\"a\", times = 12)##  [1] \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\" \"a\"\n# repeats this whole sequence 4 times\nrep(c(\"a\", \"b\", \"c\"), times = 4)##  [1] \"a\" \"b\" \"c\" \"a\" \"b\" \"c\" \"a\" \"b\" \"c\" \"a\" \"b\" \"c\"\n# repeats each value 4 times\nrep(1:10, each = 4)##  [1]  1  1  1  1  2  2  2  2  3  3  3  3  4  4  4  4  5  5  5  5  6  6  6  6  7\n## [26]  7  7  7  8  8  8  8  9  9  9  9 10 10 10 10"},{"path":"exploring-and-understanding-data.html","id":"challenge-2-creating-sequences","chapter":"3 Exploring and understanding data","heading":"3.8 Challenge 2: Creating sequences","text":"Write code generate following vector:Solution. Calculate quantiles complete_old hindfoot lengths every 5% level (0%, 5%, 10%, 15%, etc.)Solution. ","code":"##  [1] -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3\nrep(-3:3, 3)##  [1] -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3\n# this also works\nrep(seq(from = -3, to = 3, by = 1), 3)##  [1] -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3\n# you might also store the sequence as an intermediate vector\n\nmy_seq <- seq(from = -3, to = 3, by = 1)\nrep(my_seq, 3)##  [1] -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3 -3 -2 -1  0  1  2  3\nquantile(complete_old$hindfoot_length, \n         probs = seq(from = 0, to = 1, by = 0.05),\n         na.rm = T)##   0%   5%  10%  15%  20%  25%  30%  35%  40%  45%  50%  55%  60%  65%  70%  75% \n##    6   16   17   19   20   21   22   31   33   34   35   35   36   36   36   37 \n##  80%  85%  90%  95% 100% \n##   37   39   49   51   70"},{"path":"exploring-and-understanding-data.html","id":"building-with-vectors","chapter":"3 Exploring and understanding data","heading":"3.9 Building with vectors","text":"now seen vectors different forms: columns data.frame single vectors. However, can manipulated lots shapes forms. common forms :matrices\n2-dimensional numeric representations\n2-dimensional numeric representationsarrays\nmany-dimensional numeric\nmany-dimensional numericlists\nlists flexible ways store vectors\nlist can contain vectors many different types lengths\nentry list can another list, lists can get deeply nested\ndata.frame type list column individual vector vector length, since data.frame entry every column row\nlists flexible ways store vectorsa list can contain vectors many different types lengthsan entry list can another list, lists can get deeply nesteda data.frame type list column individual vector vector length, since data.frame entry every column rowfactors\nway represent categorical data\nfactors can ordered unordered\noften look like character vectors, behave differently\nhood, integers character labels, called levels, integer\nway represent categorical datafactors can ordered unorderedthey often look like character vectors, behave differentlyunder hood, integers character labels, called levels, integer","code":""},{"path":"exploring-and-understanding-data.html","id":"factors","chapter":"3 Exploring and understanding data","heading":"3.9.1 Factors","text":"spend bit time talking factors, since often challenging type data work . can create factor scratch putting character vector made using c() factor() function:can inspect levels factor using levels() function:forcats package tidyverse lot convenient functions working factors. show common operations, forcats package many useful functions.general, good practice leave categorical data character vector need use factor. reasons might need factor:Another function requires use factorYou plotting categorical data want control ordering categories plotSince factors can behave differently character vectors, always good idea check type data ’re working . might use new function first time confused results, realize later produced factor output, thought character vector.fairly straightforward convert factor character vector:However, need careful ’re somehow working factor numbers levels:","code":"\nsex <- factor(c(\"male\", \"female\", \"female\", \"male\", \"female\", NA))\n\nsex## [1] male   female female male   female <NA>  \n## Levels: female male\nlevels(sex)## [1] \"female\" \"male\"\nlibrary(forcats)\n\n# change the order of the levels\nfct_relevel(sex, c(\"male\", \"female\"))## [1] male   female female male   female <NA>  \n## Levels: male female\n# change the names of the levels\nfct_recode(sex, \"M\" = \"male\", \"F\" = \"female\")## [1] M    F    F    M    F    <NA>\n## Levels: F M\n# turn NAs into an actual factor level (useful for including NAs in plots)\nfct_na_value_to_level(sex, \"(Missing)\")## [1] male      female    female    male      female    (Missing)\n## Levels: female male (Missing)\nas.character(sex)## [1] \"male\"   \"female\" \"female\" \"male\"   \"female\" NA\nf_num <- factor(c(1990, 1983, 1977, 1998, 1990))\n\n# this will pull out the underlying integers, not the levels\nas.numeric(f_num)## [1] 3 2 1 4 3\n# if we first convert to characters, we can then convert to numbers\nas.numeric(as.character(f_num))## [1] 1990 1983 1977 1998 1990"},{"path":"exploring-and-understanding-data.html","id":"assignment-objects-and-values","chapter":"3 Exploring and understanding data","heading":"3.10 Assignment, objects, and values","text":"’ve already created quite objects R using <- assignment arrow, finer details worth talking . First, let’s start quick challenge.","code":""},{"path":"exploring-and-understanding-data.html","id":"challenge-3-assignments-and-objects","chapter":"3 Exploring and understanding data","heading":"3.11 Challenge 3: Assignments and objects","text":"value y running following code?Solution. ","code":"\nx <- 5\ny <- x\nx <- 10\nx <- 5\ny <- x\nx <- 10\ny## [1] 5"},{"path":"manipulating-tabular-data.html","id":"manipulating-tabular-data","chapter":"4 Manipulating Tabular Data","heading":"4 Manipulating Tabular Data","text":"","code":""},{"path":"manipulating-tabular-data.html","id":"learning-objectives-4","chapter":"4 Manipulating Tabular Data","heading":"4.1 Learning Objectives","text":"Import CSV data R.Understand difference base R tidyverse approaches.Subset rows columns data.frames.Use pipes link steps together pipelines.Create new data.frame columns using existing columns.Utilize concept split-apply-combine data analysis.Reshape data wide long formats.Export data CSV file.","code":"\nlibrary(tidyverse)"},{"path":"manipulating-tabular-data.html","id":"importing-data","chapter":"4 Manipulating Tabular Data","heading":"4.2 Importing data","text":"point, working complete_old dataframe contained ratdat package. However, typically won’t access data R package; much common access data files stored somewhere computer. going download CSV file containing surveys data computer, read R.Click link download file: https://datacarpentry.org/R-ecology-lesson/data/cleaned/surveys_complete_77_89.csv.prompted save file computer somewhere. Save inside cleaned data folder, data folder R-Ecology-Workshop folder. ’s inside project, able point R towards .","code":""},{"path":"manipulating-tabular-data.html","id":"file-paths","chapter":"4 Manipulating Tabular Data","heading":"4.2.0.1 File paths","text":"reference files R script, need give R precise instructions files . using something called file path. looks something like : \"Documents/Manuscripts/Chapter_2.txt\". path tell computer get whatever folder contains Documents folder way .txt file.two kinds paths: absolute relative. Absolute paths specific particular computer, whereas relative paths relative certain folder. keeping work R-Ecology-Workshop folder, paths can relative folder.Now, let’s read CSV file R store object named surveys. use read_csv function tidyverse’s readr package, argument give relative path CSV file.Typing paths can error prone, can utilize keyboard shortcut. Inside parentheses read_csv(), type pair quotes put cursor . hit Tab. small menu showing folders files show . can use ↑ ↓ keys move options, start typing narrow . can hit Enter select file folder, hit Tab continue building file path. might take bit getting used , get hang , speed writing file paths reduce number mistakes make.may noticed bit feedback R ran last line code. got useful information CSV file read . can see:number rows columnsthe delimiter file, values separated, comma \",\"set columns parsed various vector types\nfile 6 character columns 7 numeric columns\ncan see names columns type\nfile 6 character columns 7 numeric columnswe can see names columns typeWhen working output new function, ’s often good idea check class():Whoa! thing? multiple classes? Well, ’s called tibble, tidyverse version data.frame. data.frame, added perks. prints little nicely, highlights NA values negative values red, generally communicate (terms warnings errors, good thing).tidyverse vs. base RAs begin delve deeply tidyverse, briefly pause mention reasons focusing tidyverse set tools. R, often many ways get job done, approaches can accomplish tasks similar tidyverse.phrase base R used refer approaches utilize functions contained R’s default packages. already used base R functions, str(), head(), mean(), using scattered throughout lesson. However, key base R approaches teaching. include square bracket subsetting base plotting. may come across code written people looks like surveys[1:10, 2] plot(surveys$weight, surveys$hindfoot_length), base R commands. ’re interested learning approaches, can check Carpentries lessons like Software Carpentry Programming R lesson.choose teach tidyverse set packages share similar syntax philosophy, making consistent producing highly readable code. also flexible powerful, growing number packages designed according similar principles work well rest packages. tidyverse packages tend clear documentation wide array learning materials tend written novice users mind. Finally, tidyverse continued grow, strong support RStudio, implies approaches relevant future.","code":"\nsurveys <- read_csv(\"data/surveys_complete_77_89.csv\")## Rows: 16878 Columns: 13\n## ── Column specification ──────────────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (6): species_id, sex, genus, species, taxa, plot_type\n## dbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nclass(surveys)## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""},{"path":"manipulating-tabular-data.html","id":"manipulating-data","chapter":"4 Manipulating Tabular Data","heading":"4.3 Manipulating data","text":"One important skills working data R ability manipulate, modify, reshape data. dplyr tidyr packages tidyverse provide series powerful functions many common data manipulation tasks.’ll start two commonly used dplyr functions: select(), selects certain columns data.frame, filter(), filters rows according certain criteria.select() filter(), can hard remember operates columns operates rows. select() c columns filter() r rows.","code":""},{"path":"manipulating-tabular-data.html","id":"select","chapter":"4 Manipulating Tabular Data","heading":"4.3.0.1 select()","text":"use select() function, first argument name data.frame, rest arguments unquoted names columns want:columns arranged order specified inside select().select columns except specific columns, put - front column want exclude:select() also works numeric vectors order columns. select 3rd, 4th, 5th, 10th columns, run following code:careful using method, since less explicit columns want. However, can useful data.frame many columns don’t want type many names.Finally, can select columns based whether match certain criteria using () function. want numeric columns, can ask select columns class numeric:Instead giving names positions columns, instead pass () function name another function inside , case .numeric(), get columns function returns TRUE.can use select columns NA values :","code":"\nselect(surveys, plot_id, species_id, hindfoot_length)## # A tibble: 16,878 × 3\n##    plot_id species_id hindfoot_length\n##      <dbl> <chr>                <dbl>\n##  1       2 NL                      32\n##  2       3 NL                      33\n##  3       2 DM                      37\n##  4       7 DM                      36\n##  5       3 DM                      35\n##  6       1 PF                      14\n##  7       2 PE                      NA\n##  8       1 DM                      37\n##  9       1 DM                      34\n## 10       6 PF                      20\n## # ℹ 16,868 more rows\nselect(surveys, -record_id, -year)## # A tibble: 16,878 × 11\n##    month   day plot_id species_id sex   hindfoot_length weight genus     species\n##    <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl> <chr>     <chr>  \n##  1     7    16       2 NL         M                  32     NA Neotoma   albigu…\n##  2     7    16       3 NL         M                  33     NA Neotoma   albigu…\n##  3     7    16       2 DM         F                  37     NA Dipodomys merria…\n##  4     7    16       7 DM         M                  36     NA Dipodomys merria…\n##  5     7    16       3 DM         M                  35     NA Dipodomys merria…\n##  6     7    16       1 PF         M                  14     NA Perognat… flavus \n##  7     7    16       2 PE         F                  NA     NA Peromysc… eremic…\n##  8     7    16       1 DM         M                  37     NA Dipodomys merria…\n##  9     7    16       1 DM         F                  34     NA Dipodomys merria…\n## 10     7    16       6 PF         F                  20     NA Perognat… flavus \n## # ℹ 16,868 more rows\n## # ℹ 2 more variables: taxa <chr>, plot_type <chr>\nselect(surveys, c(3:5, 10))## # A tibble: 16,878 × 4\n##      day  year plot_id genus      \n##    <dbl> <dbl>   <dbl> <chr>      \n##  1    16  1977       2 Neotoma    \n##  2    16  1977       3 Neotoma    \n##  3    16  1977       2 Dipodomys  \n##  4    16  1977       7 Dipodomys  \n##  5    16  1977       3 Dipodomys  \n##  6    16  1977       1 Perognathus\n##  7    16  1977       2 Peromyscus \n##  8    16  1977       1 Dipodomys  \n##  9    16  1977       1 Dipodomys  \n## 10    16  1977       6 Perognathus\n## # ℹ 16,868 more rows\nselect(surveys, where(is.numeric))## # A tibble: 16,878 × 7\n##    record_id month   day  year plot_id hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl>           <dbl>  <dbl>\n##  1         1     7    16  1977       2              32     NA\n##  2         2     7    16  1977       3              33     NA\n##  3         3     7    16  1977       2              37     NA\n##  4         4     7    16  1977       7              36     NA\n##  5         5     7    16  1977       3              35     NA\n##  6         6     7    16  1977       1              14     NA\n##  7         7     7    16  1977       2              NA     NA\n##  8         8     7    16  1977       1              37     NA\n##  9         9     7    16  1977       1              34     NA\n## 10        10     7    16  1977       6              20     NA\n## # ℹ 16,868 more rows\nselect(surveys, where(anyNA))## # A tibble: 16,878 × 7\n##    species_id sex   hindfoot_length weight genus       species  taxa  \n##    <chr>      <chr>           <dbl>  <dbl> <chr>       <chr>    <chr> \n##  1 NL         M                  32     NA Neotoma     albigula Rodent\n##  2 NL         M                  33     NA Neotoma     albigula Rodent\n##  3 DM         F                  37     NA Dipodomys   merriami Rodent\n##  4 DM         M                  36     NA Dipodomys   merriami Rodent\n##  5 DM         M                  35     NA Dipodomys   merriami Rodent\n##  6 PF         M                  14     NA Perognathus flavus   Rodent\n##  7 PE         F                  NA     NA Peromyscus  eremicus Rodent\n##  8 DM         M                  37     NA Dipodomys   merriami Rodent\n##  9 DM         F                  34     NA Dipodomys   merriami Rodent\n## 10 PF         F                  20     NA Perognathus flavus   Rodent\n## # ℹ 16,868 more rows"},{"path":"manipulating-tabular-data.html","id":"filter","chapter":"4 Manipulating Tabular Data","heading":"4.3.0.2 filter()","text":"filter() function used select rows meet certain criteria. get rows value year equal 1985, run following:== sign means “equal ”. several operators can use: >, >=, <, <=, != (equal ). Another useful operator %%, asks value lefthand side found anywhere vector righthand side. example, get rows specific species_id values, run:can also use multiple conditions one filter() statement. get rows year less equal 1988 whose hindfoot length values NA. ! .na() function means “”.","code":"\nfilter(surveys, year == 1985)## # A tibble: 1,438 × 13\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1      9790     1    19  1985      16 RM         F                  16      4\n##  2      9791     1    19  1985      17 OT         F                  20     16\n##  3      9792     1    19  1985       6 DO         M                  35     48\n##  4      9793     1    19  1985      12 DO         F                  35     40\n##  5      9794     1    19  1985      24 RM         M                  16      4\n##  6      9795     1    19  1985      12 DO         M                  34     48\n##  7      9796     1    19  1985       6 DM         F                  37     35\n##  8      9797     1    19  1985      14 DM         M                  36     45\n##  9      9798     1    19  1985       6 DM         F                  36     38\n## 10      9799     1    19  1985      19 RM         M                  16      4\n## # ℹ 1,428 more rows\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\nfilter(surveys, species_id %in% c(\"RM\", \"DO\"))## # A tibble: 2,835 × 13\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1        68     8    19  1977       8 DO         F                  32     52\n##  2       292    10    17  1977       3 DO         F                  36     33\n##  3       294    10    17  1977       3 DO         F                  37     50\n##  4       311    10    17  1977      19 RM         M                  18     13\n##  5       317    10    17  1977      17 DO         F                  32     48\n##  6       323    10    17  1977      17 DO         F                  33     31\n##  7       337    10    18  1977       8 DO         F                  35     41\n##  8       356    11    12  1977       1 DO         F                  32     44\n##  9       378    11    12  1977       1 DO         M                  33     48\n## 10       397    11    13  1977      17 RM         F                  16      7\n## # ℹ 2,825 more rows\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\nfilter(surveys, year <= 1988 & !is.na(hindfoot_length))## # A tibble: 12,779 × 13\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         8     7    16  1977       1 DM         M                  37     NA\n##  8         9     7    16  1977       1 DM         F                  34     NA\n##  9        10     7    16  1977       6 PF         F                  20     NA\n## 10        11     7    16  1977       5 DS         F                  53     NA\n## # ℹ 12,769 more rows\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>"},{"path":"manipulating-tabular-data.html","id":"challenge-1-filtering-and-selecting","chapter":"4 Manipulating Tabular Data","heading":"4.4 Challenge 1: Filtering and selecting","text":"Use surveys data make data.frame data years 1980 1985.Solution. Use surveys data make data.frame following columns, order: year, month, species_id, plot_id.Solution. ","code":"\nsurveys_filtered <- filter(surveys, year >= 1980 & year <= 1985)\nsurveys_selected <- select(surveys, year, month, species_id, plot_id)"},{"path":"manipulating-tabular-data.html","id":"the-pipe","chapter":"4 Manipulating Tabular Data","heading":"4.5 The pipe: %>%","text":"happens want select() filter() data? couple options. First, use nested functions:R evaluate statements inside . First, select() operate surveys data.frame, removing column day. resulting data.frame used first argument filter(), selects rows month greater equal 7.Nested functions can difficult read functions, nearly impossible many functions done . alternative approach create intermediate objects:approach easier read, since can see steps order, enough steps, left cluttered mess intermediate objects, often confusing names.elegant solution problem operator called pipe, looks like %>%. can insert using keyboard shortcut Shift+Cmd+M (Mac) Shift+Ctrl+M (Windows). ’s use pipe select filter one step:take thing lefthand side insert first argument function righthand side. putting functions onto new line, can build nice, readable pipeline. can useful think little assembly line data. starts top gets piped select() function, comes modified somewhat. gets sent filter() function, modified, final product gets printed console. can also helpful think %>% meaning “”. Since many tidyverse functions verbs names, pipeline can read like sentence.’s worth showing learners can run pipeline without highlighting whole thing. cursor line pipeline, running line run whole thing.can also show highlighting section pipeline, can run first X steps .want store final product object, use assignment arrow start:good approach build pipeline step step prior assignment. add functions pipeline go, results printing console view. ’re satisfied final result, go back add assignment arrow statement start. approach interactive, allowing see results step build pipeline, produces nicely readable code.","code":"\nfilter(select(surveys, -day), month >= 7)## # A tibble: 8,244 × 12\n##    record_id month  year plot_id species_id sex   hindfoot_length weight genus  \n##        <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl> <chr>  \n##  1         1     7  1977       2 NL         M                  32     NA Neotoma\n##  2         2     7  1977       3 NL         M                  33     NA Neotoma\n##  3         3     7  1977       2 DM         F                  37     NA Dipodo…\n##  4         4     7  1977       7 DM         M                  36     NA Dipodo…\n##  5         5     7  1977       3 DM         M                  35     NA Dipodo…\n##  6         6     7  1977       1 PF         M                  14     NA Perogn…\n##  7         7     7  1977       2 PE         F                  NA     NA Peromy…\n##  8         8     7  1977       1 DM         M                  37     NA Dipodo…\n##  9         9     7  1977       1 DM         F                  34     NA Dipodo…\n## 10        10     7  1977       6 PF         F                  20     NA Perogn…\n## # ℹ 8,234 more rows\n## # ℹ 3 more variables: species <chr>, taxa <chr>, plot_type <chr>\nsurveys_noday <- select(surveys, -day)\nfilter(surveys_noday, month >= 7)## # A tibble: 8,244 × 12\n##    record_id month  year plot_id species_id sex   hindfoot_length weight genus  \n##        <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl> <chr>  \n##  1         1     7  1977       2 NL         M                  32     NA Neotoma\n##  2         2     7  1977       3 NL         M                  33     NA Neotoma\n##  3         3     7  1977       2 DM         F                  37     NA Dipodo…\n##  4         4     7  1977       7 DM         M                  36     NA Dipodo…\n##  5         5     7  1977       3 DM         M                  35     NA Dipodo…\n##  6         6     7  1977       1 PF         M                  14     NA Perogn…\n##  7         7     7  1977       2 PE         F                  NA     NA Peromy…\n##  8         8     7  1977       1 DM         M                  37     NA Dipodo…\n##  9         9     7  1977       1 DM         F                  34     NA Dipodo…\n## 10        10     7  1977       6 PF         F                  20     NA Perogn…\n## # ℹ 8,234 more rows\n## # ℹ 3 more variables: species <chr>, taxa <chr>, plot_type <chr>\nsurveys %>% \n  select(-day) %>% \n  filter(month >= 7)## # A tibble: 8,244 × 12\n##    record_id month  year plot_id species_id sex   hindfoot_length weight genus  \n##        <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl> <chr>  \n##  1         1     7  1977       2 NL         M                  32     NA Neotoma\n##  2         2     7  1977       3 NL         M                  33     NA Neotoma\n##  3         3     7  1977       2 DM         F                  37     NA Dipodo…\n##  4         4     7  1977       7 DM         M                  36     NA Dipodo…\n##  5         5     7  1977       3 DM         M                  35     NA Dipodo…\n##  6         6     7  1977       1 PF         M                  14     NA Perogn…\n##  7         7     7  1977       2 PE         F                  NA     NA Peromy…\n##  8         8     7  1977       1 DM         M                  37     NA Dipodo…\n##  9         9     7  1977       1 DM         F                  34     NA Dipodo…\n## 10        10     7  1977       6 PF         F                  20     NA Perogn…\n## # ℹ 8,234 more rows\n## # ℹ 3 more variables: species <chr>, taxa <chr>, plot_type <chr>\nsurveys_sub <- surveys %>% \n  select(-day) %>% \n  filter(month >= 7)"},{"path":"manipulating-tabular-data.html","id":"challenge-2-using-pipes","chapter":"4 Manipulating Tabular Data","heading":"4.6 Challenge 2: Using pipes","text":"Use surveys data make data.frame columns record_id, month, species_id, data year 1988. Use pipe function calls.Solution. Make sure filter() select(). need use year column filtering rows, discarded select() step. also need make sure use == instead = filtering rows year equal 1988.","code":"\nsurveys_1988 <- surveys %>%\n  filter(year == 1988) %>%\n  select(record_id, month, species_id)"},{"path":"manipulating-tabular-data.html","id":"making-new-columns-with-mutate","chapter":"4 Manipulating Tabular Data","heading":"4.7 Making new columns with mutate()","text":"Another common task creating new column based values existing columns. example, add new column weight kilograms instead grams:can create multiple columns one mutate() call, get created order write . means can even reference first new column second new column:can also use multiple columns create single column. example, ’s often good practice keep components date separate columns necessary, ’ve done . programs like Excel can automatic things dates way reproducible sometimes hard notice. However, now working R, can safely put together date column.put together columns something looks like date, can use paste() function, takes arguments items paste together, well argument sep, character used separate items.Since new column gets moved way end, doesn’t end printing . can use relocate() function put year column:Now can see character column contains date string. However, ’s truly date column. Dates type numeric variable defined, ordered scale. turn column proper date, use function tidyverse’s lubridate package, lots useful functions working dates. function ymd() parse date string order year-month-day. Let’s load package use ymd().Now can see date column type date well. example, created column two separate lines mutate(), can combine one:","code":"\nsurveys %>% \n  mutate(weight_kg = weight / 1000)## # A tibble: 16,878 × 14\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 16,868 more rows\n## # ℹ 5 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>,\n## #   weight_kg <dbl>\nsurveys %>% \n  mutate(weight_kg = weight / 1000,\n         weight_lbs = weight_kg * 2.2)## # A tibble: 16,878 × 15\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 16,868 more rows\n## # ℹ 6 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>,\n## #   weight_kg <dbl>, weight_lbs <dbl>\nsurveys %>% \n  mutate(date = paste(year, month, day, sep = \"-\"))## # A tibble: 16,878 × 14\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 16,868 more rows\n## # ℹ 5 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>,\n## #   date <chr>\nsurveys %>% \n  mutate(date = paste(year, month, day, sep = \"-\")) %>% \n  relocate(date, .after = year)## # A tibble: 16,878 × 14\n##    record_id month   day  year date     plot_id species_id sex   hindfoot_length\n##        <dbl> <dbl> <dbl> <dbl> <chr>      <dbl> <chr>      <chr>           <dbl>\n##  1         1     7    16  1977 1977-7-…       2 NL         M                  32\n##  2         2     7    16  1977 1977-7-…       3 NL         M                  33\n##  3         3     7    16  1977 1977-7-…       2 DM         F                  37\n##  4         4     7    16  1977 1977-7-…       7 DM         M                  36\n##  5         5     7    16  1977 1977-7-…       3 DM         M                  35\n##  6         6     7    16  1977 1977-7-…       1 PF         M                  14\n##  7         7     7    16  1977 1977-7-…       2 PE         F                  NA\n##  8         8     7    16  1977 1977-7-…       1 DM         M                  37\n##  9         9     7    16  1977 1977-7-…       1 DM         F                  34\n## 10        10     7    16  1977 1977-7-…       6 PF         F                  20\n## # ℹ 16,868 more rows\n## # ℹ 5 more variables: weight <dbl>, genus <chr>, species <chr>, taxa <chr>,\n## #   plot_type <chr>\nlibrary(lubridate)\n\nsurveys %>% \n  mutate(date = paste(year, month, day, sep = \"-\"),\n         date = ymd(date)) %>% \n  relocate(date, .after = year)## # A tibble: 16,878 × 14\n##    record_id month   day  year date       plot_id species_id sex  \n##        <dbl> <dbl> <dbl> <dbl> <date>       <dbl> <chr>      <chr>\n##  1         1     7    16  1977 1977-07-16       2 NL         M    \n##  2         2     7    16  1977 1977-07-16       3 NL         M    \n##  3         3     7    16  1977 1977-07-16       2 DM         F    \n##  4         4     7    16  1977 1977-07-16       7 DM         M    \n##  5         5     7    16  1977 1977-07-16       3 DM         M    \n##  6         6     7    16  1977 1977-07-16       1 PF         M    \n##  7         7     7    16  1977 1977-07-16       2 PE         F    \n##  8         8     7    16  1977 1977-07-16       1 DM         M    \n##  9         9     7    16  1977 1977-07-16       1 DM         F    \n## 10        10     7    16  1977 1977-07-16       6 PF         F    \n## # ℹ 16,868 more rows\n## # ℹ 6 more variables: hindfoot_length <dbl>, weight <dbl>, genus <chr>,\n## #   species <chr>, taxa <chr>, plot_type <chr>\nsurveys %>% \n  mutate(date = paste(year, month, day, sep = \"-\"),\n         date = as.Date(date)) %>% \n  relocate(date, .after = year)## # A tibble: 16,878 × 14\n##    record_id month   day  year date       plot_id species_id sex  \n##        <dbl> <dbl> <dbl> <dbl> <date>       <dbl> <chr>      <chr>\n##  1         1     7    16  1977 1977-07-16       2 NL         M    \n##  2         2     7    16  1977 1977-07-16       3 NL         M    \n##  3         3     7    16  1977 1977-07-16       2 DM         F    \n##  4         4     7    16  1977 1977-07-16       7 DM         M    \n##  5         5     7    16  1977 1977-07-16       3 DM         M    \n##  6         6     7    16  1977 1977-07-16       1 PF         M    \n##  7         7     7    16  1977 1977-07-16       2 PE         F    \n##  8         8     7    16  1977 1977-07-16       1 DM         M    \n##  9         9     7    16  1977 1977-07-16       1 DM         F    \n## 10        10     7    16  1977 1977-07-16       6 PF         F    \n## # ℹ 16,868 more rows\n## # ℹ 6 more variables: hindfoot_length <dbl>, weight <dbl>, genus <chr>,\n## #   species <chr>, taxa <chr>, plot_type <chr>\n# using nested functions\nsurveys %>% \n  mutate(date = ymd(paste(year, month, day, sep = \"-\"))) %>% \n  relocate(date, .after = year)## # A tibble: 16,878 × 14\n##    record_id month   day  year date       plot_id species_id sex  \n##        <dbl> <dbl> <dbl> <dbl> <date>       <dbl> <chr>      <chr>\n##  1         1     7    16  1977 1977-07-16       2 NL         M    \n##  2         2     7    16  1977 1977-07-16       3 NL         M    \n##  3         3     7    16  1977 1977-07-16       2 DM         F    \n##  4         4     7    16  1977 1977-07-16       7 DM         M    \n##  5         5     7    16  1977 1977-07-16       3 DM         M    \n##  6         6     7    16  1977 1977-07-16       1 PF         M    \n##  7         7     7    16  1977 1977-07-16       2 PE         F    \n##  8         8     7    16  1977 1977-07-16       1 DM         M    \n##  9         9     7    16  1977 1977-07-16       1 DM         F    \n## 10        10     7    16  1977 1977-07-16       6 PF         F    \n## # ℹ 16,868 more rows\n## # ℹ 6 more variables: hindfoot_length <dbl>, weight <dbl>, genus <chr>,\n## #   species <chr>, taxa <chr>, plot_type <chr>\n# using a pipe *inside* mutate()\nsurveys %>% \n  mutate(date = paste(year, month, day, \n                      sep = \"-\") %>% ymd()) %>% \n  relocate(date, .after = year)## # A tibble: 16,878 × 14\n##    record_id month   day  year date       plot_id species_id sex  \n##        <dbl> <dbl> <dbl> <dbl> <date>       <dbl> <chr>      <chr>\n##  1         1     7    16  1977 1977-07-16       2 NL         M    \n##  2         2     7    16  1977 1977-07-16       3 NL         M    \n##  3         3     7    16  1977 1977-07-16       2 DM         F    \n##  4         4     7    16  1977 1977-07-16       7 DM         M    \n##  5         5     7    16  1977 1977-07-16       3 DM         M    \n##  6         6     7    16  1977 1977-07-16       1 PF         M    \n##  7         7     7    16  1977 1977-07-16       2 PE         F    \n##  8         8     7    16  1977 1977-07-16       1 DM         M    \n##  9         9     7    16  1977 1977-07-16       1 DM         F    \n## 10        10     7    16  1977 1977-07-16       6 PF         F    \n## # ℹ 16,868 more rows\n## # ℹ 6 more variables: hindfoot_length <dbl>, weight <dbl>, genus <chr>,\n## #   species <chr>, taxa <chr>, plot_type <chr>"},{"path":"manipulating-tabular-data.html","id":"challenge-3-plotting-date","chapter":"4 Manipulating Tabular Data","heading":"4.8 Challenge 3: Plotting date","text":"ggplot() function takes data first argument, can actually pipe data straight ggplot(). Try building pipeline creates date column plots weight across date.Solution. isn’t necessarily useful plot, learn techniques help produce nice time series plots","code":"\nsurveys %>% \n  mutate(date = ymd(paste(year, month, day, sep = \"-\"))) %>% \n  ggplot(aes(x = date, y = weight)) +\n  geom_jitter(alpha = 0.1)## Warning: Removed 1692 rows containing missing values or values outside the scale range\n## (`geom_point()`)."},{"path":"manipulating-tabular-data.html","id":"the-split-apply-combine-approach","chapter":"4 Manipulating Tabular Data","heading":"4.9 The split-apply-combine approach","text":"Many data analysis tasks can achieved using split-apply-combine approach: split data groups, apply analysis group, combine results way. dplyr convenient functions enable approach, main two group_by() summarize().group_by() takes data.frame name one columns categorical values define groups. summarize() collapses group one-row summary group, giving back data.frame one row per group. syntax summarize() similar mutate(), define new columns based values columns. Let’s try calculating mean weight animals sex.can see mean weight males slightly higher females, animals whose sex unknown much higher weights. probably due small sample size, check sure. Like mutate(), can define multiple columns one summarize() call. function n() count number rows group.often want create groups based multiple columns. example, might interested mean weight every species + sex combination. add another column group_by() call.resulting data.frame much larger, since greater number groups. also see strange value showing mean_weight column: NaN. stands “Number”, often results trying operation vector zero entries. can vector zero entries? Well, particular group (like AB species ID + NA sex group) NA values weight, na.rm = T argument mean() remove values prior calculating mean. result value NaN. Since particularly interested values, let’s add step pipeline remove rows weight NA steps. means groups NA values disappear data.frame formally create groups group_by().looks better! ’s often useful take look results order, like lowest mean weight highest. can use arrange() function :want reverse order, can wrap column name desc():may seen several messages saying summarise() grouped output 'species_id'. can override using .groups argument. warning resulting data.frame retained group structure, means subsequent operations data.frame happen group level. look resulting data.frame printed console, see lines:tell us data.frame 46 rows, 4 columns, group variable species_id, 18 groups. see something similar use group_by() alone:get back entire surveys data.frame, grouping variables added: 67 groups species_id + sex combinations. Groups often maintained throughout pipeline, assign resulting data.frame new object, also groups. can lead confusing results forget grouping want carry operations whole data.frame, group. Therefore, good habit remove groups end pipeline containing group_by():Now data.frame just says # tibble: 46 × 4 top, groups.common want get one-row-per-group summary summarise() provides, times want calculate per-group value keep rows data.frame. example, might want know mean weight species ID + sex combination, might want know far mean value observation group . , can use group_by() mutate() together:Since get columns back, new columns end don’t print console. Let’s use select() just look columns interest. Inside select() can use contains() function get column containing word “weight” name:happens group_by() + mutate() combination similar using summarize(): group, mean weight calculated. However, instead reporting one row per group, mean weight group added row group. row group (like DM species ID + M sex), see value mean_weight.","code":"\nsurveys %>% \n  group_by(sex) %>% \n  summarize(mean_weight = mean(weight, na.rm = T))## # A tibble: 3 × 2\n##   sex   mean_weight\n##   <chr>       <dbl>\n## 1 F            53.1\n## 2 M            53.2\n## 3 <NA>         74.0\nsurveys %>% \n  group_by(sex) %>% \n  summarize(mean_weight = mean(weight, na.rm = T),\n            n = n())## # A tibble: 3 × 3\n##   sex   mean_weight     n\n##   <chr>       <dbl> <int>\n## 1 F            53.1  7318\n## 2 M            53.2  8260\n## 3 <NA>         74.0  1300\nsurveys %>% \n  group_by(species_id, sex) %>% \n  summarize(mean_weight = mean(weight, na.rm = T),\n            n = n())## `summarise()` has grouped output by 'species_id'. You can override using the `.groups`\n## argument.## # A tibble: 67 × 4\n## # Groups:   species_id [36]\n##    species_id sex   mean_weight     n\n##    <chr>      <chr>       <dbl> <int>\n##  1 AB         <NA>        NaN     223\n##  2 AH         <NA>        NaN     136\n##  3 BA         M             7       3\n##  4 CB         <NA>        NaN      23\n##  5 CM         <NA>        NaN      13\n##  6 CQ         <NA>        NaN      16\n##  7 CS         <NA>        NaN       1\n##  8 CV         <NA>        NaN       1\n##  9 DM         F            40.7  2522\n## 10 DM         M            44.0  3108\n## # ℹ 57 more rows\nsurveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, sex) %>% \n  summarize(mean_weight = mean(weight),\n            n = n())## `summarise()` has grouped output by 'species_id'. You can override using the `.groups`\n## argument.## # A tibble: 46 × 4\n## # Groups:   species_id [18]\n##    species_id sex   mean_weight     n\n##    <chr>      <chr>       <dbl> <int>\n##  1 BA         M             7       3\n##  2 DM         F            40.7  2460\n##  3 DM         M            44.0  3013\n##  4 DM         <NA>         37       8\n##  5 DO         F            48.4   679\n##  6 DO         M            49.3   748\n##  7 DO         <NA>         44       1\n##  8 DS         F           118.   1055\n##  9 DS         M           123.   1184\n## 10 DS         <NA>        121.     16\n## # ℹ 36 more rows\nsurveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, sex) %>% \n  summarize(mean_weight = mean(weight),\n            n = n()) %>% \n  arrange(mean_weight)## `summarise()` has grouped output by 'species_id'. You can override using the `.groups`\n## argument.## # A tibble: 46 × 4\n## # Groups:   species_id [18]\n##    species_id sex   mean_weight     n\n##    <chr>      <chr>       <dbl> <int>\n##  1 PF         <NA>         6        2\n##  2 BA         M            7        3\n##  3 PF         F            7.09   215\n##  4 PF         M            7.10   296\n##  5 RM         M            9.92   678\n##  6 RM         <NA>        10.4      7\n##  7 RM         F           10.7    629\n##  8 RF         M           12.4     16\n##  9 RF         F           13.7     46\n## 10 PP         <NA>        15        2\n## # ℹ 36 more rows\nsurveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, sex) %>% \n  summarize(mean_weight = mean(weight),\n            n = n()) %>% \n  arrange(desc(mean_weight))## `summarise()` has grouped output by 'species_id'. You can override using the `.groups`\n## argument.## # A tibble: 46 × 4\n## # Groups:   species_id [18]\n##    species_id sex   mean_weight     n\n##    <chr>      <chr>       <dbl> <int>\n##  1 NL         M           168.    355\n##  2 NL         <NA>        164.      9\n##  3 NL         F           151.    460\n##  4 SS         M           130       1\n##  5 DS         M           123.   1184\n##  6 DS         <NA>        121.     16\n##  7 DS         F           118.   1055\n##  8 SH         F            79.2    61\n##  9 SH         M            67.6    34\n## 10 SF         F            58.3     3\n## # ℹ 36 more rows# A tibble: 46 × 4\n# Groups:   species_id [18]\nsurveys %>% \n  group_by(species_id, sex)## # A tibble: 16,878 × 13\n## # Groups:   species_id, sex [67]\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1         1     7    16  1977       2 NL         M                  32     NA\n##  2         2     7    16  1977       3 NL         M                  33     NA\n##  3         3     7    16  1977       2 DM         F                  37     NA\n##  4         4     7    16  1977       7 DM         M                  36     NA\n##  5         5     7    16  1977       3 DM         M                  35     NA\n##  6         6     7    16  1977       1 PF         M                  14     NA\n##  7         7     7    16  1977       2 PE         F                  NA     NA\n##  8         8     7    16  1977       1 DM         M                  37     NA\n##  9         9     7    16  1977       1 DM         F                  34     NA\n## 10        10     7    16  1977       6 PF         F                  20     NA\n## # ℹ 16,868 more rows\n## # ℹ 4 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>\nsurveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, sex) %>% \n  summarize(mean_weight = mean(weight),\n            n = n()) %>% \n  arrange(desc(mean_weight)) %>% \n  ungroup()## `summarise()` has grouped output by 'species_id'. You can override using the `.groups`\n## argument.## # A tibble: 46 × 4\n##    species_id sex   mean_weight     n\n##    <chr>      <chr>       <dbl> <int>\n##  1 NL         M           168.    355\n##  2 NL         <NA>        164.      9\n##  3 NL         F           151.    460\n##  4 SS         M           130       1\n##  5 DS         M           123.   1184\n##  6 DS         <NA>        121.     16\n##  7 DS         F           118.   1055\n##  8 SH         F            79.2    61\n##  9 SH         M            67.6    34\n## 10 SF         F            58.3     3\n## # ℹ 36 more rows\nsurveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, sex) %>% \n  mutate(mean_weight = mean(weight),\n            weight_diff = weight - mean_weight)## # A tibble: 15,186 × 15\n## # Groups:   species_id, sex [46]\n##    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n##        <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n##  1        63     8    19  1977       3 DM         M                  35     40\n##  2        64     8    19  1977       7 DM         M                  37     48\n##  3        65     8    19  1977       4 DM         F                  34     29\n##  4        66     8    19  1977       4 DM         F                  35     46\n##  5        67     8    19  1977       7 DM         M                  35     36\n##  6        68     8    19  1977       8 DO         F                  32     52\n##  7        69     8    19  1977       2 PF         M                  15      8\n##  8        70     8    19  1977       3 OX         F                  21     22\n##  9        71     8    19  1977       7 DM         F                  36     35\n## 10        74     8    19  1977       8 PF         M                  12      7\n## # ℹ 15,176 more rows\n## # ℹ 6 more variables: genus <chr>, species <chr>, taxa <chr>, plot_type <chr>,\n## #   mean_weight <dbl>, weight_diff <dbl>\nsurveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, sex) %>% \n  mutate(mean_weight = mean(weight),\n            weight_diff = weight - mean_weight) %>% \n  select(species_id, sex, contains(\"weight\"))## # A tibble: 15,186 × 5\n## # Groups:   species_id, sex [46]\n##    species_id sex   weight mean_weight weight_diff\n##    <chr>      <chr>  <dbl>       <dbl>       <dbl>\n##  1 DM         M         40       44.0      -4.00  \n##  2 DM         M         48       44.0       4.00  \n##  3 DM         F         29       40.7     -11.7   \n##  4 DM         F         46       40.7       5.28  \n##  5 DM         M         36       44.0      -8.00  \n##  6 DO         F         52       48.4       3.63  \n##  7 PF         M          8        7.10      0.902 \n##  8 OX         F         22       21         1     \n##  9 DM         F         35       40.7      -5.72  \n## 10 PF         M          7        7.10     -0.0980\n## # ℹ 15,176 more rows"},{"path":"manipulating-tabular-data.html","id":"challenge-4-making-a-time-series","chapter":"4 Manipulating Tabular Data","heading":"4.10 Challenge 4: Making a time series","text":"Use split-apply-combine approach make data.frame counts total number animals sex caught day surveys data.Solution. Now use data.frame just made plot daily number animals sex caught time. ’s geom use, line plot might good choice. also think differentiate data corresponds sex.Solution. ","code":"\nsurveys_daily_counts <- surveys %>% \n  mutate(date = ymd(paste(year, month, day, sep = \"-\"))) %>% \n  group_by(date, sex) %>% \n  summarize(n = n())## `summarise()` has grouped output by 'date'. You can override using the `.groups`\n## argument.\n# shorter approach using count()\nsurveys_daily_counts <- surveys %>% \n  mutate(date = ymd(paste(year, month, day, sep = \"-\"))) %>% \n  count(date, sex)\nsurveys_daily_counts %>% \n  ggplot(aes(x = date, y = n, color = sex)) +\n  geom_line()"},{"path":"manipulating-tabular-data.html","id":"reshaping-data-with-tidyr","chapter":"4 Manipulating Tabular Data","heading":"4.11 Reshaping data with tidyr","text":"Let’s say interested comparing mean weights species across different plots. can begin process using group_by() + summarize() approach:looks great, bit difficult compare values across plots. nice reshape data.frame make comparisons easier. Well, tidyr package tidyverse pair functions allow reshape data pivoting : pivot_wider() pivot_longer(). pivot_wider() make data wider, means increasing number columns reducing number rows. pivot_longer() opposite, reducing number columns increasing number rows.case, might nice create data.frame species row, plot column containing mean weight given species. use pivot_wider() reshape data way. takes 3 arguments:name data.framenames_from: column used generate names new columns?values_from: column used fill values new columns?columns used names_from values_from pivoted.case, want new columns named plot_id column, values coming mean_weight column. can pipe data.frame right pivot_wider() add two arguments:Now ’ve got reshaped data.frame. things notice. First, new column plot_id value. one old column left data.frame: species_id. wasn’t used pivot_wider(), stays, now contains single entry unique species_id value.Finally, lot NAs appeared. species aren’t found every plot, data.frame value every row every column, NA inserted. can double-check verify going .Looking new pivoted data.frame, can see NA value species BA plot 1. Let’s take sp_by_plot data.frame look mean_weight species + plot combination.get back 0 rows. mean_weight species BA plot 1. either happened BA ever caught plot 1, every BA caught plot 1 NA weight value rows got removed used filter(!.na(weight)) process making sp_by_plot. rows species + plot combination, pivoted data.frame, value gets filled NA.another pivot_ function opposite, moving data wide long format, called pivot_longer(). takes 3 arguments: cols columns want pivot, names_to name new column contain old column names, values_to name new column contain old values.can pivot new wide data.frame long format using pivot_longer(). want pivot columns except species_id, use PLOT new column plot IDs, MEAN_WT new column mean weight values.One thing notice NA values got generated pivoted wider. However, can filter , gets us back data sp_by_plot, pivoted wider.Data often recorded spreadsheets wider format, lots tidyverse tools, especially ggplot2, like data longer format, pivot_longer() often useful.","code":"\nsp_by_plot <- surveys %>% \n  filter(!is.na(weight)) %>% \n  group_by(species_id, plot_id) %>% \n  summarise(mean_weight = mean(weight)) %>% \n  arrange(species_id, plot_id)## `summarise()` has grouped output by 'species_id'. You can override using the `.groups`\n## argument.\nsp_by_plot## # A tibble: 300 × 3\n## # Groups:   species_id [18]\n##    species_id plot_id mean_weight\n##    <chr>        <dbl>       <dbl>\n##  1 BA               3         8  \n##  2 BA              21         6.5\n##  3 DM               1        42.7\n##  4 DM               2        42.6\n##  5 DM               3        41.2\n##  6 DM               4        41.9\n##  7 DM               5        42.6\n##  8 DM               6        42.1\n##  9 DM               7        43.2\n## 10 DM               8        43.4\n## # ℹ 290 more rows\nsp_by_plot_wide <- sp_by_plot %>% \n  pivot_wider(names_from = plot_id, \n              values_from = mean_weight)\n\nsp_by_plot_wide## # A tibble: 18 × 25\n## # Groups:   species_id [18]\n##    species_id    `3`   `21`    `1`    `2`    `4`   `5`    `6`   `7`    `8`\n##    <chr>       <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl> <dbl>  <dbl>\n##  1 BA           8      6.5   NA     NA     NA     NA    NA     NA    NA   \n##  2 DM          41.2   41.5   42.7   42.6   41.9   42.6  42.1   43.2  43.4 \n##  3 DO          42.7   NA     50.1   50.3   46.8   50.4  49.0   52    49.2 \n##  4 DS         128.    NA    129.   125.   118.   111.  114.   126.  128.  \n##  5 NL         171.   136.   154.   171.   164.   192.  176.   170.  134.  \n##  6 OL          32.1   28.6   35.5   34     33.0   32.6  31.8   NA    30.3 \n##  7 OT          24.1   24.1   23.7   24.9   26.5   23.6  23.5   22    24.1 \n##  8 OX          22     NA     NA     22     NA     20    NA     NA    NA   \n##  9 PE          22.7   19.6   21.6   22.0   NA     21    21.6   22.8  19.4 \n## 10 PF           7.12   7.23   6.57   6.89   6.75   7.5   7.54   7     6.78\n## 11 PH          28     31     NA     NA     NA     29    NA     NA    NA   \n## 12 PM          20.1   23.6   23.7   23.9   NA     23.7  22.3   23.4  23   \n## 13 PP          17.1   13.6   14.3   16.4   14.8   19.8  16.8   NA    13.9 \n## 14 RF          14.8   17     NA     16     NA     14    12.1   13    NA   \n## 15 RM          10.3    9.89  10.9   10.6   10.4   10.8  10.6   10.7   9   \n## 16 SF          NA     49     NA     NA     NA     NA    NA     NA    NA   \n## 17 SH          76.0   79.9   NA     88     NA     82.7  NA     NA    NA   \n## 18 SS          NA     NA     NA     NA     NA     NA    NA     NA    NA   \n## # ℹ 15 more variables: `9` <dbl>, `10` <dbl>, `11` <dbl>, `12` <dbl>,\n## #   `13` <dbl>, `14` <dbl>, `15` <dbl>, `16` <dbl>, `17` <dbl>, `18` <dbl>,\n## #   `19` <dbl>, `20` <dbl>, `22` <dbl>, `23` <dbl>, `24` <dbl>\nsp_by_plot %>% \n  filter(species_id == \"BA\" & plot_id == 1)## # A tibble: 0 × 3\n## # Groups:   species_id [0]\n## # ℹ 3 variables: species_id <chr>, plot_id <dbl>, mean_weight <dbl>\nsp_by_plot_wide %>% \n  pivot_longer(cols = -species_id, names_to = \"PLOT\", values_to = \"MEAN_WT\")## # A tibble: 432 × 3\n## # Groups:   species_id [18]\n##    species_id PLOT  MEAN_WT\n##    <chr>      <chr>   <dbl>\n##  1 BA         3         8  \n##  2 BA         21        6.5\n##  3 BA         1        NA  \n##  4 BA         2        NA  \n##  5 BA         4        NA  \n##  6 BA         5        NA  \n##  7 BA         6        NA  \n##  8 BA         7        NA  \n##  9 BA         8        NA  \n## 10 BA         9        NA  \n## # ℹ 422 more rows\nsp_by_plot_wide %>% \n  pivot_longer(cols = -species_id, names_to = \"PLOT\", values_to = \"MEAN_WT\") %>% \n  filter(!is.na(MEAN_WT))## # A tibble: 300 × 3\n## # Groups:   species_id [18]\n##    species_id PLOT  MEAN_WT\n##    <chr>      <chr>   <dbl>\n##  1 BA         3         8  \n##  2 BA         21        6.5\n##  3 DM         3        41.2\n##  4 DM         21       41.5\n##  5 DM         1        42.7\n##  6 DM         2        42.6\n##  7 DM         4        41.9\n##  8 DM         5        42.6\n##  9 DM         6        42.1\n## 10 DM         7        43.2\n## # ℹ 290 more rows"},{"path":"manipulating-tabular-data.html","id":"exporting-data","chapter":"4 Manipulating Tabular Data","heading":"4.12 Exporting data","text":"Let’s say want send wide version sb_by_plot data.frame colleague doesn’t use R. case, might want save CSV file.First, might want modify names columns, since right now bare numbers, aren’t informative. Luckily, pivot_wider() argument names_prefix allow us add “plot_” start column.looks better! Let’s save data.frame new object.Now can save data.frame CSV using write_csv() function readr package. first argument name data.frame, second path new file want create, including file extension .csv.go look data/cleaned_data folder, see new CSV file.use filter() subset rows select() subset columnsbuild pipelines one step time assigning resultit often best keep components dates separate needed, use mutate() make date columngroup_by() can used summarize() collapse rows mutate() keep number rowspivot_wider() pivot_longer() powerful reshaping data, plan use thoughtfully","code":"\nsp_by_plot %>% \n  pivot_wider(names_from = plot_id, values_from = mean_weight,\n              names_prefix = \"plot_\")## # A tibble: 18 × 25\n## # Groups:   species_id [18]\n##    species_id plot_3 plot_21 plot_1 plot_2 plot_4 plot_5 plot_6 plot_7 plot_8\n##    <chr>       <dbl>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n##  1 BA           8       6.5   NA     NA     NA      NA    NA      NA    NA   \n##  2 DM          41.2    41.5   42.7   42.6   41.9    42.6  42.1    43.2  43.4 \n##  3 DO          42.7    NA     50.1   50.3   46.8    50.4  49.0    52    49.2 \n##  4 DS         128.     NA    129.   125.   118.    111.  114.    126.  128.  \n##  5 NL         171.    136.   154.   171.   164.    192.  176.    170.  134.  \n##  6 OL          32.1    28.6   35.5   34     33.0    32.6  31.8    NA    30.3 \n##  7 OT          24.1    24.1   23.7   24.9   26.5    23.6  23.5    22    24.1 \n##  8 OX          22      NA     NA     22     NA      20    NA      NA    NA   \n##  9 PE          22.7    19.6   21.6   22.0   NA      21    21.6    22.8  19.4 \n## 10 PF           7.12    7.23   6.57   6.89   6.75    7.5   7.54    7     6.78\n## 11 PH          28      31     NA     NA     NA      29    NA      NA    NA   \n## 12 PM          20.1    23.6   23.7   23.9   NA      23.7  22.3    23.4  23   \n## 13 PP          17.1    13.6   14.3   16.4   14.8    19.8  16.8    NA    13.9 \n## 14 RF          14.8    17     NA     16     NA      14    12.1    13    NA   \n## 15 RM          10.3     9.89  10.9   10.6   10.4    10.8  10.6    10.7   9   \n## 16 SF          NA      49     NA     NA     NA      NA    NA      NA    NA   \n## 17 SH          76.0    79.9   NA     88     NA      82.7  NA      NA    NA   \n## 18 SS          NA      NA     NA     NA     NA      NA    NA      NA    NA   \n## # ℹ 15 more variables: plot_9 <dbl>, plot_10 <dbl>, plot_11 <dbl>,\n## #   plot_12 <dbl>, plot_13 <dbl>, plot_14 <dbl>, plot_15 <dbl>, plot_16 <dbl>,\n## #   plot_17 <dbl>, plot_18 <dbl>, plot_19 <dbl>, plot_20 <dbl>, plot_22 <dbl>,\n## #   plot_23 <dbl>, plot_24 <dbl>\nsurveys_sp <- sp_by_plot %>% \n  pivot_wider(names_from = plot_id, values_from = mean_weight,\n              names_prefix = \"plot_\")\n\nsurveys_sp## # A tibble: 18 × 25\n## # Groups:   species_id [18]\n##    species_id plot_3 plot_21 plot_1 plot_2 plot_4 plot_5 plot_6 plot_7 plot_8\n##    <chr>       <dbl>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n##  1 BA           8       6.5   NA     NA     NA      NA    NA      NA    NA   \n##  2 DM          41.2    41.5   42.7   42.6   41.9    42.6  42.1    43.2  43.4 \n##  3 DO          42.7    NA     50.1   50.3   46.8    50.4  49.0    52    49.2 \n##  4 DS         128.     NA    129.   125.   118.    111.  114.    126.  128.  \n##  5 NL         171.    136.   154.   171.   164.    192.  176.    170.  134.  \n##  6 OL          32.1    28.6   35.5   34     33.0    32.6  31.8    NA    30.3 \n##  7 OT          24.1    24.1   23.7   24.9   26.5    23.6  23.5    22    24.1 \n##  8 OX          22      NA     NA     22     NA      20    NA      NA    NA   \n##  9 PE          22.7    19.6   21.6   22.0   NA      21    21.6    22.8  19.4 \n## 10 PF           7.12    7.23   6.57   6.89   6.75    7.5   7.54    7     6.78\n## 11 PH          28      31     NA     NA     NA      29    NA      NA    NA   \n## 12 PM          20.1    23.6   23.7   23.9   NA      23.7  22.3    23.4  23   \n## 13 PP          17.1    13.6   14.3   16.4   14.8    19.8  16.8    NA    13.9 \n## 14 RF          14.8    17     NA     16     NA      14    12.1    13    NA   \n## 15 RM          10.3     9.89  10.9   10.6   10.4    10.8  10.6    10.7   9   \n## 16 SF          NA      49     NA     NA     NA      NA    NA      NA    NA   \n## 17 SH          76.0    79.9   NA     88     NA      82.7  NA      NA    NA   \n## 18 SS          NA      NA     NA     NA     NA      NA    NA      NA    NA   \n## # ℹ 15 more variables: plot_9 <dbl>, plot_10 <dbl>, plot_11 <dbl>,\n## #   plot_12 <dbl>, plot_13 <dbl>, plot_14 <dbl>, plot_15 <dbl>, plot_16 <dbl>,\n## #   plot_17 <dbl>, plot_18 <dbl>, plot_19 <dbl>, plot_20 <dbl>, plot_22 <dbl>,\n## #   plot_23 <dbl>, plot_24 <dbl>\nwrite_csv(surveys_sp, \"data/surveys_meanweight_species_plot.csv\")"},{"path":"conceptual-ecological-models.html","id":"conceptual-ecological-models","chapter":"5 Conceptual Ecological Models","heading":"5 Conceptual Ecological Models","text":"","code":""},{"path":"background-on-habitat-models-in-usace.html","id":"background-on-habitat-models-in-usace","chapter":"6 Background on habitat models in USACE","heading":"6 Background on habitat models in USACE","text":"INTRO HABITAT MODELS GENERAL; CONSIDER WHETHER PARE REMOVEAcross business lines, U.S. Army Corps Engineers (USACE) engages large variety decisions affect multitude ecological outcomes (e.g., ecosystem restoration oyster reefs, environmental flows imperiled fishes, bird breeding grounds impacted dredge material management). numerous aquatic, riparian, terrestrial analytical tools exist, ecological models typically easily accessible usable form field practitioners often require significant data modeling expertise effectively employ. However, ecological models must used quantify environmental impacts benefits throughout project life-cycle planning, engineering, construction, operations, maintenance.common approach ecological modeling environmental impacts benefits based quantity quality habitat. “index” models (Swannack et al. 2012) originally developed species-specific applications (e.g., slider turtles), general approach also adapted guilds (e.g., salmonids), communities (e.g., floodplain vegetation), ecosystem processes (e.g., Hydrogeomorphic Method). standard platform exists computing outcomes index models, users often develop ad hoc spreadsheet models, highly prone numerical errors (McKay 2009). common quantity-quality structure index models provides opportunity develop consistent, error-checked index modeling calculator adaptable variety applications across Corps.Furthermore, ecological modeling often seeks inform trade-offs monetary assessment social benefits costs (e.g., restoration investment cost economic damages avoided) non-monetary assessment environmental benefits costs (e.g., habitat gains restoration impact imperiled taxa’s habitat). Cost-effectiveness incremental cost analyses (CEICA) provide useful set techniques comparing non-monetary monetary costs benefits management actions (Robinson et al. 1995). CEICA commonly applied planning designing ecosystem restoration projects often coupled index models inform management decisions.","code":""},{"path":"background-on-habitat-models-in-usace.html","id":"index-based-ecological-models","chapter":"6 Background on habitat models in USACE","heading":"6.0.0.1 2.1. Index-Based Ecological Models","text":"Ecological models become common tools informing decisions related management complex ecological processes. Models span breadth potential ecological management applications seafood harvest limits, transport nutrients freshwaters, bioaccumulation contaminants, management imperiled taxa, wetland impact assessment. addition diverse outcomes, ecological models often take variety theoretical constructs ranging theoretical, analytical models statistical correlations variables agent-based simulations animal movement (See Swannack et al. 2012 review ecological model types). diversity ecological endpoints model constructs led wide array tools applicable ecosystem management restoration.Index models family techniques commonly applied planning ecosystem restoration projects. Briefly, index models quantitatively translate multiple features processes relative assessment habitat suitability given organism relative assessment ecosystem condition (Tirpak et al. 2009, Swannack et al. 2012). specifically, index models combine assessments habitat ecosystem quality quantity overarching metric assessing relative condition site (e.g., “habitat unit” “functional capacity unit”). Quantity commonly expressed metric area acres hectares; however, metrics may appropriate specific applications river length lake volume. Quality assessed identifying key variables correlated habitat ecosystem condition. variable translated suitability index curve, transforms dimensional quantities flow velocity dimensionless values quality (0 1 0 unsuitable/low condition 1 suitable/ideal condition). Multiple suitability curves combined various equational forms overarching assessment habitat quality (e.g., “habitat suitability index” “functional capacity index”).Index models may derived variety methods resources. Like models, many index model developers emphasized algorithms simplify complex ecosystems, thus, tools considered adaptable hypotheses rather mechanistic, cause-effect relationships. value index models lies utility quantitatively comparing relative merits alternative management actions testing hypotheses. following represent common sources index models applied USACE ecosystem restoration projects:U.S. Fish Wildlife Service (USFWS) Habitat Suitability Index (HSI) Models: HSI approach quantitatively relates potential species presence habitat characteristics. Species complex relationships environment, HSI models provide simple method characterizing potential habitat support target species across landscape. USFWS led development 500+ HSI models 1970-1980s support environmental management decisions nationwide (https://www.nwrc.usgs.gov/wdb/pub/hsi/hsiindex.htm). quantitative relationships species habitat generally based combination literature, field studies, expert opinion, reports colloquially referred “blue books” blue covers binding original publications.Hydrogeomorphic Method (HGM) Wetland Assessment: Similarly, HGM approach common technique rapidly assessing wetland function. HGM methodology model development thoroughly documented (Brinson 1993, Smith et al. 1995), models available 30+ wetland types nationwide (https://wetlands.el.erdc.dren.mil/guidebooks.cfm).Literature-Based Index Models: Index models also appear within peer-reviewed grey literature variety formats. original HSI models subsequently adapted local conditions updated new data became available (e.g., bluegill model Stuber et al. 1982 adapted Palesh Anderson 1990). Models also appear peer-reviewed literature new data become available, recent revision oyster suitability models expands breadth applicability (Swannack et al. 2014).Project- Objective-Centric Index Models: Specific restoration projects may build models unique set project objectives (McKay et al. 2019), can evolve project proceeds preliminary screening detailed alternatives analysis (e.g., McKay et al. 2018ab). recently, Carrillo et al. (2020) proposed Toolkit interActive Modeling (TAM), facilitates development index models real-time mediated modeling workshop settings (Herman et al. 2019).","code":""},{"path":"background-on-habitat-models-in-usace.html","id":"cost-effectiveness-and-incremental-cost-analysis-ceica","chapter":"6 Background on habitat models in USACE","heading":"6.0.0.2 2.2. Cost-Effectiveness and Incremental Cost Analysis (CEICA)","text":"USACE ecosystem restoration mission first authorized Water Resources Development Act 1986 stated purpose “…restore significant structure, function dynamic processes degraded” (USACE 1999, ER 1165-2-501). Given goal, USACE programs emphasize ecological outcomes (opposed social economic outcomes). Generally, ecological resources may quantified variety ways ranging habitat suitability focal taxa (e.g., endangered species) changes physical processes (e.g., sediment delivery geomorphic change) changes biological processes (e.g., carbon uptake storage). USACE business lines (e.g., navigation), costs benefits actions compared monetary terms, benefit-cost ratio serves crucial decision metric. However, outputs restoration typically monetized, different set methods required inform restoration decision-making address issue “ecosystem restoration worth Federal investment?” particular, cost-effectiveness incremental cost analyses provide techniques comparing non-monetary ecological benefits relative monetary costs restoration actions (Robinson et al. 1995).Cost-effectiveness incremental cost analyses (CEICA) analytical tools assessing relative benefits costs ecosystem restoration actions informing decisions. Benefits costs assessed prior analyses using ecological models (e.g., index models) cost engineering methods, respectively. CEICA may conducted site scale compare alternatives single location (e.g., action vs. dam removal vs. fish ladder) system scale compare relative merits multiple sites (e.g., sites vs. Site-vs. Site-B vs. Site-Site-B). Within USACE, Institute Water Resources provided toolkit conducting CEICA, IWR Planning Suite (http://www.iwr.usace.army.mil/Missions/Economics/IWR-Planning-Suite/).Cost-effectiveness analysis provides mechanism examining efficiency alternative actions. given level investment, agency wants identify plan return--investment (.e., environmental benefits), given level environmental benefits, agency wants plan least cost. “efficiency frontier” identifies plans efficiently provide benefits per cost basis (.e., cost-effective plans). “non-dominated” alternatives compose Pareto-optimal frontier.Incremental cost analysis conducted set cost-effective plans. technique sequentially compares plan higher cost plans reveal changes unit cost output levels increase eliminates plans efficiently provide benefits per unit cost basis. Specifically, analysis examines slope cost-effectiveness frontier isolate incremental unit cost ($/unit) increases magnitude environmental benefit increases. Incremental cost analysis ultimately intended inform decision-makers consequences increasing unit cost increasing benefits (.e., unit becomes expensive). Plans emerging incremental cost analysis efficiently accomplish objective relative unit costs typically referred “best buys”. Importantly, “best buys” cost-effective, cost-effective plans best buys.","code":""},{"path":"background-on-habitat-models-in-usace.html","id":"include-tam-model-here","chapter":"6 Background on habitat models in USACE","heading":"6.0.1 Include TAM model here?","text":"","code":""},{"path":"ecorest-web-app.html","id":"ecorest-web-app","chapter":"7 Ecorest Web App","heading":"7 Ecorest Web App","text":"STRICTLY USING R KEEP REMOVE","code":""},{"path":"ecorest-web-app.html","id":"purpose","chapter":"7 Ecorest Web App","heading":"7.1 Purpose","text":"user guide provides general information Habitat Suitability Index modeling Cost-Effective Incremental Cost Analysis, step--step guidance use ecorest webapp.","code":""},{"path":"ecorest-web-app.html","id":"introduction-to-hsi-and-ceica-tools","chapter":"7 Ecorest Web App","heading":"7.2 Introduction to HSI and CEICA Tools","text":"Ecosystem management projects often use ecological modeling quantify environmental impacts benefits alternative project scenarios assess current ecosystem condition. Cost-Effective Incremental Cost Analysis (CEICA) another management tool provides information efficiency alternative project scenarios produce environmental outputs monetary non-monetary costs outputs (Robinson et al. 1995). Ecological models CEICA often incorporated planning, design decision-informing steps restoration projects compare potential ecological economic outcomes series alternatives target project goals.Index models type ecological model commonly used environmental assessments restoration projects. Index models combine habitat ecosystem quality sometimes quantity metric assessing habitat condition. output habitat Suitability Index (HSI) model defined “numerical index represents capacity given habitat support selected fish wildlife species” (USFWS 1991). Habitat quality assessed identifying key variables correlated habitat ecosystem condition. variable translated suitability index curve, transforms dimensional quantities dimensionless values quality. Suitability index values range 0 1, 0 unsuitable/low condition 1 suitable/ideal condition. Multiple suitability curves combined equations overarching assessment habitat quality. Habitat quantity, also used sometimes HSI analysis, commonly expressed metric area (e.g., miles, acres) combined quality values given area.Cost-effectiveness incremental cost analysis also project planning tool supports decision-making comparing costs associated level benefits project alternative can produce. environmental restoration planning, CEICA compares non-monetary environmental outputs (e.g., environmental benefits) relative monetary costs restoration actions plans (Robinson et al. 1995). US Army Corps Engineers (USACE) restoration plans compare project alternatives future without project (FWOP) scenarios order determine effects plan ecosystem restored. IWR Planning Suite existing USACE tool used conduct CEICA. guide CEICA can found .","code":""},{"path":"ecorest-web-app.html","id":"ecorest-webapp","chapter":"7 Ecorest Web App","heading":"7.3 Ecorest Webapp","text":"ecosrest webapp combines HSI CEICA capabilities, package ecorest, single graphical user interface. Users can access ecosrest data functions without need use R programming language. instructions conduct HSI CEICA using ecorest webapp.","code":""},{"path":"ecorest-web-app.html","id":"model-selection","chapter":"7 Ecorest Web App","heading":"7.4 Model Selection","text":"first step conduct Habitat Suitability Index analysis selecting appropriate model(s) study. Model Selection tab includes subtabs Choose model Visualize model.","code":""},{"path":"ecorest-web-app.html","id":"choose-model","chapter":"7 Ecorest Web App","heading":"7.4.1 Choose Model","text":"section allows user select model either existing USFWS HSI “Bluebook Model” (left panel) “User-Specified Model” (right panel).","code":""},{"path":"ecorest-web-app.html","id":"bluebook-model-left-panel","chapter":"7 Ecorest Web App","heading":"7.4.1.1 Bluebook model (left panel):","text":"“Bluebook Model”, click dropdown button select model choice.","code":""},{"path":"ecorest-web-app.html","id":"user-specified-model-right-panel","chapter":"7 Ecorest Web App","heading":"7.4.1.2 User-specified model (right panel):","text":"Check box upper-right side indicate user specified model used.Download example file guidance metadata formatting.\nmetadata include information model variable names used (SIVs).\nHeaders metadata belong first row, starting first column\nVariables headers values ignored\nVariables headers values allowed\nOmitting model name allowed\n\nInformation model belongs second row denoted columns.\ninformation available one metadata (e.g., submodel),leave cells header empty.\n\nInsert variable names SIV headers end names “.SIV”.\nmodel suitability curves example, add headers “SIV4”, “SIV5”,etc.\nmetadata include information model variable names used (SIVs).Headers metadata belong first row, starting first column\nVariables headers values ignored\nVariables headers values allowed\nOmitting model name allowed\nVariables headers values ignoredVariables headers values allowedOmitting model name allowedInformation model belongs second row denoted columns.\ninformation available one metadata (e.g., submodel),leave cells header empty.\ninformation available one metadata (e.g., submodel),leave cells header empty.Insert variable names SIV headers end names “.SIV”.model suitability curves example, add headers “SIV4”, “SIV5”,etc.Upload metadata .csv file first upload box.Download example file guidance model formatting.\nHeaders model variables belong first row, starting first column.\nfirst column header SIV1 variable name metadata except “.SIV” ending.\nField data first model variable (SIV) goes rows header/column.\nvalues may numeric (e.g., 1, 2, 3) categorical (e.g., ,b,c).\n\nsecond column header name SIV1 including “.SIV” ending.\nSuitable index values (SIVs) first model variable (SIV1) go cells header/column.\nvalues must numeric value 0-1.\n\nRepeat SIVs (e.g., .variable.name goes first, .variable.name.SIV goes second)\nmodel variable, number populated rows within field data pair must match number populated rows suitable index column. words, every field data point must suitable index value associated .\nRows columns values must continuous throughout file.\nHeaders model variables belong first row, starting first column.first column header SIV1 variable name metadata except “.SIV” ending.\nField data first model variable (SIV) goes rows header/column.\nvalues may numeric (e.g., 1, 2, 3) categorical (e.g., ,b,c).\nField data first model variable (SIV) goes rows header/column.values may numeric (e.g., 1, 2, 3) categorical (e.g., ,b,c).second column header name SIV1 including “.SIV” ending.\nSuitable index values (SIVs) first model variable (SIV1) go cells header/column.\nvalues must numeric value 0-1.\nSuitable index values (SIVs) first model variable (SIV1) go cells header/column.values must numeric value 0-1.Repeat SIVs (e.g., .variable.name goes first, .variable.name.SIV goes second)model variable, number populated rows within field data pair must match number populated rows suitable index column. words, every field data point must suitable index value associated .Rows columns values must continuous throughout file.Upload user-specified model .csv file second upload box.","code":""},{"path":"ecorest-web-app.html","id":"visualize-model","chapter":"7 Ecorest Web App","heading":"7.4.2 Visualize Model","text":"section allows user verify metadata suitability plots chosen model. model selected available USFWS bluebook models uploaded (user-specified), metadata suitability plots appear shown .upper box prints metadata chosen model lower box visualizes suitability indices model variable.metadata can downloaded Download Outputs section discussed towards end. produced suitability plots can downloaded right-clicking plots selecting “copy” “save” option.issues arise tab, verify uploaded metadata model data configured according input file formatting. See “Choose Model”section reference guide formatting information.","code":""},{"path":"ecorest-web-app.html","id":"habitat-suitability-calculator","chapter":"7 Ecorest Web App","heading":"7.5 Habitat Suitability Calculator","text":"choosing model, second step conducting HSI analysis selecting equation entering data compute patch quantity (Habitat Unit; HU) quality.\n### Manual input\nsubtab calculates HSI using inputs provided user can either single scenario (left panel) multiple scenarios (right panel). multiple scenarios, scenario entered separate rows. Examples multiple scenarios multiple project sites habitat patches.","code":""},{"path":"ecorest-web-app.html","id":"single-scenario-left-panel","chapter":"7 Ecorest Web App","heading":"7.5.0.1 Single scenario (left panel):","text":"Enter habitat patch size (numeric) associated patch quality project area.Select appropriate HSI function. bluebook models, select ‘HSIeqtn’.Enter numeric categorical values (e.g., , b, c) variable\nadd units inputs\nsuitability index variable appear input box.\nInsert numeric categorical values box accordingly.\nHSI outputs visible bottom left.\nadd units inputsEach suitability index variable appear input box.Insert numeric categorical values box accordingly.HSI outputs visible bottom left.","code":""},{"path":"ecorest-web-app.html","id":"multiple-scenario-right-panel","chapter":"7 Ecorest Web App","heading":"7.5.0.2 Multiple scenario (right panel):","text":"Select HSI function.‘Compiler’, select ‘Edit’ enter data table.Double click cells table enter data.Enter different scenario per row\nLeave last row(s) empty less 10 scenarios\n10 scenarios, use CSV Input subtab\nLeave last row(s) empty less 10 scenariosIf 10 scenarios, use CSV Input subtabClick ‘Calculate’ view outputs.","code":""},{"path":"ecorest-web-app.html","id":"csv-input","chapter":"7 Ecorest Web App","heading":"7.5.1 CSV input","text":"tab allows user insert data via .csv file process multiple scenarios one without need use ‘Manual Input’.","code":""},{"path":"ecorest-web-app.html","id":"hsi-calculator-left-panel","chapter":"7 Ecorest Web App","heading":"7.5.1.1 HSI calculator (left panel):","text":"panel allows user computes HSI quality multiple scenarios uploading .csv file field data.\n1. Download example format .csv file.\n2. Upload .csv file containing field data file upload box\n* File formatting conventions file include:\n- Headers must start 1st row column\n- header names must match model variable name\n- IMPORTANT bluebook models, names must match variable names listed ‘Manual Input tab left panel.\n- Bluebook models ’NA’ headers…\n- Field data starts second row populated column\n- Categorical bluebook models must appropriate letter match suitability lowercase (e.g., ,b,c)\n- Rows columns field data must contiguous throughout. empty rows columnes . Except ones NAs?\n- Must comma delimited file extension (.csv)\n* HSI outputs visible bottom right","code":""},{"path":"ecorest-web-app.html","id":"hu-calculator-right-panel","chapter":"7 Ecorest Web App","heading":"7.5.1.2 HU Calculator (right panel):","text":"panel computes habitat units given information habitat quantity (area) multiple scenarios. (Requires HSU multiple scenario completed!)Enter numeric value area\nadd units numeric inputs\nadd units numeric inputsSelect function\nShow – Requires vector weights\nHSIarimean – input required\nHSIgeomean – input required\nHSImin – input required\nHSIwarimean – Requires vector weights\nShow – Requires vector weightsHSIarimean – input requiredHSIgeomean – input requiredHSImin – input requiredHSIwarimean – Requires vector weightsUpload .csv file containing vector weights file upload box required\nfile containing example formatting field data can downloaded tab\nFile formatting conventions vector weights file include:\nLabels belong first row, starting first column\nWeighted values belong denoted columns 0 1\nnumber populated rows every column must equivalent\nRows weighted values must contiguous throughout column\nMust comma delimited file extension (.csv)\nHU outputs visible bottom\n\nfile containing example formatting field data can downloaded tabFile formatting conventions vector weights file include:\nLabels belong first row, starting first column\nWeighted values belong denoted columns 0 1\nnumber populated rows every column must equivalent\nRows weighted values must contiguous throughout column\nMust comma delimited file extension (.csv)\nHU outputs visible bottom\nLabels belong first row, starting first columnWeighted values belong denoted columns 0 1The number populated rows every column must equivalentRows weighted values must contiguous throughout columnMust comma delimited file extension (.csv)HU outputs visible bottom","code":""},{"path":"ecorest-web-app.html","id":"cost-effective-incremental-cost-analysis","chapter":"7 Ecorest Web App","heading":"7.6 Cost-effective Incremental Cost Analysis","text":"","code":""},{"path":"ecorest-web-app.html","id":"annualizer","chapter":"7 Ecorest Web App","heading":"7.6.1 Annualizer","text":"section computes time-averaged quantities based linear interpolation.Upload .csv file containing numeric vector time intervals first file upload box (timevec) .csv file containing numeric vector values interpolated second upload box (benefits)\nfile containing example formatting input files can found upload box\nFile formatting conventions vector values file vector time intervals file include:\nContains single column\nLabel belongs first cell\nValues must numeric\nColumn values must contiguous throughout\nfiles must contain equivalent populated row counts\n-Must comma delimited file extension (.csv)\n\nfile containing example formatting input files can found upload boxFile formatting conventions vector values file vector time intervals file include:\nContains single column\nLabel belongs first cell\nValues must numeric\nColumn values must contiguous throughout\nfiles must contain equivalent populated row counts\n-Must comma delimited file extension (.csv)\nContains single columnLabel belongs first cellValues must numericColumn values must contiguous throughoutBoth files must contain equivalent populated row counts\n-Must comma delimited file extension (.csv)single time averaged quantity appear \nvalue may extracted highlighting value cursor, right clicking, selecting copy\nvalue may extracted highlighting value cursor, right clicking, selecting copy","code":""},{"path":"ecorest-web-app.html","id":"annualizer-1","chapter":"7 Ecorest Web App","heading":"7.6.2 Annualizer","text":"section computes plots Cost-effective Incremental Cost Analysis.Upload .csv file containing Cost-effective incremental Cost Analysis (CEICA) data file drop location .\nfile containing example formatting input files can found upload box\nFile formatting conventions vector values file vector time intervals file include:\nContains three columns, starting first cell\nLabel belongs first row order: altnames, benefit, cost\nAltnames values string\nBenefit cost values must numeric\nColumn row values must contiguous\nrow must contain equivalent populated row counts\nMust comma delimited file extension (.csv)\nfile containing example formatting input files can found upload boxFile formatting conventions vector values file vector time intervals file include:Contains three columns, starting first cellLabel belongs first row order: altnames, benefit, costAltnames values stringBenefit cost values must numericColumn row values must contiguousEach row must contain equivalent populated row countsMust comma delimited file extension (.csv)Two plots appear, cost-effective analysis bottom left, incremental cost analysis bottom right\nplots can downloaded right-clicking plots selecting “copy” “save” option.\nplots can downloaded right-clicking plots selecting “copy” “save” option.","code":""},{"path":"ecorest-web-app.html","id":"download-outputs","chapter":"7 Ecorest Web App","heading":"7.7 Download Outputs","text":"","code":""},{"path":"ecorest-web-app.html","id":"export-files","chapter":"7 Ecorest Web App","heading":"7.7.1 Export Files","text":"section allows user download metadata, SI, HU results .csv file. files can compiled single file downloadable file “Generate Report” button.","code":""},{"path":"ecorest-web-app.html","id":"references","chapter":"7 Ecorest Web App","heading":"7.8 References","text":"Robinson R. Hansen W., Orth K. 1995. Evaluation environmental investments procedures manual interim: Cost effectiveness incremental cost analyses. IWR Report 95-R-1. Institute Water Resources, U.S. Army Corps Engineers, Alexandria, Virginia.USFW 1991","code":""},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"habitat-suitability-index-models-with-ecorest","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8 Habitat Suitability Index models with ecorest","text":"module teach use ecorest package R efficiently reproducibly carry HSI modeling generate useful output like :","code":""},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"background-on-hsi-modeling-with-ecorest","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.1 Background on HSI modeling with ecorest","text":"ecorest, standard platform computing outcomes habitat index models. now, users often develop ad hoc spreadsheet models, can highly prone numerical errors (McKay 2009). common quantity-quality structure index models, however, provided opportunity develop consistent, error-checked index modeling calculator adaptable variety applications across USACE. tool ecorest, can greatly increase efficiency performing habitat modeling well decrease likelihood computational errors.ecorest package can used quickly apply 350 HSI models developed U.S. Fish Wildlife Service, often referred “bluebook” models, flexible enough carry user-defined HSI model, including ones appear literature custom models developed specific projects.tutorial, demonstrate ecorest package can used two different HSI modeling scenarios, one relies bluebook model, another uses custom HSI model.","code":""},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"run-an-hsi-analysis-with-ecorest-using-a-bluebook-model","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.2 Run an HSI analysis with ecorest using a bluebook model","text":"scenario, use ecorest carry modeling analysis originally done Sacramento District part Delta Islands Levees Feasibility Study. study, Marsh Wren HSI model used examine ecosystem effects intertidal marsh restoration. overall Feasibility Study can found , appendix details habitat evaluation procedure can found .conduct HSI modeling scenario, first need add necessary packages R session.ecorest package contains list object called HSImodels. 351 elements list data frame representing one U.S. Fish Wildlife Service Habitat suitability index (HSI) models. HSI model consists multiple independent variables (e.g., percent canopy cover) associated habitat suitability values ranging 0 1. Categorical input variables coded letters. models can called R corresponding model name using HSImodels$modelname (e.g., HSImodels$barredowl).look HSI models available, run following code:Another important object contained within package HSImetadata dataframe. contains important information HSI model, including different suitability variables within model aggregated calculate overall HSI value project alternative. following code generates small subset variables rows dataframe","code":"\nlibrary(ecorest)\nlibrary(tidyverse)\nnames(HSImodels)##   [1] \"alewifeJuv\"                             \"alewifeJuvAndSAEL\"                     \n##   [3] \"alewifeSAEL\"                            \"americanalligatorNontidal\"             \n##   [5] \"americanalligatorTidal\"                 \"americanblackduckWinteringEVegWetland\" \n##   [7] \"americanblackduckWinteringNCapeCod\"     \"americanblackduckWinteringSCapeCod\"    \n##   [9] \"americancoot\"                           \"americaneiderBreeding\"                 \n##  [11] \"americanoysterGulfofMexModifier\"        \"americanoysterGulfofMexTypical\"        \n##  [13] \"americanshadEstu\"                       \"americanshadRiv\"                       \n##  [15] \"americanwoodcockWinteringForestedDry\"   \"americanwoodcockWinteringForestedMoist\"\n##  [17] \"americanwoodcockWinteringForestedWet\"   \"americanwoodcockWinteringShrubDry\"     \n##  [19] \"americanwoodcockWinteringShrubMoist\"    \"americanwoodcockWinteringShrubWet\"     \n##  [21] \"arcticgrayling\"                         \"arcticgraylingAdultJuv\"                \n##  [23] \"arcticgraylingSEF\"                      \"atlanticcroakerLATideLt0.5m\"           \n##  [25] \"atlanticcroakerLATideMt0.5m\"            \"atlanticcroakerOtherTideLt0.5m\"        \n##  [27] \"atlanticcroakerOtherTideMt0.5m\"         \"atlanticcroakerWetlandLATideLt0.5m\"    \n##  [29] \"atlanticcroakerWetlandLATideMt0.5m\"     \"atlanticcroakerWetlandOtherTideLt0.5m\" \n##  [31] \"atlanticcroakerWetlandOtherTideMt0.5m\"  \"bairdssparrow\"                         \n##  [33] \"baldeagleBreeding\"                      \"barredowl\"                             \n##  [35] \"beaverLacAreaLt8ha\"                     \"beaverLacAreaMtoe8ha\"                  \n##  [37] \"beaverPalu\"                             \"beaverRiv\"                             \n##  [39] \"beltedkingfishLenticConstWave\"          \"beltedkingfishLenticNoConstWave\"       \n##  [41] \"beltedkingfishLotic\"                    \"bigmouthbuffaloLacNoSal\"               \n##  [43] \"bigmouthbuffaloLacSal\"                  \"bigmouthbuffaloRivNoSal\"               \n##  [45] \"bigmouthbuffaloRivSal\"                  \"blackbear\"                             \n##  [47] \"blackbelliedwhistlingduck\"              \"blackbrant\"                            \n##  [49] \"blackbullheadLac\"                       \"blackbullheadRiv\"                      \n##  [51] \"blackcappedchickadeeFoodCanH\"           \"blackcappedchickadeeFoodCanVol\"        \n##  [53] \"blackcrappieLacNoSal\"                   \"blackcrappieLacSal\"                    \n##  [55] \"blackcrappieRivNoSal\"                   \"blackcrappieRivSal\"                    \n##  [57] \"blacknosedaceLac\"                       \"blacknosedaceRiv\"                      \n##  [59] \"blackshoulderedkite\"                    \"blacktailedprairiedog\"                 \n##  [61] \"bluegillLac\"                            \"bluegillRiv\"                           \n##  [63] \"bluegrouse\"                             \"blueherringJuv\"                        \n##  [65] \"blueherringJuvAndSAEL\"                  \"blueherringSAEL\"                       \n##  [67] \"bluewingedtealBreeding\"                 \"bobcatLt4ha\"                           \n##  [69] \"bobcatMtoe4ha\"                          \"brewerssparrow\"                        \n##  [71] \"brooktroutLacAllLtoe15C\"                \"brooktroutLacAllMt15C\"                 \n##  [73] \"brooktroutRivAllLtoe15CLtoe5mEC\"        \"brooktroutRivAllLtoe15CMt5mEC\"         \n##  [75] \"brooktroutRivAllMt15CLtoe5mEC\"          \"brooktroutRivAllMt15CMt5mEC\"           \n##  [77] \"brownshrimpNGulfofMex\"                  \"brownthrasher\"                         \n##  [79] \"browntroutCompLtoe10C\"                  \"browntroutCompMt10C\"                   \n##  [81] \"browntroutLimitLtoe10C\"                 \"browntroutLimitMt10C\"                  \n##  [83] \"bullfrog\"                               \"cactuswren\"                            \n##  [85] \"canvasbackBreeding\"                     \"channelcatfishLac\"                     \n##  [87] \"channelcatfishRiv\"                      \"chinooksalmonComp5to10CSand\"           \n##  [89] \"chinooksalmonComp5to10CSilt\"            \"chinooksalmonCompLtoe5CSand\"           \n##  [91] \"chinooksalmonCompLtoe5CSilt\"            \"chinooksalmonCompMt10CSand\"            \n##  [93] \"chinooksalmonCompMt10CSilt\"             \"chinooksalmonLimit5to10CSand\"          \n##  [95] \"chinooksalmonLimit5to10CSilt\"           \"chinooksalmonLimitLtoe5CSand\"          \n##  [97] \"chinooksalmonLimitLtoe5CSilt\"           \"chinooksalmonLimitMt10CSand\"           \n##  [99] \"chinooksalmonLimitMt10CSilt\"            \"chumsalmonAlevin\"                      \n##  [ reached getOption(\"max.print\") -- omitted 251 entries ]\nHSImetadata %>%\n  select(model, submodel, Eqtn) %>% # Select which columns to display\n  slice(1,4:6) # Select which rows to display##                                   model                     submodel            Eqtn\n## 1                            alewifeJuv    Juvenile life stage model    min(CF, CWQ)\n## 2             americanalligatorNontidal             Nontidal wetland (CCB*CCN)^(1/2)\n## 3                americanalligatorTidal               Tidal wetlands (CCB*CCN)^(1/2)\n## 4 americanblackduckWinteringEVegWetland Estuarine vegetated wetlands              CF"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"explore-the-marsh-wren-hsi-model","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.2.1 Explore the Marsh Wren HSI model","text":"use Marsh Wren HSI model, extract HSImodels object.Print Marsh Wren model console look structure:can see, ’s series suitability curves ordered parameter breakpoints associated suitability indices parameter. column environmental variable (e.g., emerg.hydrophytes.class) followed column (whose name ends .SIV) suitability index values associated environmental predictor.marsh wren HSI model can also viewed graphically. HSIplotter function creates JPEG image file images folder working directory. user selects name file, keep “.jpg” file extension.","code":"\nwren_hsi <- HSImodels$marshwren\nprint(wren_hsi)##   emerg.hydrophytes.class emerg.hydrophytes.SIV emerg.herb.can.cov.pct emerg.herb.can.cov.SIV\n## 1                       a                   1.0                      0                    0.0\n## 2                       b                   0.5                     50                    0.1\n## 3                       c                   0.1                     80                    1.0\n## 4                       d                   0.0                    100                    1.0\n##   avg.wtr.d.cm avg.wtr.d.cm.SIV woody.can.cov.pct woody.can.cov.SIV\n## 1            0                0                 0                 1\n## 2           15                1               100                 0\n## 3           40                1                NA                NA\n## 4           NA               NA                NA                NA\nHSIplotter(wren_hsi, \"images/marshwren_hsi.jpg\")"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"calculate-suitability-values-from-environmental-variables","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.2.2 Calculate suitability values from environmental variables","text":"calculate acres habitat project produce, need estimates environmental variables make chosen HSI model. Marsh Wren, variables include:Growth form emergent hydrophytesCanopy cover emergent herbaceous vegetationMean water depthCanopy cover woody vegetationValues variables can imported .csv file, can entered manually . take values row table corresponds target year 1 (TY1). Environmental variables must order appear HSI model. Categorical variables, emergent hydrophyte growth form, coded letters.order calculate habitat units, also need provide project area acres. provide area listed TY1 .Next, use SIcalc function calculate suitability value variable model. SIcalc function computes suitability indices using two inputs: suitability model (wren_hsi) project-specific environmental variables ’ve provided (`env_vars).","code":"\nenv_vars <- tibble(v1 = \"a\",\n                   v2 = 4,\n                   v3 = 99.1,\n                   v4 = 0)\narea = 34\nsi_vars <- SIcalc(wren_hsi, env_vars)\nprint(si_vars)## [1] 1.000 0.008 1.000 1.000"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"aggregate-hsi-value-and-habitat-units","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.2.3 Aggregate HSI value and Habitat Units","text":"crucial part HSI modeling determining SI values different variables combined create overarching HSI score. SI values can combined numerous ways (e.g., geometric mean, minimum value, etc.). bluebook models, however, identify species/submodel-specific way combine SI values, according specific attributes species. Therefore, bluebook model used, HSIeqtn function used calculate cummulative HSI score using appropriate equation. function requires name HSI model, variables individual metrics ’ve calculated, HSImetadata file, euqation stored.calculated cummulative HSI score separate SI values, can lastly calculate Habitat Units associated given project.","code":"\ntotal_HSI <- HSIeqtn(\"marshwren\", si_vars, HSImetadata)\nprint(total_HSI)## [1] 0.2\nTotal_hab <- total_HSI*area\nprint(Total_hab)## [1] 6.8"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"habitat-units-for-multiple-years-or-alternative-projects","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.2.4 Habitat Units for multiple years or alternative projects","text":"multiple project alternatives exist, multiple years environmental data, can perform operations using code. , -loop allows us iterate scenarios/years calculate SI values habitat unitsTable 8.1: Habitat Suitability Index (HSI) Variables \nResulting Outputs Marsh Wren Model -Project.results ’ve generated using ecorest package identical ones report, can see:\nbeauty carrying R using script can change input value reproduce results matter seconds re-running code, instead go steps manually. using ecorest package means instant access hundreds quality-controlled bluebook models.","code":"\n# Create dataframe of environmental variables for 4 scenarios/years\nnew_env_vars <- tibble(V1 = rep(\"a\", 4),\n                       V2 = c(5, 8.5, 12, 16),\n                       V3 = c(94.5, 89.9, 85.3, 80.8),\n                       V4 = c(0, 0, 0, 0))\n\nnyears <- nrow(new_env_vars) # Number of years/alternatives\nnvars <- ncol(new_env_vars) # Number of environmental variables\n\nnew_area = c(68, 102, 136, 170)\n\n# Create an empty matrix and vector to hold the results of the SI and HSI calculations, respectively\nnew_si_vars <- matrix(0, nrow=nyears, ncol=nvars)\nnew_total_HSI <- rep(NA, 4)\n\n# Use a for-loop to calculate SI values and HSI scores for each year/scenario\nfor (i in 1:nyears) {\n  new_si_vars[i, ] <- SIcalc(wren_hsi, new_env_vars[i, ])\n  new_total_HSI[i] <- HSIeqtn(\"marshwren\", new_si_vars[i, ], HSImetadata)\n}\n\n# Create a dataframe of the new SI values\nnew_si_df <- as_tibble(new_si_vars) %>%\n  set_names(c(\"SI_V1\",\"SI_V2\",\"SI_V3\",\"SI_V4\"))\n\n# Create an output table with all of the input and output\noutput_tab_wren <- new_env_vars %>%\n  bind_cols(new_si_df) %>%\n  mutate(output_HSI = round(new_total_HSI, 2),\n         total_acres = new_area,\n         HUs = output_HSI*total_acres)\n\n# Print the table using the knitr package\nknitr::kable(output_tab_wren, \n             digits = 2, \n             padding = 2,\n             caption = \"Habitat Suitability Index (HSI) Variables and \n             Resulting Outputs for the Marsh Wren Model With-Project.\")"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"hsi-modeling-with-custom-model","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.3 HSI Modeling with custom model","text":"Sometimes, project use custom index model instead bluebook model calculate habitat units. example, South San Francisco Bay Shoreline Study, USACE-SPN collaborated ERDC’s Coastal Ecology Integrated Ecological Modeling, develop quantitative model tidal marsh restoration subsided former baylands sensitive multiple restoration measures, including import beneficially used material bathymetry lifts, ecotones refugia.used ecorest package habitat model caclulations.","code":""},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"explore-model-and-data","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.3.1 Explore model and data","text":"Import .csv marsh model, print names variables, plot model. Note: plotting function work, model must read using base R function read.csv instead Tidyverse function read_csvNext, read environmental data associated alternative project designs.","code":"\n# Import marsh HSI model\nmarsh_model<-read.csv(\"data/SF-TM-HEI_InputData.csv\")\nprint(names(marsh_model))## [1] \"percent.tidal.range\"                                     \n## [2] \"percent.tidal.range.SIV\"                                 \n## [3] \"Average.Marsh.Age\"                                       \n## [4] \"Average.Marsh.Age.SIV\"                                   \n## [5] \"Percent.Marsh.within.500.or.200\"                         \n## [6] \"Percent.Marsh.within.500.or.200.SIV\"                     \n## [7] \"Percent.Marsh.Shoreward.Edge.with.Ecotone.Transition\"    \n## [8] \"Percent.Marsh.Shoreward.Edge.with.Ecotone.Transition.SIV\"\nHSIplotter(marsh_model,\"images/marsh_model.jpg\")\n# Dataset of environmental conditions associated with project alternatives\nmarsh_alts <- read.csv(\"data/SF-TM-HEI_FieldData.csv\")\n\n# marsh_alts %>% \n#   pivot_longer(V1:V4, names_to = \"variable\", values_to = \"value\") %>%\n#   ggplot() +\n#   geom_point(aes(variable, value))+\n#   facet_wrap(~alt, nrow = 15)\n\nprint(marsh_alts)##      alt  V1  V2  V3  V4\n## 1   FWOP   0   0   0   0\n## 2  Alt1a  20 100   0   0\n## 3  Alt1b  50 100   0   0\n## 4  Alt1c 100 100   0   0\n## 5  Alt2a  20 100  20 100\n## 6  Alt2b  50 100  20 100\n## 7  Alt2c 100 100  20 100\n## 8  Alt3a  20 100 100 100\n## 9  Alt3b  50 100 100 100\n## 10 Alt3c 100 100 100 100\n## 11 Alt3d 100  20 100 100\n## 12 Alt3e 100  10 100 100\n## 13 Alt3f 100   1 100 100\n## 14 Alt3g 100   0 100 100\n## 15 Alt3h 100   0   0   0"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"calculate-individual-suitability-indices","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.3.2 Calculate individual suitability indices","text":", create empty matrix store results calculate SI values parameter using SICalc().","code":"\n # Create a dataframe of just environmental variables associated with each alternative\nenv_marsh <- select(marsh_alts, -alt)\nnalternatives<-length(marsh_alts$alt) # Number of alternatives\n\n# Create empty matrix to store SI values for each alternative\nsi_marsh <- matrix(NA, nrow=nalternatives, ncol=4)\n\n# Calculate the SI values for each alternative using a for-loop\nfor(i in 1:nalternatives) {\n  si_marsh[i, ] <- SIcalc(marsh_model, env_marsh[i, ])\n}\n\n# Convert matrix of SI values to dataframe and name the columns\nsi_marsh_df <- as_tibble(si_marsh) %>%\n  set_names(paste0(\"SI_\", names(env_marsh)))"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"calculate-the-total-hsi-score","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.3.3 Calculate the Total HSI score","text":", analysis team developed custom formula combine different HSI scores:\nCube root((Tidal connectivity* Marsh Age)*(Ecotone + Refugia)/2)R syntax, code looks like \n((((SIV2*SIV1)(SIV4+SIV3)/2))^(1/3))calculate cummulative score, ’ll use mutate function create new column dataframe suitability index values, calculate total HSI values columns.","code":"\n# Calculate overall HSI from individual SI values\nsi_total <- si_marsh_df %>%\n  mutate(total_hsi = ((((SI_V4+SI_V3)/2)*(SI_V2*SI_V1))^(1/3)))"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"cummulative-hsi-and-habitat-units","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.3.4 Cummulative HSI and Habitat Units","text":"Next, ’ll calculate habitat units associated project, assuming total project area 300 acres.Finally, can create ouput table data.Table 8.2: SF Salt Marsh HSI Values Marsh Units.","code":"\n# Calculate habitat units by multiplying total HSI by project area (300 acres)\narea_marsh <- 300\n\nsi_total_hu<-si_total %>%\n  mutate(HUs = area_marsh*total_hsi)\noutput_tab <- bind_cols(marsh_alts, si_total_hu) %>%\n  set_names(c(\"Alternative\", \"PTR\", \"MA\", \"HTR\", \"E\", \"PTR-SI\", \"MA-SI\", \n              \"HTR-SI\", \"E-SI\", \"HSI-Total\", \"Marsh Units\"))\n\nknitr::kable(output_tab, caption=\"SF Salt Marsh HSI Values and Marsh Units.\", \n             align=\"c\", \n             digits = 2)"},{"path":"habitat-suitability-index-models-with-ecorest.html","id":"linking-steps-using-pipes","chapter":"8 Habitat Suitability Index models with ecorest","heading":"8.3.5 Linking steps using pipes","text":"last several operations conducted can done single “tidy” way using pipe operator %>%.final line code checks demonstrates two output dataframes identical.","code":"\narea_marsh = 300\n\noutput_tab_2 <- as_tibble(si_marsh) %>%\n  set_names(paste0(\"SI_\", names(env_marsh))) %>%\n  mutate(total_hsi = ((((SI_V4+SI_V3)/2)*(SI_V2*SI_V1))^(1/3)),\n         HUs = area_marsh*total_hsi) %>%\n  bind_cols(marsh_alts,.) %>% # This code is slightly different so that marsh_alts data will come first; the \".\" symbol indicates everything that has come before this function\n  set_names(c(\"Alternative\", \"PTR\", \"MA\", \"HTR\", \"E\", \"PTR-SI\", \"MA-SI\", \n              \"HTR-SI\", \"E-SI\", \"HSI-Total\", \"Marsh Units\"))\n\nall.equal(output_tab, output_tab_2)## [1] TRUE"},{"path":"spatial-habitat-models.html","id":"spatial-habitat-models","chapter":"9 Spatial Habitat Models","heading":"9 Spatial Habitat Models","text":"Consider exploring “Geospatial suitability indices (GSI) toolbox : user’s guide”\nhttps://erdc-library.erdc.dren.mil/items/7e880360-d004-4601-9a42-eddd64233e34","code":""},{"path":"linear-models.html","id":"linear-models","chapter":"10 Linear Models","heading":"10 Linear Models","text":"module teach use linear models R assess relationships among environmental factors USACE-managed Upper Mississippi River.Acknowledgements:\ninspiration/language/code used adapted permission :\nBen Staton’s Intro R Natural Resources course\nQuebec Center biodiversity Science’s Linear model workshop","code":""},{"path":"linear-models.html","id":"relevance-of-linear-models-to-usace","chapter":"10 Linear Models","heading":"10.1 Relevance of linear models to USACE","text":"Linear models offshoots estimate relationship response variable one predictor variables. models used widely ecologists understand, example, environmental management factors important determining biological outcomes phenomena. Linear models several potential applications USACE projects ecological modeling practices:Validating updating relationships within existing HSI modelsCreating new habitat models based empirical data instead conjectureEstimating relationship focal taxa habitat characteristics order predict response species USACE habitat-altering projects (thus potentially acting alternative habitat model)","code":""},{"path":"linear-models.html","id":"learning-objectives-5","chapter":"10 Linear Models","heading":"10.2 Learning objectives","text":"Understand purpose structure linear modelRun linear model RInterpret output linear modelAssess linear model validity","code":""},{"path":"linear-models.html","id":"background-on-linear-models","chapter":"10 Linear Models","heading":"10.3 Background on linear models","text":"Linear models used estimate relationship () response variable one predictor variable(s). typically constructed analyze priori hypothesis variables correlated. results analysis indicate direction strength relationship variables, level confidence relationship.","code":""},{"path":"linear-models.html","id":"linear-model-formulation","chapter":"10 Linear Models","heading":"10.3.1 Linear model formulation","text":"linear model, response variable variable wish explain, also known dependent variable, value may depend values predictor variables. one response variable. Predictor variables (also known independent explanatory variables), hand, variables potential explain predict response variable. Linear models can multiple predictor variables.linear model, single observation response variable \\(y\\) defined \\(y_i\\), corresponding observation predictor variable \\(x\\) defined \\(x_i\\). values \\(y\\) \\(x\\) related using formula, describes relationship two variables straight line:\\[ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\\]\\(y_i\\) response variable\\(x_i\\) predictorThe parameter \\(\\beta_0\\) interceptThe parameter \\(\\beta_1\\) quantifies effect** \\(x\\) \\(y\\)residual \\(\\epsilon_i\\) represents unexplained variationBasically, just reformulation classic middle school equation used graph straight line–\\(y = mx + b\\)–case \\(\\beta_1\\) stands \\(m\\) \\(\\beta_0\\) \\(b\\). , also inherently idea explanatory variables never explain variation predictor: ’s left model error \\(\\epsilon_i\\), also knows residuals.Remember, main purpose fitting linear model estimate coefficient values (\\(\\beta\\)); provides insight magnitude direction relationship predictors response variables. also interested much variation response variable explained predictor variables","code":""},{"path":"linear-models.html","id":"linear-model-assumptions","chapter":"10 Linear Models","heading":"10.3.2 Linear model assumptions","text":"Linear models important assumptions. statistician Andrew Gelman lists important linear model assumptions, order importance, follows:Validity: response predictors pertain directly research question.Additivity linearity: response variable model linear function separate predictors.Independence errors: value one residual completely independent value adjacent residuals.Equal variance errors: greater variance values predictor others.Normality errors: residuals taken together distributed normally.last three assumptions listed model residuals. Remember, model error represent difference data point \\(y_i\\) model prediction \\(\\hat{y}_i\\). figure indicates model residuals meet assumptions., one think assumptions violated? Well, academic Jan Vanhove helpful way thinking : assumptions violated, model inferences shouldn’t necessarily thought incorrect, rather less relevant.","code":""},{"path":"linear-models.html","id":"application-of-a-linear-model","chapter":"10 Linear Models","heading":"10.4 Application of a linear model","text":"demonstrate linear modeling practice, ’ll use data USACE’s Upper Mississippi River Restoration Program’s Long Term Resource Monitoring Program. data ’ve collated source contains fisheries catch data corresponding environmental conditions. may interested broadly understanding environmental conditions–depth, current, etc.–determine aspects fish communities. However, throwing several variables model predict drivers , say, fish abundance, assess whether correlations dependencies among environmental variables. need avoid mistaking effect one predictor another.example, aquatic systems, often relationship water temperature dissolved oxygen: solubility oxygen water decreases temperature increases, meaning colder water frequently oxygenated. However, dissolved oxygen levels may also affected aquatic plants, water turbulence can introduce oxygen water surface. Understanding dependencies may important ultimate goal understanding factors affect fish communities. , use linear models R.","code":""},{"path":"linear-models.html","id":"import-and-explore-the-data","chapter":"10 Linear Models","heading":"10.4.1 Import and explore the data","text":"First, read subset fish environmental data fall sampling navigation pools, 4, 8, 13 Upper Mississippi River. filter data remove dissolved oxygen values > 20 mg/L, since values levels may erroneous.can use ggplot plot relationship dissolved oxygen temperature. can also add line predictors; specify want line linear adding call method = \"lm\".can see ’s pretty clear relationship two variables. ’d like go beyond quantify relationship statistically.","code":"\nlibrary(tidyverse)\n\numr_wide <- read_csv(\"data/umr_counts_wide.csv\")\n\numr_sub <- umr_wide %>%\n  filter(do < 20, \n         !is.na(vegd))\nggplot(umr_sub, \n       aes(temp, do))+\n  geom_point(alpha = .5, pch = 21, size = 1)+\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Temperature (C)\", y = \"Dissolved Oxygen\")+\n  theme_classic()"},{"path":"linear-models.html","id":"fit-a-model-and-assess-output","chapter":"10 Linear Models","heading":"10.4.2 Fit a model and assess output","text":"can now use lm() function r create linear model assessing relationship variables. use lm() function, provide R formula model. formula include (~ temp) indicates interested modeling function temp. words, telling R dissolved oxygen response variable, temperature predictor variable. wanted add another predictor change formula (e.g., ~ temp + depth ~ temp*detph wanted interactive effective). also indicate dataset use.’s fit first model, now stored lm.mod object.use summary function assess model results.output summary function contains important information :Coefficients: Estimates parameters standard deviationPr(>|t|): Results t-test determine parameters different 0Adjusted R squared: well model explain data?F-statistic(ANOVA): model significantly different model predictor (null model)?Taken together, values can used assess extent temperature predicts dissolved oxygen study location. can first look estimate \\(\\beta_1\\) coefficient temp, indicates effect size temperature dissolved oxygen, approximate value -0.26. means average, every 1 degree C increase temperature, dissolved oxygen decreases -0.26 mg/L. represents moderately substantial relationship. also get estimate intercept, \\(\\beta_0\\) coefficient. suggests predict dissolved oxygen level 12.6 mg/L temperature 0 degrees.can also see Adjusted R-squared estimate 0.16 model explains 16% variance dissolved oxygen. ecological research decent amount variance. may still wish refine model better job explaining variance.","code":"\nlm.mod <- lm(do ~ temp,\n           data = umr_sub)\nmod_summ <- summary(lm.mod)\nmod_summ## \n## Call:\n## lm(formula = do ~ temp, data = umr_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -9.1881 -1.1783 -0.0571  1.0723 10.5807 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 12.64919    0.19403   65.19   <2e-16 ***\n## temp        -0.25855    0.01161  -22.27   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.295 on 2570 degrees of freedom\n## Multiple R-squared:  0.1617, Adjusted R-squared:  0.1614 \n## F-statistic: 495.8 on 1 and 2570 DF,  p-value: < 2.2e-16"},{"path":"linear-models.html","id":"assess-model-validity","chapter":"10 Linear Models","heading":"10.4.3 Assess model validity","text":"can trust results? first need verify model assumptions met, examining residuals turns key assessing linear model appropriate choice modeling data. can making diagnostic plots residuals using plot(lm.mod) function. Running function create four plots sequentially R, examine individually following code. See detailed explanation plots .first plot shows Residuals vs. Fitted values. Remember, residuals difference predicted values response variable (dissolved oxygen ) observed values response variable. model assumptions met, plot horizontal line residuals spread around fairly evenly. residuals show non-linear patterns (e.g., parabola) may indicate non-linear relationship predictors response variable. appears fairly random scatter residuals, suggesting major problems non-linearity.Q-Q residual plot used assess whether residuals follow normal distribution; points plot closely follow diagonal line. example, residuals deviate bit tails, suggesting residuals may perfectly distributed, normality residuals critical large datasets like considered one less important linear model assumptions.Scale-Location plot checks constant variance residuals. Similar first plot, red line roughly flat, shouldn’t systematic spread data. model fairly well , although slight increase variance higher fitted values.Finally Residuals vs. Leverage plot indicate whether influential outliers can bias results. plot, specifically look large points upper lower right: points large residuals high leverage. Depending spread residuals, may dashed lines points called “Cook’s distance” scores. Points outside dashed lines, may strong influence regression results, suggesting parameter estimates might biased.Taken together, plots suggest linear model reasonable choice assessing relationship temperature dissolved oxygen. model violated linear model assumptions egregiously, need use different model type, often generalized linear model, covered subsequent module.","code":"\nplot(lm.mod, which = 1)\nplot(lm.mod, which = 2)\nplot(lm.mod, which = 3)\nplot(lm.mod, which = 5)"},{"path":"linear-models.html","id":"ancova","chapter":"10 Linear Models","heading":"10.4.4 ANCOVA","text":"Even linear model reasonable case, may hope explain variance. alluded possibility variables may important. submersed aquatic vegetation pumping oxygen water column? dataset contains categorical variable density vegetation vegd 1 vegetation sparse 2 vegetation dense. Categorical variables can added linear models R, although need make sure coded factors, numeric variables.model categorical variables, ANOVA. categorical variable used concert continuous variable, known ANCOVA, equivalent fitting two regression lines within model; lines parallel different intercepts. difference intercepts represents average effect categorical variable response.can start look possibility influence vegetation first plotting data , time coloring points ggplot differentially (.e., adding color = vegd earlier code):assess magnitude effect, run new linear model includes continuous temperature predictor categorical vegetation predictor.summary shows coefficient vegd2 -0.59. means average, locations temperature 0.6 mg/L less oxygen dense vegetation present (.e., vegd equals 2) compared sparse vegetation. Note, coefficient one level vegetation variable (.e., vegd equals 2, vegd equals 1). one level categorical variable (, vegd equals 1) always used reference level, coefficients reported represent difference response variable level baseline level. Beyond coefficients, can see R-squared increased marginally: adding vegd model increased explanation variance response data 1.5%.real analysis, might try data transformations improve model fit, /explore variables potential model inclusion. Finally, might assess model best using model selection approach like AIC. -depth coverage topics, point user following sources:Quebec Center biodiversity Science’s Linear model workshopBen Staton’s Intro R Natural Resources course","code":"\numr_sub <- mutate(umr_sub, \n                  vegd = as.factor(vegd))\nggplot(umr_sub, \n       aes(temp, do, color = vegd))+\n  geom_point(alpha = .5, pch = 21, size = 1.5)+\n  geom_smooth(method = \"lm\")+\n  labs(x = \"Temperature (C)\", y = \"Dissolved Oxygen (mg/L)\")+\n  theme_classic()\nancov.mod <- lm(do ~ temp + vegd, \n                data = umr_sub)\n\nsummary(ancov.mod)## \n## Call:\n## lm(formula = do ~ temp + vegd, data = umr_sub)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.8610 -1.1965 -0.1168  1.0716 10.8873 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 12.78663    0.19367  66.021  < 2e-16 ***\n## temp        -0.24924    0.01161 -21.469  < 2e-16 ***\n## vegd2       -0.58551    0.09052  -6.468 1.18e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.277 on 2569 degrees of freedom\n## Multiple R-squared:  0.1752, Adjusted R-squared:  0.1745 \n## F-statistic: 272.8 on 2 and 2569 DF,  p-value: < 2.2e-16"},{"path":"linear-models.html","id":"summary","chapter":"10 Linear Models","heading":"10.5 Summary","text":"saw linear models can used describe linear relationship response variable number predictor variables. best linear models thought means assess hypotheses developed based subject matter expertise. results linear model indicate whether data support hypothesis, giving us estimates magnitude direction effect sizes, much variability model explains much uncertainy .Linear models best fairly constrained scenarios .e., response data continuous variables, linear relationship variables, etc. However, ecological research, many data types–especially binary count data–rarely ever meet criteria, model types required. example next module presents extension linear models can used ubiquitous data types like counts binary data conform assumptions linear models.","code":""},{"path":"generalized-linear-models.html","id":"generalized-linear-models","chapter":"11 Generalized Linear Models","heading":"11 Generalized Linear Models","text":"module teach use Generalized Linear Models assess importance management-relevant environmental factors fish speciesAcknowledgments:\ninspiration/code adapted permission :\nBen Staton’s Intro R Natural Resources course\nQuebec Center biodiversity Science’s Generalized linear model workshop","code":""},{"path":"generalized-linear-models.html","id":"generalized-linear-model-background","chapter":"11 Generalized Linear Models","heading":"11.1 Generalized Linear Model Background","text":"models examined previous section linear models. assume residuals normally-distributed response variable predictor variables linearly-related. However several ubiquitous types data used ecological modeling–presence/absence data counts organisms–follow assumptions. types data, Generalized linear models (GLMs) can overcome problems.go statistical details GLMs, -depth description statistical underpinnings, see [] (https://r.qcbs.ca/workshop06/book-en/) elsewhere. important , however, understand three key elements GLMs:Response distribution: probability distribution response variable Y, binomial distribution binary data Poisson distribution count data.Linear predictor: linear combination explanatory variables (η=Xβ), analogous standard linear model.Link function: function relates mean response variable’s distribution (μ) linear predictor (η). choice link function typically guided response distribution; example, count data modeled Poisson distribution often use natural logarithm link function.common examples GLMs ecology logistic regression binary data poisson negative binomial regression count data.","code":""},{"path":"generalized-linear-models.html","id":"logistic-regression","chapter":"11 Generalized Linear Models","heading":"11.2 Logistic regression","text":"Binary data, two opposite outcomes, common ecology, example, present/absent, success/failure, lived/died, male/female, etc. want predict probability one outcome opposite changes depending variable(s), need use logistic regression model, written :\\[\\begin{equation}\n  logit(p_i)=\\beta_0 + \\beta_1 x_{i1} + ... + \\beta_j x_{ij}+ ... + \\beta_n x_{}, y_i \\sim Bernoulli(p_i)\n\\tag{11.1}\n\\end{equation}\\], \\(p_i\\) probability success trial \\(\\) values predictor variables \\(x_{ij}\\). \\(logit(p_i)\\) link function links linear parameter scale data scale. logit link function constrains value \\(p_i\\) 0 1 regardless values \\(\\beta\\) coefficients.logit link equivalent log odds ratio, words, natural log likely event compared happening.Therefore, logistic regression, model calculate log odds outcome, want know odds ratio (.e., ), just take inverse log. example analysis conduct make obvious.","code":""},{"path":"generalized-linear-models.html","id":"example-logistic-regression-anaysis","chapter":"11 Generalized Linear Models","heading":"11.2.1 Example logistic regression anaysis","text":"example logistic regression analysis, ’ll use fisheries dataset three navigation pools Upper Mississippi River used chapter linear models. fish data collected understand long-term trends river, ’ll use data see relationships may exist habitat predictors fish responses.","code":""},{"path":"generalized-linear-models.html","id":"import-and-explore-data","chapter":"11 Generalized Linear Models","heading":"11.2.1.1 Import and explore data","text":"First read data filter includes data daylight electrofishing (gear == \"D\"), backwater habitat, depths < 5 m, gear accurate.Let’s look column names dataframe. see last 10 columns, starting BLGL codes species. columns counts different species sampling event.Counts can “noisy” data often difficult predict, ’s common instead model presence/absence. order , can convert counts 1’s 0’s using following code. using mutate change values species columns. case_when dplyr function operates similarly -else statement. , saying columns species names, value greater 0, convert 1, value (.e., ’s 0), remain 0.’re going examine whether predictor variables dataset predictive occurrence one species, common carp. able predict habitat variables influence presence species might basis predicting USACE management activities impact species.First, let’s plot common carp occurrence function several predictor variables: temperature, water transparency (.e., secchi disk reading), depth, conductivity. easily ggplot, need variables one column can use facet_wrap function make singe panel variable. create dataframe called carp_long using pivot_longer function go wide format long format, makes plotting seemless.pivot_longer tell columns want combine, name column now inclues variable names name column includes variable values.Now can plot variables.plots, variables pop potentially important. example locations carp occurrences appear lower secchi disk readings (.e., less clear water) higher temperatures, strength relationships unclear, modeling comes play.","code":"\nlibrary(tidyverse)\n\numr_wide <- read_csv(\"data/umr_counts_wide.csv\")\n\n#Period already filtered to 3\numr_sub <-  umr_wide %>%\n  filter(gear == \"D\",\n         stratum_full == \"Backwater\",\n         depth < 5)\nnames(umr_sub)##  [1] \"date\"         \"utm_e\"        \"utm_n\"        \"stratum_full\" \"year\"         \"period\"      \n##  [7] \"pool\"         \"gear\"         \"secchi\"       \"temp\"         \"depth\"        \"cond\"        \n## [13] \"current\"      \"do\"           \"substrt\"      \"vegd\"         \"BLGL\"         \"FWDM\"        \n## [19] \"CARP\"         \"LMBS\"         \"ERSN\"         \"BKCP\"         \"SHRH\"         \"GZSD\"        \n## [25] \"WTBS\"         \"SFSN\"\nspecies <- names(umr_sub)[17:26]\n\nfish_binary <- umr_sub %>% \n mutate(across(any_of(species), ~ case_when(. > 0 ~ 1, TRUE ~ 0)))\ncarp_long <- fish_binary %>%\n  select(CARP, secchi:do) %>%\n  pivot_longer(cols = secchi:cond, names_to = \"variable\", values_to = \"value\")\nggplot(carp_long, \n         aes(value, CARP))+\n  geom_jitter(height = .1, width = .02, alpha =0.5, color = \"steelblue\")+\n  geom_boxplot(aes(group = CARP), \n                   width = 0.5, alpha = 0.5, color = \"black\", fill = \"gray\")+\n  facet_wrap(~variable, nrow = 2, scales = \"free_x\")+\n  scale_y_continuous(breaks = c(0,1))+\n  labs(x = \"Value of predictor\", y = \"Carp occurrence\")+\n  theme_classic()## Warning: Removed 170 rows containing non-finite outside the scale range (`stat_boxplot()`).## Warning: Removed 170 rows containing missing values or values outside the scale range\n## (`geom_point()`)."},{"path":"generalized-linear-models.html","id":"fit-model-with-glm-function","chapter":"11 Generalized Linear Models","heading":"11.2.1.2 Fit model with glm function","text":"’ll use glm function base R , kind formula notation linear models, indicating want model carp occurrences function four predictor variables. ’ll use fish_binary dataset . Finally need select ‘family’ error distribution response variable. presence/absence data, binomial distribution typically chosen ’s distribution two states, typically 1 “success” 0 “failure.”can look results model summary function.summary function generates output similar ’ve observed linear modeling. Estimate column shows us parameter estimate different model parameters, can also get indication whether parameters considered significant, e.g., p-values less 0.05. , see parameters considered significant, except conductivity.interpret model coefficient values? Let’s look values :logistic regression involves logit link function, ’s easy linear modeling. , coefficient values can interpreted additive effect , example, temperature log odds success.odds ratio interpretable log odds. get taking inverse natural log coefficicent values, words raising e power coefficients. R, use exp() function .values indicate odds occurrence 2.71 times (171% higher) depth increases meter.can now use ggplot generate graph model results looking effect depth Carp occurrence probability. Note, however, approximate, model also included parameters, plot merely considers depth.","code":"\nglm.bin<- glm(CARP ~ secchi + temp + depth + cond,\n            data = fish_binary,\n            family = binomial)\nsummary(glm.bin)## \n## Call:\n## glm(formula = CARP ~ secchi + temp + depth + cond, family = binomial, \n##     data = fish_binary)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -1.2036029  0.5342537  -2.253  0.02427 *  \n## secchi      -0.0322025  0.0035546  -9.059  < 2e-16 ***\n## temp         0.0957375  0.0191719   4.994 5.93e-07 ***\n## depth        0.9963667  0.2239745   4.449 8.64e-06 ***\n## cond         0.0027675  0.0009828   2.816  0.00486 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 1074.79  on 777  degrees of freedom\n## Residual deviance:  936.89  on 773  degrees of freedom\n##   (68 observations deleted due to missingness)\n## AIC: 946.89\n## \n## Number of Fisher Scoring iterations: 3\n# Extracting model coefficients\nglm.bin$coefficients##  (Intercept)       secchi         temp        depth         cond \n## -1.203602861 -0.032202531  0.095737510  0.996366684  0.002767454\nexp(glm.bin$coefficient)## (Intercept)      secchi        temp       depth        cond \n##   0.3001110   0.9683104   1.1004702   2.7084234   1.0027713\nggplot(fish_binary, aes(x = depth, y = CARP)) +\n  geom_jitter(height = 0.05, width = 0.05) +\n  stat_smooth(\n    method = \"glm\",\n    method.args = list(family = binomial),\n    se = TRUE\n  ) +\n  xlab(\"Depth (m)\") +\n  ylab(\"Probability of presence\") +\n  ggtitle(\"Probability of presence of  Carp as a function of depth\") +\n  theme_classic()## `geom_smooth()` using formula = 'y ~ x'"},{"path":"generalized-linear-models.html","id":"glm-with-the-tidymodels-package","chapter":"11 Generalized Linear Models","heading":"11.2.1.3 GLM with the tidymodels package","text":"R, certain kinds analysis, may different packages can perform statistical procedures, different strengths. simple glm CARP, glm function base R works well, model complexity increases may instances additional capacities make sense. One package enables tidymodels package, ’ll first introduce , can come back later. following code implements type analysis, now using tidymodels code.want model counts?interpret coefficients, can say one-unit increase current, log count \nY increases significantly 5.246739516, expected count increases 189.85\nexp(5.246739516)≈189.85. one-unit increase current lot scale, though may better consider 0.1 m/s increase current increases counts 19 fishTidymodels version","code":"\n# Load required libraries\nlibrary(tidymodels)\n\nresults <- data.frame()\n\nfor (i in 1:length(species)){\n\ndata <- fish_binary %>%\n  rename(species = species[i])\n\n# Split the data into training and testing sets\nset.seed(123)\ndata_split <- initial_split(data, prop = 0.8)\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)\n\n# Specify the model: GLM for regression\nglm_spec <- linear_reg() %>%\n  set_engine(\"glm\") %>%\n  set_mode(\"regression\")\n\n# Define a recipe: Preprocessing steps\nglm_recipe <- recipe(species ~ secchi + temp + depth + current + do, data = train_data) %>%\n  step_normalize(all_numeric_predictors())\n\n# Create a workflow\nglm_workflow <- workflow() %>%\n  add_recipe(glm_recipe) %>%\n  add_model(glm_spec)\n\n# Perform 10-fold cross-validation\nset.seed(123)\ncv_splits <- vfold_cv(train_data, v = 10)\n\n# Fit the model with cross-validation\ncv_results <- fit_resamples(\n  glm_workflow,\n  resamples = cv_splits,\n  metrics = metric_set(rmse, rsq),\n  control = control_resamples(save_pred = TRUE)\n)\n\n# View cross-validation metrics\ncollect_metrics(cv_results)\n\n# Finalize the model on the entire training set\nfinal_glm <- fit(glm_workflow, data = train_data)\n\n# Test the finalized model on the testing set\ntest_results <- predict(final_glm, test_data) %>%\n  bind_cols(test_data) %>%\n  metrics(truth = species, estimate = .pred) %>%\n  mutate(sp = species[i])\n\n#print(test_results)\n\nresults <- bind_rows(results, test_results)\n\n}\n# Load required libraries\numr_sub %>%\n  select(LMBS, secchi:do) %>%\n  pivot_longer(cols = secchi:do, names_to = \"variable\", values_to = \"value\") %>%\n  ggplot(aes(value, LMBS))+\n  geom_jitter(height = .05, pch = 21, alpha =0.5)+\n  geom_smooth(method = \"glm\")+\n  facet_wrap(~variable, nrow = 2, scales = \"free_x\")\nglm.poisson = glm(LMBS ~ secchi + temp + depth + current + do,\n  data = umr_sub,\n  family = poisson) # this is what makes it a Poisson GLM! Note the default link is log.\n\nsummary(glm.poisson)## \n## Call:\n## glm(formula = LMBS ~ secchi + temp + depth + current + do, family = poisson, \n##     data = umr_sub)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)  2.1876972  0.0730252  29.958  < 2e-16 ***\n## secchi       0.0060138  0.0003939  15.268  < 2e-16 ***\n## temp         0.0305910  0.0024742  12.364  < 2e-16 ***\n## depth       -0.1558713  0.0317927  -4.903 9.45e-07 ***\n## current     -1.7909347  0.1238641 -14.459  < 2e-16 ***\n## do           0.0262556  0.0042626   6.160 7.30e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 10137.7  on 496  degrees of freedom\n## Residual deviance:  9474.3  on 491  degrees of freedom\n##   (349 observations deleted due to missingness)\n## AIC: 11573\n## \n## Number of Fisher Scoring iterations: 5\nglm.poisson$coefficients\nlibrary(poissonreg)\n\nresults_counts <- data.frame()\n\nfor (i in 1:length(species)){\n\ndata <- umr_sub %>%\n  rename(count = species[i])\n\n# Split the data into training and testing sets\nset.seed(123)\ndata_split <- initial_split(data, prop = 0.8)\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)\n\n# Specify the model: Poisson Regression\npoisson_spec <- poisson_reg() %>%\n  set_engine(\"glm\") %>%\n  set_mode(\"regression\")\n\n# Specify the model: Negative Binomial Regression\n#nb_spec <- gen_additive_mod() %>%\n # set_engine(\"glm\", family = MASS::negative.binomial(theta = 1)) %>%\n  #set_mode(\"regression\")\n\n# Define a recipe: Preprocessing steps\nreg_recipe <- recipe(count ~ secchi + temp + depth + current + do, data = train_data) %>%\n  step_normalize(all_numeric_predictors())\n\n# Create workflows\npoisson_workflow <- workflow() %>%\n  add_recipe(reg_recipe) %>%\n  add_model(poisson_spec)\n\n#nb_workflow <- workflow() %>%\n # add_recipe(reg_recipe) %>%\n  #add_model(nb_spec)\n\n# Perform 10-fold cross-validation\nset.seed(123)\ncv_splits <- vfold_cv(train_data, v = 10)\n\n# Fit the Poisson model with cross-validation\npoisson_cv_results <- fit_resamples(\n  poisson_workflow,\n  resamples = cv_splits,\n  metrics = metric_set(rmse, mae, rsq),\n  control = control_resamples(save_pred = TRUE)\n)\n\n# Fit the Negative Binomial model with cross-validation\n# nb_cv_results <- fit_resamples(\n#   nb_workflow,\n#   resamples = cv_splits,\n#   metrics = metric_set(rmse, mae, rsq),\n#   control = control_resamples(save_pred = TRUE)\n# )\n\n# View cross-validation metrics\nprint(species[i])\ncat(\"Poisson Regression Metrics:\\n\")\ncollect_metrics(poisson_cv_results)\n\n#cat(\"\\nNegative Binomial Regression Metrics:\\n\")\n#collect_metrics(nb_cv_results)\n\n# Finalize and test the Poisson model\nfinal_poisson <- fit(poisson_workflow, data = train_data)\npoisson_test_results <- predict(final_poisson, test_data) %>%\n  bind_cols(test_data) %>%\n  metrics(truth = count, estimate = .pred) %>%\n  mutate(sp = species[i],\n         model = \"pois\")\n\n# Finalize and test the Negative Binomial model\n#final_nb <- fit(nb_workflow, data = train_data)\n#nb_test_results <- predict(final_nb, test_data) %>%\n # bind_cols(test_data) %>%\n  #metrics(truth = count, estimate = .pred) %>%\n  #mutate(sp = comm_sp[i],\n   #      model = \"nb\")\n\nresults_counts <- bind_rows(results_counts, poisson_test_results)#, nb_test_results)\n\n}"},{"path":"random-effects.html","id":"random-effects","chapter":"12 Random Effects","heading":"12 Random Effects","text":"","code":""},{"path":"random-forest.html","id":"random-forest","chapter":"13 Random Forest","heading":"13 Random Forest","text":"Adapted Carpentries workshop\nhttps://carpentries-incubator.github.io/r-ml-tabular-data/Random forest portion :\nhttps://carpentries-incubator.github.io/r-ml-tabular-data/04-Decision-Forests/index.html","code":""},{"path":"boosted-regression-trees.html","id":"boosted-regression-trees","chapter":"14 Boosted Regression Trees","heading":"14 Boosted Regression Trees","text":"Adapted Carpentries workshop\nhttps://carpentries-incubator.github.io/r-ml-tabular-data/Boosted trees portion \nhttps://carpentries-incubator.github.io/r-ml-tabular-data/05-Gradient-Boosting/index.html","code":""},{"path":"population-modeling.html","id":"population-modeling","chapter":"15 Population Modeling","heading":"15 Population Modeling","text":"","code":""},{"path":"population-modeling.html","id":"occupancy-models-in-r-with-unmarked-james-paterson","chapter":"15 Population Modeling","heading":"15.0.1 Occupancy models in R with unmarked: James Paterson","text":"Intro occupancy models\nhttps://jamesepaterson.github.io/jamespatersonblog/2020-09-01_occupancyintroduction.htmlPart 2: Comparing Occ. Models\nhttps://jamesepaterson.weebly.com/blog/occupancy-models--r-part-2-model-comparisonsDynamic occupancy modeling:\nhttps://jamesepaterson.github.io/jamespatersonblog/2021-01-01_dynamicoccupancy.htmlSee mark recapture models (e.g., JS, CJS):\nhttps://jamesepaterson.weebly.com/blog","code":""},{"path":"population-modeling.html","id":"course-outline","chapter":"15 Population Modeling","heading":"15.1 Course outline","text":"Population modeling\nBackground population modeling, drawing :\nPrimer Ecology using R (https://hankstevens.github.io/Primer--Ecology/expo.html)\nModeling Population Growth module UNL (https://dshizuka.github.io/RCourse/09.2.PopGrowth.html)\n\nDensity independent growth\nDensity-independent demography\nDensity dependent growth\nPopulations space\nUse simple analyses Wenger et al. (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ece3.9339) demonstrate relating poulations environmental covariates\nBackground population modeling, drawing :\nPrimer Ecology using R (https://hankstevens.github.io/Primer--Ecology/expo.html)\nModeling Population Growth module UNL (https://dshizuka.github.io/RCourse/09.2.PopGrowth.html)\nPrimer Ecology using R (https://hankstevens.github.io/Primer--Ecology/expo.html)Modeling Population Growth module UNL (https://dshizuka.github.io/RCourse/09.2.PopGrowth.html)Density independent growthDensity-independent demographyDensity dependent growthPopulations spaceUse simple analyses Wenger et al. (https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ece3.9339) demonstrate relating poulations environmental covariates","code":""},{"path":"network-models-and-connectivity.html","id":"network-models-and-connectivity","chapter":"16 Network Models and Connectivity","heading":"16 Network Models and Connectivity","text":"Placeholder edited exploration WUCT Tool, combined materials WUCT Github repoCan also consider tutorial Riverconn package\nhttps://cran.r-project.org/web/packages/riverconn/vignettes/Tutorial.html","code":""},{"path":"network-models-and-connectivity.html","id":"overview-1","chapter":"16 Network Models and Connectivity","heading":"16.1 Overview","text":"model document describes procedure quantifying benefits associated removal organism movement barriers within watershed (e.g., dam removal, culvert repair, fish ladder installation) impacts barrier addition (e.g., dam construction, weir installation). model focuses upstream movement migratory organisms fish intended application watershed-scale.algorithm based four primary components: habitat quantity upstream dam, habitat quality upstream dam, passability structure given organism, shape/topology watershed. algorithm combines data estimate quality-weighted, accessible habitat watershed scale. model documentation intented U.S. Army Corps Engineers (USACE) model certification process details development, technical details, application adaptable modeling framework.","code":""},{"path":"network-models-and-connectivity.html","id":"background","chapter":"16 Network Models and Connectivity","heading":"16.2 Background","text":"Water resources transportation infrastructure dams culverts provide countless socio-economic benefits; however, infrastructure can also disconnect movement organisms, sediment, water river ecosystems (Pringle 2001). Trade-offs associated competing costs benefits occur globally, applications barrier addition (e.g., dam road construction), reengineering (e.g., culvert repair, fish ladder installation), removal (e.g., dam removal aging infrastructure). Nationwide, millions barriers inhibit movement aquatic organisms, barrier removal repair emerged key techniques river restoration. 2016, 1,200 dams removed nationwide (Bellmore et al. 2016) well countless road-stream crossings repaired facilitate movement (Januchowski-Hartley et al. 2013).Restoration practitioners require tools informing barrier removal, repair, retrofit decisions. important application rapid selection efficient sites removal, given large number watershed barriers (.e., barrier-barrier-B priority restoration?). Another application computation restoration benefits particular site compare relative effects alternative management actions (e.g., fish ladder dam removal preferrable?). Dozens studies globally examined questions different methods techniques (O’Hanley Tomberlin 2005, Neeson et al. 2015, McKay et al. 2016).document reviews development framework prioritizing barriers quantifying benefits restoration actions watershed-scale. purpose model assess watershed scale habitat connectivity quality migratory organisms inform restoration planning. framework adaptable varying project timelines, scopes, applications. following issues crucial scoping application framework:focus migratory organisms moving upstream watershed (e.g., salmon seeking access breeding habitat). Downstream movement considered limiting model framework neglected, although can important limiting factor species.framework focuses quantifying accessibility habitat focal taxa, habitat quantity quality can incorporated multiple methods.Overall, modeling approach may used rapidly screen barriers site selection quantify benefits alternative restoration actions site scale. simplicity, document refer methods “barrier prioritization techniques”.framework can used context benefits barrier removal desired taxa impacts barrier removal relative invasive species. either case, watershed connectivity may assessed following procedure, interpretation results may different. instance, user may chose maximize connectivity desirable species minimizing connectivity invasive species.Many barrier prioritization studies address multiple taxa development watershed priorities. framework applied multiple taxa separately (.e., developing connectivity estimates taxa), overall assessment obtained using combined metric (e.g., sum average connected habitat species).Given scoping factors, model referred Watershed-Scale Upstream Connectivity Toolkit (WUCT). document intends record WUCT framework’s technical details, use, relevant information purpose USACE planning model certification requirement (EC 1105-2-412, PB 2013-02). Regional certification requested, procedure recommended tailoring framework local applications.","code":""},{"path":"network-models-and-connectivity.html","id":"application-bronx-river","chapter":"16 Network Models and Connectivity","heading":"16.3 Application: Bronx River","text":"model application examines fish passage prioritization Hudson-Raritan Estuary (HRE) project led USACE New York District (NAN). Specifically, application quantifies fish passage benefits associated two sites Bronx River watershed, proposed 2017 Draft Feasibility Report (USACE 2017) supported Comprehensive Restoration Plan (USACE 2016). Fish passage outputs quantified terms “accessible habitat” using Watershed-Scale Upstream Connectivity Toolkit (WUCT) river herring focal taxa.Three dams interest Bronx River system moving downstream upstream. First, East 182nd Street Dam first barrier encountered, fish ladder (Alaskan Steep pass) constructed partners including NYC Parks, Bronx Borough, Wildlife Conservation Society, National Oceanic Atmospheric Administration, US Fish Wildlife Service, New York State, National Fish Wildlife Foundation (Lumbian Larson 2015). Second, Bronx Zoo Dam next structure, USACE proposed three restoration alternatives part feasibility study (including fish ladder). Third, Stone Mill Dam (aka. Snuff Mill Dam) next structure, USACE proposed three restoration alternatives part feasibility study (one fish ladder + attractors, one fish ladder, one without fish ladder). significant amount habitat accessible Stone Mill Dam, considering main steam tributary habitats. Bronx River shown support river herring populations, accessibility limiting (Larson Sugar 2004), 182nd St Dam fish ladder subsequently demonstrated river herring utilize technical fishways region.WUCT requires three general types inputs, HRE parameterization follows (also shown Table 3):Habitat Quantity - barrier, area upstream habitat opened used primary basis habitat quantity. First, length upstream habitat computed (.e., distance dam next upstream barrier) included tributary habitats newly accessible. River width estimated aerial photos Google Earth smallest observable width upstream structure (.e., extremely conservative estimate). create area-based metric , length river multiplied width.Habitat Quality - Habitat quality predicted based watershed-scale, geospatial analysis upstream habitat presented McKay et al. (2017). model included three metrics accounting land use development pressure, water quality, proportion basin conservation status.Passability - Local studies fish passage rates (.e., passability) unavailable Bronx River. , passability estimated based studies elsewhere efficacy technical fishways general river herring specifically. Prior restoration actions, structures assumed zero passage river herring. Alewife studies New England (Franklin et al. 2012) report high overall passage rates 64-99% passage East River, Massachusetts particularly high rates technical steep passes 94-97%. values line meta-analysis 65 published fish passage studies (Noonan et al. 2011), indicated fish passage efforts typically result 42% fish passage average across variety taxa. Based Massachusetts data, used 80% passability fish ladders conservative estimate passage efficiency. 182nd Street Dam Ladder included analyses part future without prokect condition. Stone Mill Dam, Alternative-includes fish attractors increase utilization ladder, assumed increase passability 10% (.e., 88% total).following script imports data, isolates necessary input data, computes permutations restoration actions, computes connectivity watershed-scale restoration plan. Table 4 presents output WUCT application. connectivity values represent connectivity- quality-weighted assessment total habitat watershed scale.EVAL FALSE NOWTable 16.1: Table 3. Input data WUCT Bronx River described text. node specifies existing condition (shown Alt=0), multiple restoration alternatives also specified node (shown Alt>0).Create connectivity function. Perhaps can loaded.Table 16.2: Table 4. Alternatives analysis using WUCT Bronx River Watershed. Competing restoration alternatives shown rows, alternative used plan denoted number shown.","code":"\n#Dummy example - Import data\nbarrieralts <- read.csv(\"data/WUCT_HREData_2018-07-18_BarrierAlts.csv\", header=TRUE, dec=\".\")\nA <- data.matrix(read.csv(\"data/WUCT_HREData_2018-07-18_Adjacency.csv\", header=FALSE, dec=\".\"))\n\n##########\n#Send input data from the example problem as a table\nknitr::kable(barrieralts, caption=\"Table 3. Input data for the WUCT to the Bronx River as described in the text. Each node specifies the existing condition (shown as Alt=0), and multiple restoration alternatives are also be specified for each node (shown as Alt>0).\")\n#Isolate properties of the alternatives at each barrier\nbnames <- paste(unique(barrieralts$BarrierID))\nnbar <- length(bnames)\n\n##########\n#Compute the number of alternatives at each barrier\nnalts <- c()\nfor(i in 1:nbar){nalts[i] <- length(which(barrieralts$BarrierID == bnames[i]))}\nnalts.total <- prod(nalts) #Compute the total number of combinations of actions\n\n##########\n#Create a list which stores all alternatives at each site\n  #This list stores the row number of each alternative from \"barrieralts\".\nsite.alts <- list() #Create an empty list to store the combinations of sites/alts\nfor(i in 1:nbar){site.alts[i] <- list(which(barrieralts$BarrierID == bnames[i]))}\n\n#Compute all combinations of alternatives and sites\n  #This returns a data frame where each columns is a site or barrier and each row is a unique plan with a combination of sites and alternatives.\nsitealts.combos <- expand.grid(site.alts)\n\n#Convert this data frame to a matrix \nsitealts.combos <- data.matrix(sitealts.combos)\n\n##########\n#Compute connectivity for each plan\nWC.out <- c() #Empty vector to store watershed connectivity for each plan\nfor(i in 1:nalts.total){\n  #Isolate the passability and habitat values to be used\n  pass.temp <- barrieralts$Passability[sitealts.combos[i,]]\n  hab.temp <- barrieralts$QualityUpstream[sitealts.combos[i,]] * barrieralts$QuantityUpstream[sitealts.combos[i,]]\n  \n  #Compute connectivity and store result\n  WC.out[i] <- connectivity(nbar,A,pass.temp,hab.temp)\n}\n\n##########\n#Send output from the example problem as a table\nWC.HRE <- matrix(NA, nrow=nalts.total,ncol=nbar+2)\nfor(i in 1:nalts.total){WC.HRE[i,] <- c(i,barrieralts$Alt[sitealts.combos[i,]],WC.out[i])}\ncolnames(WC.HRE) <- c(\"Plan\",bnames,\"Connectivity\")\nknitr::kable(WC.HRE, caption=\"Table 4. Alternatives analysis using the WUCT in the Bronx River Watershed. Competing restoration alternatives are shown as rows, and the alternative used in the plan is denoted by the number shown.\")"},{"path":"agent-based-models.html","id":"agent-based-models","chapter":"17 Agent-based Models","heading":"17 Agent-based Models","text":"Consider exploring abmR package conduct agent-based models Rhttps://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14014","code":""},{"path":"decision-support.html","id":"decision-support","chapter":"18 Decision Support","heading":"18 Decision Support","text":"Using ecological model output restoration decisions.","code":""},{"path":"cost-effectiveness-and-incremental-cost-analysis-ceica-with-ecorest.html","id":"cost-effectiveness-and-incremental-cost-analysis-ceica-with-ecorest","chapter":"19 Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest","heading":"19 Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest","text":"module teach use ecorest package R efficiently reproducibly carry Cost Effectivness Incremental Cost Analysis (CEICA) generate useful output like just lines code:","code":""},{"path":"cost-effectiveness-and-incremental-cost-analysis-ceica-with-ecorest.html","id":"background-on-cost-effectivness-and-incremental-cost-analysis","chapter":"19 Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest","heading":"19.1 Background on Cost Effectivness and Incremental Cost Analysis","text":"PARE SECTION DOWNThe USACE ecosystem restoration mission first authorized Water Resources Development Act 1986 stated purpose “…restore significant structure, function dynamic processes degraded” (USACE 1999, ER 1165-2-501). Given goal, USACE programs emphasize ecological outcomes (opposed social economic outcomes). Generally, ecological resources may quantified variety ways ranging habitat suitability focal taxa (e.g., endangered species) changes physical processes (e.g., sediment delivery geomorphic change) changes biological processes (e.g., carbon uptake storage). USACE business lines (e.g., navigation), costs benefits actions compared monetary terms, benefit-cost ratio serves crucial decision metric. However, outputs restoration typically monetized, different set methods required inform restoration decision-making address issue “ecosystem restoration worth Federal investment?” particular, cost-effectiveness incremental cost analyses provide techniques comparing non-monetary ecological benefits relative monetary costs restoration actions (Robinson et al. 1995).Cost-effectiveness incremental cost analyses (CEICA) analytical tools assessing relative benefits costs ecosystem restoration actions informing decisions. Benefits costs assessed prior analyses using ecological models (e.g., index models) cost engineering methods, respectively. CEICA may conducted site scale compare alternatives single location (e.g., action vs. dam removal vs. fish ladder) system scale compare relative merits multiple sites (e.g., sites vs. Site-vs. Site-B vs. Site-Site-B). Within USACE, Institute Water Resources provided toolkit conducting CEICA, IWR Planning Suite (http://www.iwr.usace.army.mil/Missions/Economics/IWR-Planning-Suite/).Cost-effectiveness analysis provides mechanism examining efficiency alternative actions. given level investment, agency wants identify plan return--investment (.e., environmental benefits), given level environmental benefits, agency wants plan least cost. “efficiency frontier” identifies plans efficiently provide benefits per cost basis (.e., cost-effective plans). “non-dominated” alternatives compose Pareto-optimal frontier.Incremental cost analysis conducted set cost-effective plans. technique sequentially compares plan higher cost plans reveal changes unit cost output levels increase eliminates plans efficiently provide benefits per unit cost basis. Specifically, analysis examines slope cost-effectiveness frontier isolate incremental unit cost ($/unit) increases magnitude environmental benefit increases. Incremental cost analysis ultimately intended inform decision-makers consequences increasing unit cost increasing benefits (.e., unit becomes expensive). Plans emerging incremental cost analysis efficiently accomplish objective relative unit costs typically referred “best buys”. Importantly, “best buys” cost-effective, cost-effective plans best buys.demonstrate CEICA analysis, use example Beaver Island HREP project. PROVIDE BACKGROUND HERERead cost benefit data:","code":"\nlibrary(tidyverse)\nlibrary(ecorest)\n\n# Most basic with Beaver Island\ndf <- read_csv(\"data/beaver_island_cost_ben.csv\")\n\nknitr::kable(df, padding = 2)"},{"path":"cost-effectiveness-and-incremental-cost-analysis-ceica-with-ecorest.html","id":"ceica-with-ecorest-in-4-easy-steps","chapter":"19 Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest","heading":"19.2 CEICA with ecorest in 4 easy steps!","text":"Section X.X tutorial walks CEICA works step--step develop deeper understanding analysis actually . first, demonstrate easy process using functions ecorest package. following code everything one needs determine alternatives cost effective ‘best buys’, plot results.First, determine project alternatives cost effective using CEfinder function.\ninputs consist 2 vectors: 1) Project benefits; 2) Project annualized costsThe output vector 1s 0s, 1s cost effective options.Next, determine cost effective alternatives ‘best buys’ using BBfinder function\ninputs vectors benefits costs, well vector cost effectiveness scores ’ve just calculated.output BB function list comprised two dataframes. first data frame columns restoration benefits, costs, whether alternatives cost effectiveness best buys.second dataframe features cost, benefit, incremental costs per benefit best buy compared previous best buy. example, third best buy costs 3.18026^{5} second best buy, yields additional benefits 45 habitat units. dividing incremental costs benefits, can see per-unit incremental cost best buy three 7067.24Now ’ve determined cost effective best buy options can create table output. Note: BB object list two dataframes, need extract just column 1s 0s indicating “best buy” status. , use code BB[[1]][,4], pulls first dataframe list (.e., [[1]]), fourth column dataframe (.e., [,4]). See information subsetting brackets.Finally, can use CEICAplotter function create plots depicting results cost effectiveness analysis, incremental cost analysis. 5 required inputs function project alternative names, benefits, annualized costs, cost effectiveness score, best buy score, file name plot.","code":"\nrestCE <- CEfinder(df$RestBen, df$AnnCost)\nrestCE##  [1] 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1\nBB <- BBfinder(df$RestBen, df$AnnCost, restCE)\nBB## [[1]]\n##       benefit    cost CE BB\n##  [1,]     0.0       0  1  1\n##  [2,]   162.5  496526  1  0\n##  [3,]   163.4  499260  1  0\n##  [4,]   172.1  513615  1  0\n##  [5,]   179.2  518462  1  1\n##  [6,]   196.1  721698  0  0\n##  [7,]   203.1  804896  0  0\n##  [8,]   203.2  719258  1  0\n##  [9,]   210.2  809741  1  0\n## [10,]   217.1  831390  1  0\n## [11,]   224.2  836488  1  1\n## [12,]   224.5  927732  1  0\n## [13,]   207.5  933020  0  0\n## [14,]   233.1  944914  1  0\n## [15,]   240.2  950447  1  1\n## [16,]   252.1 1117284  1  0\n## [17,]   259.2 1120429  1  0\n## [18,]   262.1 1202194  1  0\n## [19,]   269.2 1204094  1  1\n## \n## [[2]]\n##      benefit    cost  inccost\n## [1,]     0.0       0    0.000\n## [2,]   179.2  518462 2893.203\n## [3,]   224.2  836488 7067.244\n## [4,]   240.2  950447 7122.438\n## [5,]   269.2 1204094 8746.448\n#Create a table of the results\ndf %>% \n  select(AltID, RestBen, AnnCost, AvgCost) %>%\n  mutate(CE = restCE,\n         BB = BB[[1]][,4]) %>%\n  knitr::kable(padding = 2)\n# Create a plot of CEICA results\nCEICAplotter(df$AltID, df$RestBen, df$AnnCost, restCE, BB[[1]][,4], \"images/CEICAexample1.jpeg\")"},{"path":"cost-effectiveness-and-incremental-cost-analysis-ceica-with-ecorest.html","id":"ceica-in-depth","chapter":"19 Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest","heading":"19.3 CEICA in-depth","text":"’ve seen CEICA can accomplished quickly code. However, user wishes understanding projects determined cost effective best buys, go greater depth .first component CEICA cost effectiveness analysis., alternative, ask: alternatives produce higher ecological outcomes equal lower costs?\nanswer yes, alternative considered non-cost effective.Non-cost effectiveness can though two ways:\nInefficient Production: alternative output level can generated lesser cost another alternativeIneffective Production: alternative greater output level can generated lesser equal cost another alternativeLet’s look closely cost/benefit data :first alternative, cost $0, considered cost effective, projects lesser equal cost. let’s look second option see ’s cost effective. , first see alternatives greater benefitsThis shows position benefit vector projects greater values.Now, ’re looking see projects equal greater benefits lower costs.value 1 indicates alternatives level benefits low cost.Let’s look different alternative: Alternatuve E2L1, sixth alternative:suggests another alternative greater equal level benefits costs less E2L1. index value 3 (compared index value 1 E2L1), suggests ’s two projects E2L1 project list: E2L2, lower cost higher benefit. Therefore, E2L1 considered cost effective.iterate project ’ve just done, can use loop, following code indicatesThis lets us quickly see alternatives cost-effective .","code":"\ndf %>% select(AltID, AnnCost, RestBen) %>% knitr::kable()\n# Vectors defined to make calculations easier\nbenefit <- df$RestBen\ncost <- df$AnnCost\n\n#Find which projects have greater than or equal benefits than the second project's benefits\ngreater_bens <- which(benefit >= benefit[2])\ngreater_bens##  [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\nwhich(cost[greater_bens] <= cost[2])## [1] 1\ngreater_bens <- which(benefit >= benefit[6])\ngreater_bens##  [1]  6  7  8  9 10 11 12 13 14 15 16 17 18 19\nwhich(cost[greater_bens] <= cost[6])## [1] 1 3\n# Set up empty vector to store whether each alternative is cost effective\nCE <- c()\n\n# Iterate through each project to see if another project renders that one cost ineffective\n# An ifelse statement assigns a value of 1 to projects that are cost effective, and 0 to ones that are not\nfor (i in 1:length(benefit)) {\n        bigben <- which(benefit >= benefit[i])\n        CE[i] <- ifelse(length(which(cost[bigben] <= cost[i])) == \n            1, 1, 0)\n    }\n\ncbind(df$AltID, CE)##              CE \n##  [1,] \"0\"    \"1\"\n##  [2,] \"D2L3\" \"1\"\n##  [3,] \"D2L4\" \"1\"\n##  [4,] \"D2L1\" \"1\"\n##  [5,] \"D2L2\" \"1\"\n##  [6,] \"E2L1\" \"0\"\n##  [7,] \"F2L1\" \"0\"\n##  [8,] \"E2L2\" \"1\"\n##  [9,] \"F2L2\" \"1\"\n## [10,] \"H2L1\" \"1\"\n## [11,] \"H2L2\" \"1\"\n## [12,] \"I2L3\" \"1\"\n## [13,] \"H2L3\" \"0\"\n## [14,] \"G2L1\" \"1\"\n## [15,] \"G2L2\" \"1\"\n## [16,] \"J2L1\" \"1\"\n## [17,] \"J2L2\" \"1\"\n## [18,] \"K2L1\" \"1\"\n## [19,] \"K2L2\" \"1\""},{"path":"cost-effectiveness-and-incremental-cost-analysis-ceica-with-ecorest.html","id":"identifying-best-buys","chapter":"19 Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest","heading":"19.4 Identifying ‘best buys’","text":"Identifying best buys matter finding cost effective alternatives can increase environmental benefits lowest incremental cost (.e., lowest cost per additional habitat unit).first best buy always one lowest average cost 0.NEED ANNOTATE MOREThis indicates 9th option (among cost effective options) next best oneThe user iterate “hand” options. iterations required, often great time use -loops. following code accomplishes . code nearly identical ’ve already run. main difference use BB object store alternatives best buys sure iteration, new set alternatives consider exclusively subsequent iterations.NEED FIX THISThis indicates best buys positions 1, 5, 9, 12, 16 cost effective vector. see projects can run following code. first subsets Project ID column just alternatives cost effective, options, finds alt ID’s positions stored BB option (e.g., first, fifth, ninth, etc. IDs).","code":"\n# We can start again with our vectors of benefits, and costs, but we also now have a vector of cost effectiveness  \n\n#First we filter to just cost effective benefits and costs\nben.CE <- benefit[which(CE == 1)]\ncost.CE <- cost[which(CE == 1)]\n\n# Reorder benefits and costs from lowest to greatest cost\nben.CE2 <- ben.CE[order(cost.CE)] \ncost.CE2 <- cost.CE[order(cost.CE)]\n\n#All costs and benefits are greater, so we can look at the incremental costs of all others options to find the best_buy\ninccost <- (cost.CE[-1] - cost.CE2[1])/(ben.CE2[-1] - ben.CE2[1])\n            \ninccost##  [1] 3055.545 3055.447 2984.399 2893.203 3539.656 3852.241 3829.526 3730.990 4132.437 4053.685\n## [11] 3956.898 4431.908 4322.643 4586.776 4472.860\nwhich(inccost == min(inccost)) + 1## [1] 5\n#This indicates that the fifth alternative is the second best-buy after zero\n\n# To look for the next best buy, we want to just look at projects after the fifth project\nce.bentemp <- ben.CE2[-1:-5] # Selects all the project benefits with greater benefits than the current best buy\nce.costtemp <- cost.CE2[-1:-5] # All the project costs with greater costs than current best buy\ninccost <- (ce.costtemp - cost.CE2[5])/(ce.bentemp - ben.CE2[5]) # calculate avg. costs from each costlier option compared to the current best buy\n\ninccost  ##  [1] 8366.500 9396.097 8256.675 7067.244 9034.658 7911.911 7081.721 8214.294 7524.587 8247.672\n## [11] 7618.133\nwhich(inccost == min(inccost)) + 5## [1] 9\nBB <- c(1)\nnCE <- length(CE)\n\nfor (i in 1:nCE) {\n        ce.bentemp <- ben.CE2[-1:-BB[i]] # Selects all the project benefits with greater benefits than the current best buy\n        ce.costtemp <- cost.CE2[-1:-BB[i]] # All the project costs with greater costs than current best buy\n        inccost <- (ce.costtemp - cost.CE2[BB[i]])/(ce.bentemp - # calculate incremental costs from each subsequent option compared to the current best buy\n            ben.CE2[BB[i]])\n        BB[i + 1] <- which(inccost == min(inccost)) + BB[i] # Of all the incremental costs above this best_buy, which has the lowest?\n        if (BB[i + 1] >= nCE) {\n            break\n        }\n    }\n\nBB"},{"path":"annualizing-benefits-and-costs.html","id":"annualizing-benefits-and-costs","chapter":"20 Annualizing benefits and costs","heading":"20 Annualizing benefits and costs","text":"module teach use ecorest EngrEcon packages R efficiently reproducibly calculated annualized benefits costs restoration project planning:","code":""},{"path":"annualizing-benefits-and-costs.html","id":"background-on-annualization","chapter":"20 Annualizing benefits and costs","heading":"20.1 Background on annualization","text":"Annualization technique determining costs benefits projects annual time scale, regardless overall time horizon project. Calculating annualized costs benefits important component restoration planning enables fair comparison alternatives project whose costs /benefits occur different periods time following implementtion.","code":""},{"path":"annualizing-benefits-and-costs.html","id":"annualizing-benefits","chapter":"20 Annualizing benefits and costs","heading":"20.2 Annualizing benefits","text":"Annualization benefits can easily carried ecorest package. ALong ecorest also load tidyverse package plotting/wrangling EngrEcon package cost annualization.Imagine simple scenario ecosystem restoration benefits calculated four time periods. can store benefits dataframe plot ggplot follows:ecorest package provides easy way achieve annualizer function, computes “time-averaged quantities based linear interpolation,” exactly .Inputs function : 1) vector time intervals \n2) vector values interpolate>indicates annualized ecological benefits project 87.2 units (e.g., acres, habitat units, etc.)","code":"\nlibrary(tidyverse)\nlibrary(ecorest)\nlibrary(EngrEcon)\n#User-specified time intervals\nben_df <- data.frame(year = c(0,2,20,50),\n                     ben = c(0,100,90,80))\n\np <- ggplot(ben_df)+\n    geom_point(aes(year, ben), size = 2)+\n    geom_line(aes(year, ben))+\n  labs(x = \"Year\", y = \"Benefits\")+\n  theme_classic()\n  \np\ndf_rect <- tibble(xmin = ben_df$year[2:3],\n                  xmax = ben_df$year[3:4],\n                  ymin = c(0,0),\n                  ymax = ben_df$ben[3:4])\n\np + geom_rect(data = df_rect,\n            aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n            fill = NA, lty = \"dashed\", color = \"black\")\nannualizer(ben_df$year, ben_df$ben)## [1] 87.2"},{"path":"annualizing-benefits-and-costs.html","id":"annualizing-costs","chapter":"20 Annualizing benefits and costs","heading":"20.3 Annualizing costs","text":"Cost annualization carried fair comparisons can made projects different temporal scales.EDIT FOLLOWING.Cost estimates compiled site-scale restoration action following standard cost engineering methods. phase, construction cost represents parametric cost comparative purposes , confined construction activities. real estate, pre-construction engineering design, construction management, cultural resources costs included present.Monitoring adaptive management typically conducted ten-year window ecosystem restoration projects (WRDA 2007, Section 2036). Monitoring cost estimated four points time, sampling event pre-construction engineering design well sampling years 1, 3, 5 following construction. sampling event assumed collection data fish communities, invertebrate communities, bathymetric mapping, hydraulic outcomes. Adaptive management estimated proportion construction cost ranging 7.5% 25% depending site- alternative-complexity (Appendix B).Operations, maintenance, repair, replacement, rehabilitation (OMRRR) costs estimated relative four common practices. First, quarterly site visits planned general maintenance small-scale restoration features, trash removal, minor maintenance educational features (signage, benches, classrooms) cost $10,000 per year. Second, bi-annual site visits planned include simple inspection, estimated $4.00 per linear foot stream every year. Third, invasive species removal estimated cost $15,000 per site occur every 10-years. Fourth, repair structural restoration features (e.g., rock, wood, earth work) assumed occur every 25 years. estimates resulted OMRRR costs ranging 1.2% 16.7% construction cost depending site alternative (Appendix B, Table B1), approximately line stream restoration projects (Abera McKay 2023).Average annual economic costs computed cost categories. Interest construction computed based construction costs site- alternative-specific construction durations. FY24 Federal discount rate (2.75%, USACE 2023) used annualize construction cost, interest construction, monitoring adaptive management expenses 50-year planning horizon. Cost data annualized using EngrEcon software package, although web application also exists conducting calculations. Table 3 provides example cost estimates Site-17F2M, Appendix B provides cost summary sites actions.Cost data annualized using EngrEcon software package, although web application also exists conducting calculations.","code":""},{"path":"annualizing-benefits-and-costs.html","id":"steps-for-annualization","chapter":"20 Annualizing benefits and costs","heading":"20.3.1 Steps for annualization:","text":"Read initial costs: Project_first, Monitoring, AdaptiveManCalculate present value OMRR costs using om_distribute function. function…Now present value costs one dataframe: Project_first, Monitoring, AdapMan ; OMRR costs previous stepCalculate Interest construction using based discount rate, duration construction, construction cost using interest_during_construction functionLast step: annualize costs using present_to_annual function using discount rate 50 year time horizonFinally, create table display subset results.Table 20.1: Table 1. Example monetary cost data Site-17F2M.","code":"\n#Populate these sections of code from code below\n\n# Set federal discont rate for water resources projects in FY24\ndiscount <- 0.0275\n\n# Read in initial costs\ncosts <- read_csv(\"data/utoy_cost.csv\")\ncosts_omrrr <- costs %>%\n  rowwise() %>%\n  mutate(General = om_distribute(discount, 50, 1, 10000 * ifelse(RipAreaFt2>0, 1, 0)),\n         InspectionTrash = om_distribute(discount, 50, 2, 4*ReachLengthFt),\n         Invasives = om_distribute(discount, 50, 10, 15000 * ifelse(RipAreaFt2>0, 1, 0)),\n         WoodRockEarth = om_distribute(discount, 50, 25, 0.1*ProjectFirst),\n         TotalOMRR = InspectionTrash + General + Invasives + WoodRockEarth)\ncosts_idc <- costs_omrrr %>%\n  rowwise() %>%\n  mutate(IDC = case_when(DurationMon==0~0, TRUE ~ interest_during_construction(discount, DurationMon, ProjectFirst)))\ncosts_ann <- costs_idc %>% \n  rowwise() %>%\n  mutate(ProjectFirstAnn = present_to_annual(discount, 50, ProjectFirst),\n         IDCAnn = present_to_annual(discount, 50, IDC),\n         MonitoringAnn = present_to_annual(discount, 50, Monitoring),\n         AdManAnn = present_to_annual(discount, 50, AdMan),\n         OMAnn = present_to_annual(discount, 50, TotalOMRR),\n         TotalAnn = ProjectFirstAnn + MonitoringAnn + AdManAnn + IDCAnn + OMAnn)\nTable1 <- cbind(costs_ann$ReachID, costs_ann$SiteAction, costs_ann$DurationMon,\n                 formatC(costs_ann$ProjectFirst, format=\"f\", digits=0, big.mark = \",\"),\n                 formatC(costs_ann$Monitoring, format=\"f\", digits=0, big.mark = \",\"),\n                 formatC(costs_ann$AdMan, format=\"f\", digits=0, big.mark = \",\"),\n                 formatC(costs_ann$OMAnn, format=\"f\", digits=0, big.mark = \",\"),\n                 formatC(costs_ann$TotalAnn, format=\"f\", digits=0, big.mark = \",\"))\nTable1 <- Table1[1:4,]\n\ncolnames(Table1) <- c(\"Site\", \"Alternative\", \"Construction Duration (mo)\", \n                       \"Construction Cost\", \"Monitoring Cost\", \"Adapative Management Cost\",\n                       \"OMRRR Annual Cost\", \"Total Annualized Cost\")\n\nknitr::kable(Table1, caption=\"Table 1. Example of monetary cost data for Site-17F2M.\", align='c') "},{"path":"spatial-data-manipulation.html","id":"spatial-data-manipulation","chapter":"21 Spatial Data Manipulation","heading":"21 Spatial Data Manipulation","text":"Use info :\nhttps://rspatial.org/index.html","code":""},{"path":"important-data-sources.html","id":"important-data-sources","chapter":"22 Important data sources","heading":"22 Important data sources","text":"Adapted rom Brian Breaker:","code":""},{"path":"important-data-sources.html","id":"usgs-gage-data-using-the-dataretrieval-package","chapter":"22 Important data sources","heading":"22.1 USGS gage data using the dataRetrieval package","text":"exercise uses USGS dataRetrieval package USGS explore\ndata availability retrieve data. USGS dataRetrieval package accesses NWIS web portal.\nDocumentation packages can found :\nhttps://github.com/USGS-R/dataRetrievalLet’s start seeing streamflow data available Arkansas (AR)? can use whatNWISsites function.\n, Parameter code 00060 refers daily flow cubic feet per second (cfs).can subset just active sites, just ones unit-value flow data (e.g., 15 min flow).Now sites look , can reduce . example, just want sites Buffalo River? require filtering using character strings. Hint: look ?str_detectNow can get flow data 5 sites Buffalo River.“uv” going retrieve 15min data Sys.Date set equal date script run.can also get data associated gages using siteInfo function, including data drainage area.Let’s look data, mean flow data last hour site create simple time-series plotNow wanted convert data hourly data saved end hour.Create new data frame can open look back forth see changing stepWe can also download daily data starting many years ago, including data starting water year 2020 5 sites Buffalo River.can plot data using ggplot.wanted write gages instead filtering data,\ncan reference site number directly function.","code":"\nlibrary(tidyverse)\nlibrary(dataRetrieval)\nwhatSites <- whatNWISsites(stateCd = \"AR\", parameterCd = \"00060\")## GET: https://waterservices.usgs.gov/nwis/site/?stateCd=AR&parameterCd=00060&format=mapper\nwhatSites <- whatNWISsites(stateCd = \"AR\", parameterCd = \"00060\", \n                           siteStatus = \"active\")## GET: https://waterservices.usgs.gov/nwis/site/?stateCd=AR&parameterCd=00060&siteStatus=active&format=mapper\nwhatSites <- whatNWISsites(stateCd = \"AR\", parameterCd = \"00060\", \n                           siteStatus = \"active\", hasDataTypeCd = \"dv\")## GET: https://waterservices.usgs.gov/nwis/site/?stateCd=AR&parameterCd=00060&siteStatus=active&hasDataTypeCd=dv&format=mapper\n# filter all of our sites by the \"Buffalo\" in station name\nwhatSites <- whatSites %>% \n  dplyr::filter(str_detect(station_nm, \"Buffalo\"))\n\n# what information is available for those sites? includes start and end dates\nwhatInfo <- whatNWISdata(siteNumber = whatSites$site_no)## GET: https://waterservices.usgs.gov/nwis/site/?seriesCatalogOutput=true&sites=07055646,07055660,07055680,07056000,07056700&format=rdb## WARNING: NWIS does not deliver\n## discrete water quality data newer than March 11, 2024\n## or updates to existing data. For additional details, see:\n## https://doi-usgs.github.io/dataRetrieval/articles/Status.html\n# we don't want to look at water quality data... so let's filter it out\nwhatInfo <-  dplyr::filter(whatInfo, !data_type_cd == \"qw\")\nflowDat <- readNWISuv(whatSites$site_no, startDate = Sys.Date(), parameterCd = \"00060\")## GET: https://waterservices.usgs.gov/nwis/iv/?site=07055646,07055660,07055680,07056000,07056700&format=waterml,1.1&ParameterCd=00060&startDT=2025-01-28\n# Rename unwieldy names; dataRetrieval has a function to do that.\nflowDat <- renameNWISColumns(flowDat)\nsiteInfo <- readNWISsite(whatSites$site_no)## GET: https://waterservices.usgs.gov/nwis/site/?siteOutput=Expanded&format=rdb&site=07055646,07055660,07055680,07056000,07056700\n# What if we just want site number and drainage area for the sites\nsiteInfo <-  dplyr::select(siteInfo, site_no, drain_area_va)\np <- ggplot(flowDat, aes(x = dateTime, y = Flow_Inst, color = site_no)) + \n  geom_line()\n\np\nflowDat2 <- flowDat %>% \n  mutate(dateTime = as.POSIXct(dateTime, format = \"%Y-%m-%d %H:%M:%S\", tz = \"UTC\")) %>%\n  mutate(date_hour = floor_date(dateTime, unit = \"hour\")) %>%\n  group_by(site_no, date_hour) %>%  \n  summarize(flow = mean(Flow_Inst)) %>% \n  ungroup()\n\n# is there a relationship between flow and drainage area\nggplot(data = flowDat, aes(x = dateTime, y = Flow_Inst, color = site_no)) + \n     geom_line()+\n     geom_line(data = flowDat2, aes(x = date_hour, y = flow , color = site_no),\n               linetype=\"dashed\")\nflowDatdaily <- readNWISdv(whatSites$site_no, startDate = \"2019-10-01\", parameterCd = \"00060\")\nflowDatdaily <- renameNWISColumns(flowDatdaily)\nlibrary(scales)## \n## Attaching package: 'scales'## The following object is masked from 'package:purrr':\n## \n##     discard## The following object is masked from 'package:readr':\n## \n##     col_factor\nggplot(data = flowDatdaily, aes(x = Date, y = Flow, color = site_no)) + \n     geom_line()+\n     scale_y_continuous(breaks = seq(0, 500000, 5000) )+ \n     scale_x_date(breaks=\"6 month\", labels=date_format(\"%Y-%m\"),expand = c(0,0) )\nflowDatdailyone <- readNWISdv(\"07055646\", startDate = \"2019-10-01\", parameterCd = \"00060\")## GET: https://waterservices.usgs.gov/nwis/dv/?site=07055646&format=waterml,1.1&ParameterCd=00060&StatCd=00003&startDT=2019-10-01\nflowDatdailytwo <- readNWISdv(c(\"07055646\", \"07055660\"), startDate = \"2019-10-01\", parameterCd = \"00060\")## GET: https://waterservices.usgs.gov/nwis/dv/?site=07055646,07055660&format=waterml,1.1&ParameterCd=00060&StatCd=00003&startDT=2019-10-01"},{"path":"important-data-sources.html","id":"national-hydrography-dataset-with-nhdplustools","chapter":"22 Important data sources","heading":"22.2 National Hydrography Dataset with nhdplusTools","text":"https://doi-usgs.github.io/nhdplusTools/","code":""},{"path":"important-data-sources.html","id":"nlcd","chapter":"22 Important data sources","heading":"22.3 NLCD","text":"","code":""},{"path":"important-data-sources.html","id":"precipitation-data-prism","chapter":"22 Important data sources","heading":"22.4 Precipitation data (PRISM)","text":"","code":""},{"path":"important-data-sources.html","id":"other-data-sources-commonly-used-in-usace","chapter":"22 Important data sources","heading":"22.5 Other data sources commonly used in USACE?","text":"","code":""}]
