<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>15 Random Forest | Using R for ecological modeling in USACE</title>
<meta name="author" content="Ed Stowe">
<meta name="generator" content="bookdown 0.42 with bs4_book()">
<meta property="og:title" content="15 Random Forest | Using R for ecological modeling in USACE">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="15 Random Forest | Using R for ecological modeling in USACE">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.8.0/transition.js"></script><script src="libs/bs3compat-0.8.0/tabs.js"></script><script src="libs/bs3compat-0.8.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<meta name="description" content="This module will teach you how to run a full machine learning workflow with a random forest model using the tidymodels package in R. Graphical output of a river network along with associated dams...">
<meta property="og:description" content="This module will teach you how to run a full machine learning workflow with a random forest model using the tidymodels package in R. Graphical output of a river network along with associated dams...">
<meta name="twitter:description" content="This module will teach you how to run a full machine learning workflow with a random forest model using the tidymodels package in R. Graphical output of a river network along with associated dams...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Using R for ecological modeling in USACE</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Course overview</a></li>
<li><a class="" href="required-set-up-for-the-course.html">Required set-up for the course</a></li>
<li class="book-part">Basic Training on R and RStudio</li>
<li><a class="" href="introduction-to-r-and-rstudio.html"><span class="header-section-number">1</span> Introduction to R and RStudio</a></li>
<li><a class="" href="data-visualization-with-ggplot2.html"><span class="header-section-number">2</span> Data Visualization with ggplot2</a></li>
<li><a class="" href="exploring-and-understanding-data.html"><span class="header-section-number">3</span> Exploring and understanding data</a></li>
<li><a class="" href="manipulating-tabular-data.html"><span class="header-section-number">4</span> Manipulating Tabular Data</a></li>
<li class="book-part">Ecological Modeling in R</li>
<li><a class="" href="conceptual-ecological-models.html"><span class="header-section-number">5</span> Conceptual Ecological Models</a></li>
<li class="book-part">Habitat Models</li>
<li><a class="" href="background-on-habitat-models-in-usace.html"><span class="header-section-number">6</span> Background on habitat models in USACE</a></li>
<li><a class="" href="habitat-suitability-index-models-with-ecorest.html"><span class="header-section-number">7</span> Habitat Suitability Index models with ecorest</a></li>
<li><a class="" href="ecorest-web-app.html"><span class="header-section-number">8</span> Ecorest Web App</a></li>
<li><a class="" href="sensitivity-and-uncertainty-analysis-for-habitat-suitability-index-hsi-models.html"><span class="header-section-number">9</span> Sensitivity and uncertainty analysis for habitat suitability index (HSI) models</a></li>
<li><a class="" href="spatial-habitat-models.html"><span class="header-section-number">10</span> Spatial Habitat Models</a></li>
<li class="book-part">Linear Models</li>
<li><a class="" href="linear-models.html"><span class="header-section-number">11</span> Linear Models</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">12</span> Generalized Linear Models</a></li>
<li><a class="" href="random-effects.html"><span class="header-section-number">13</span> Random Effects</a></li>
<li><a class="" href="generalized-additive-models.html"><span class="header-section-number">14</span> Generalized Additive Models</a></li>
<li class="book-part">Machine Learning</li>
<li><a class="active" href="random-forest.html"><span class="header-section-number">15</span> Random Forest</a></li>
<li><a class="" href="boosted-regression-trees.html"><span class="header-section-number">16</span> Boosted Regression Trees</a></li>
<li class="book-part">Other Modeling Approaches</li>
<li><a class="" href="population-modeling.html"><span class="header-section-number">17</span> Population Modeling</a></li>
<li><a class="" href="network-models-and-connectivity.html"><span class="header-section-number">18</span> Network Models and Connectivity</a></li>
<li><a class="" href="agent-based-models.html"><span class="header-section-number">19</span> Agent-based Models</a></li>
<li class="book-part">Models and decision-making</li>
<li><a class="" href="decision-support.html"><span class="header-section-number">20</span> Decision Support</a></li>
<li><a class="" href="annualizing-benefits-and-costs-with-ecorest-and-engrecon.html"><span class="header-section-number">21</span> Annualizing benefits and costs with ecorest and EngrEcon</a></li>
<li><a class="" href="ceica-chapter.html"><span class="header-section-number">22</span> Cost-Effectiveness and Incremental Cost Analysis (CEICA) with ecorest</a></li>
<li class="book-part">Models Integration</li>
<li><a class="" href="model-integration.html"><span class="header-section-number">23</span> Model Integration</a></li>
<li class="book-part">Other R applications</li>
<li><a class="" href="r-for-gis.html"><span class="header-section-number">24</span> R for GIS</a></li>
<li class="book-part">Environmental data sources</li>
<li><a class="" href="using-r-for-data-access.html"><span class="header-section-number">25</span> Using R for data access</a></li>
<li><a class="" href="usgs-gage-data-using-the-dataretrieval-package.html"><span class="header-section-number">26</span> USGS gage data using the dataRetrieval package</a></li>
<li><a class="" href="national-hydrography-dataset.html"><span class="header-section-number">27</span> National Hydrography Dataset</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="random-forest" class="section level1" number="15">
<h1>
<span class="header-section-number">15</span> Random Forest<a class="anchor" aria-label="anchor" href="#random-forest"><i class="fas fa-link"></i></a>
</h1>
<p><strong>This module will teach you how to run a full machine learning workflow with a random forest model using the tidymodels package in <code>R</code>.</strong></p>
<div class="float">
<img src="images/blgl_pdp.png" style="width:100.0%" alt="Graphical output of a river network along with associated dams created using nhdplusTools along with data from the National Inventory of Dams."><div class="figcaption"><em>Graphical output of a river network along with associated dams created using <strong><code>nhdplusTools</code></strong> along with data from the National Inventory of Dams.</em></div>
</div>
<p><em>Authors: Ed Stowe (writing, editing)</em><br><em>Last update: 2025-10-03</em><br><em>Acknowledgements: Case study includes code that was adapted from demonstration analyses by Julia Silge on <a href="https://juliasilge.com/blog/sf-trees-random-tuning/">random forest</a> and <a href="https://juliasilge.com/blog/mario-kart/">partial dependence plots</a>, used under <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a></em></p>
<div id="learning-objectives-8" class="section level2" number="15.1">
<h2>
<span class="header-section-number">15.1</span> Learning objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-8"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Understand how random forest models works and when they are useful</li>
<li>Carry out a full machine learning workflow</li>
<li>Learn how to tune and assess a random forest model and determine which variables are important</li>
</ul>
</div>
<div id="background-1" class="section level2" number="15.2">
<h2>
<span class="header-section-number">15.2</span> Background<a class="anchor" aria-label="anchor" href="#background-1"><i class="fas fa-link"></i></a>
</h2>
<div id="what-is-machine-learning" class="section level3" number="15.2.1">
<h3>
<span class="header-section-number">15.2.1</span> What is machine learning?<a class="anchor" aria-label="anchor" href="#what-is-machine-learning"><i class="fas fa-link"></i></a>
</h3>
<p>Machine learning constitutes using algorithms that can learn to recognize patterns in data and then make predictions in new scenarios.</p>
</div>
<div id="when-is-it-most-useful" class="section level3" number="15.2.2">
<h3>
<span class="header-section-number">15.2.2</span> When is it most useful?<a class="anchor" aria-label="anchor" href="#when-is-it-most-useful"><i class="fas fa-link"></i></a>
</h3>
<p>In general, ML is most useful when prediction are more important than explanation; and when there is an adequate amount of data. ML models work better with more data, typically when there are at least a few hundred observations.</p>
</div>
<div id="can-i-do-machine-learning" class="section level3" number="15.2.3">
<h3>
<span class="header-section-number">15.2.3</span> Can I do machine learning<a class="anchor" aria-label="anchor" href="#can-i-do-machine-learning"><i class="fas fa-link"></i></a>
</h3>
<p>Yes. Machine learning (ML) has a reputation for complexity and technical difficulty. But many machine learning algorithms are relatively simple, have been in use for decades, and are now fairly accessible via R packages like the tidymodels</p>
</div>
<div id="what-programs-can-i-use-for-ml" class="section level3" number="15.2.4">
<h3>
<span class="header-section-number">15.2.4</span> What programs can I use for ML?<a class="anchor" aria-label="anchor" href="#what-programs-can-i-use-for-ml"><i class="fas fa-link"></i></a>
</h3>
<p>There are lots of tools/programs for running ML algorithms, but one very accessible way is to use the tidymodels packages in R, which provides an integrated framework for using dozens of different ML algorithms. Different algorithms might make sense for different applications. Here we use random forest, an algorithm that’s been popular for decades because of its flexibility, performance, relative ease, and suitability for tabular data (i.e., spreadsheets).</p>
</div>
<div id="how-does-random-forest-work" class="section level3" number="15.2.5">
<h3>
<span class="header-section-number">15.2.5</span> How does random forest Work<a class="anchor" aria-label="anchor" href="#how-does-random-forest-work"><i class="fas fa-link"></i></a>
</h3>
<p>Random forest is an extension of a technique called decision trees. Decision trees, like other supervised machine learning algorithms, are designed to predict outcomes based on input data. There are two main types of outcomes that decision trees might predict:
- Classification: predicting categorical outcomes (e.g., present/absent; male/female, etc.)
- Regression: predicting numeric outcomes (e.g., abundance of fish; number of species, etc.)</p>
<p>Input data is used to identify break points, called decision nodes, in the data that help predict what the outcome might be. For example, if we were to predict whether a given passenger survived the sinking of the Titanic, the first decision node (i.e., the most informative) would be whether the person was male or female. Other input variables, like the age of the passenger, would likely make up other important nodes in the tree, and the final prediction (i.e., did the person survive or note?) is denoted by the leaf node.</p>
<p>Decision trees are versatile and interpretable, but they often learn the data that they are trained on too well, which is called being “overfit.” Overfitted models tend to do poorly when used in prediction, because they are not general enough.</p>
<p>Random forest (and some similar algorithms) help overcome the problem of overfitting by leveraging the predictions of many distinct trees. It does this by:</p>
<ol style="list-style-type: decimal">
<li>Creating many different decision trees, each using a random subset of the data (called bagging).</li>
<li>Building each tree using only a few randomly chosen predictor variables.</li>
<li>Generating independent predictions from each tree.</li>
<li>Combining the predictions of the different trees by selecting the prediction that the most trees agree on.</li>
</ol>
<p>Using random data and input variables for each tree has been shown to increase the overall accuracy and generalizability of these models compared to single decision trees.</p>
</div>
</div>
<div id="case-study" class="section level2" number="15.3">
<h2>
<span class="header-section-number">15.3</span> Case study<a class="anchor" aria-label="anchor" href="#case-study"><i class="fas fa-link"></i></a>
</h2>
<p>Here we present a case study using machine learning to predict whether or not bluegill will be present at different sites in the Upper Mississippi River based on habitat covariates. Bluegill are often the focus of restoration efforts there, so better understanding what controls bluegill presence can help determine what features restoration should focus on. This analysis includes steps that are fundamental to all machine learning workflows and also relevant in many other models forms as well, which include:</p>
<ul>
<li>
<em>Splitting the data</em>: partitioning data so that models can be trained and then tested on independent data</li>
<li>
<em>Tuning and training models</em>: using the training processing to examine model fit and determine which model specifications (i.e., hyperparameters) yield the best predictions</li>
<li><em>Assessing model performance</em></li>
<li>
<em>Predicting independent data</em>: compare model predictions to test dataset to see if it performs well</li>
</ul>
<div id="add-packages" class="section level3" number="15.3.1">
<h3>
<span class="header-section-number">15.3.1</span> Add packages<a class="anchor" aria-label="anchor" href="#add-packages"><i class="fas fa-link"></i></a>
</h3>
<p>This case study will use the <code>tidymodels</code> package. We will also load the following packages:
- <code>tidyverse</code> for plotting and data-handling
- <code>doParallel</code> for tuning models in parallel
- <code>vip</code> for calculating variable importance
- <code>DALEXtra</code> for making partial dependence plots</p>
<p>These packages should be installed if you have not used them before (e.g., <code>install.packages("vip")</code>)</p>
<div class="sourceCode" id="cb360"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/RevolutionAnalytics/doparallel">doParallel</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/koalaverse/vip/">vip</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ModelOriented.github.io/DALEXtra/">DALEXtra</a></span><span class="op">)</span></span></code></pre></div>
<p>First, we can import the bluegill occupancy dataset, and look at the data structure
### Import dataset</p>
<div class="sourceCode" id="cb361"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">blgl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/bluegill.csv"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Rows: 1422 Columns: 11
## ── Column specification ──────────────────────────────────────
## Delimiter: ","
## chr  (1): pool
## dbl (10): occ, utm_e, utm_n, period, secchi, temp, depth, cond, current, do
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb363"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">blgl</span><span class="op">)</span></span></code></pre></div>
<pre><code>## spc_tbl_ [1,422 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ occ    : num [1:1422] 0 1 1 1 0 1 1 0 0 0 ...
##  $ utm_e  : num [1:1422] 734608 734108 734608 735008 734108 ...
##  $ utm_n  : num [1:1422] 4648501 4648551 4648501 4650751 4648601 ...
##  $ pool   : chr [1:1422] "13" "13" "13" "13" ...
##  $ period : num [1:1422] 2 3 3 2 2 3 3 1 1 1 ...
##  $ secchi : num [1:1422] 35 60 48 46 NA 29 42 42 32 NA ...
##  $ temp   : num [1:1422] 22.7 20.7 16.6 23.8 NA 18.9 15.8 27.8 25.4 NA ...
##  $ depth  : num [1:1422] 0.5 0.6 0.9 1.2 NA 0.9 1 0.8 0.8 NA ...
##  $ cond   : num [1:1422] 404 464 321 376 NA 459 312 367 492 NA ...
##  $ current: num [1:1422] 0 0 0 0.08 NA 0.06 0.06 0 0 NA ...
##  $ do     : num [1:1422] 11.8 4.4 10.5 8 NA 7.4 9.9 8.2 5.3 NA ...
##  - attr(*, "spec")=
##   .. cols(
##   ..   occ = col_double(),
##   ..   utm_e = col_double(),
##   ..   utm_n = col_double(),
##   ..   pool = col_character(),
##   ..   period = col_double(),
##   ..   secchi = col_double(),
##   ..   temp = col_double(),
##   ..   depth = col_double(),
##   ..   cond = col_double(),
##   ..   current = col_double(),
##   ..   do = col_double()
##   .. )
##  - attr(*, "problems")=&lt;externalptr&gt;</code></pre>
<p>We see that all but one of these variables are numeric. However, for our classification algorithm, we need to convert the presence/absence column (<code>occ</code> for occupancy) to a factor. We also have two other categorical variables that should be factors: pool for the number of the navigation pool, and period, for the season (with 2, 3, 4 being approximately spring, summer, and fall, respectively).</p>
<div class="sourceCode" id="cb365"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">blgl</span> <span class="op">&lt;-</span> <span class="va">blgl</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html">across</a></span><span class="op">(</span>.cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">occ</span>, <span class="va">pool</span>, <span class="va">period</span><span class="op">)</span>, <span class="va">as.factor</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We may also want to explore the data a bit. Here we look to see if there are any patterns of bluegill occupancy across space, and based on depth.</p>
<div class="sourceCode" id="cb366"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">blgl</span>,</span>
<span>       <span class="va">depth</span> <span class="op">&lt;</span> <span class="fl">4</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">utm_e</span><span class="op">/</span><span class="fl">1000</span>, <span class="va">utm_n</span><span class="op">/</span><span class="fl">1000</span>, color <span class="op">=</span> <span class="va">depth</span>, shape <span class="op">=</span> <span class="va">occ</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">pool</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">scale_color_viridis_c</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"UTM E (thousands of m)"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"UTM N (thousands of m)"</span>,</span>
<span>       shape <span class="op">=</span> <span class="st">"Presence"</span>,</span>
<span>       color <span class="op">=</span> <span class="st">"Depth (m)"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="usace_R_training_files/figure-html/unnamed-chunk-67-1.png" width="600" height="70%"></div>
<p>Clearly these data are complex, and modeling should help us make sense of it.</p>
</div>
<div id="data-partitioning" class="section level3" number="15.3.2">
<h3>
<span class="header-section-number">15.3.2</span> Data partitioning<a class="anchor" aria-label="anchor" href="#data-partitioning"><i class="fas fa-link"></i></a>
</h3>
<p>Splitting the data is very important so that we have some independent data on which to judge our models performance. Here we split 75% of the data into the dataset that will be used to train the model, and the remainder into the dataset for testing/assessing our model. 75% is the tidymodels default splitting proportion.</p>
<div class="sourceCode" id="cb367"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">blgl_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">blgl</span>, strata <span class="op">=</span> <span class="va">occ</span>, prop <span class="op">=</span> <span class="fl">.75</span><span class="op">)</span></span>
<span><span class="va">blgl_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">blgl_split</span><span class="op">)</span></span>
<span><span class="va">blgl_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">blgl_split</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="pre-processing-with-recipes" class="section level3" number="15.3.3">
<h3>
<span class="header-section-number">15.3.3</span> Pre-processing with recipes<a class="anchor" aria-label="anchor" href="#pre-processing-with-recipes"><i class="fas fa-link"></i></a>
</h3>
<p>Build a recipe for data preprocessing.</p>
<p>First, we must tell the recipe() what our model is going to be (using a formula here) and what our training data is. The recipe is where we can do lots of helpful data manipulations, such as normalizing the data (step_normalize()), replacing categorical variables with dummy variables (step_dummy), adding interactions (step_interact()), and numerous other options. Random forest models needed fewer data transformations than many algorithms, so we’ll just to one powerful transformation: step_impute_bag(). This uses a machine learning algorithm to impute missing variables, since we can’t have any missing predictor data to run this or many other machine learning algorithm. Another option would be to remove any rows with missing data (using step_naomit()), but that would remove a lot of data.</p>
<div class="sourceCode" id="cb368"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">blgl_rec</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">occ</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">blgl_train</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_impute_bag</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>ALthough not strictly necessary, to see what the data look like after applying transformations, we can use the functions <code>prep</code> and then <code>juice</code>. The <code>juiced</code> dataframe now shows us what our data will look like when it’s fed into the ML algorithm.</p>
<div class="sourceCode" id="cb369"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">blgl_prep</span> <span class="op">&lt;-</span> <span class="fu">prep</span><span class="op">(</span><span class="va">blgl_rec</span><span class="op">)</span></span>
<span><span class="va">juiced</span> <span class="op">&lt;-</span> <span class="fu">juice</span><span class="op">(</span><span class="va">blgl_prep</span><span class="op">)</span>  </span></code></pre></div>
</div>
<div id="model-specifications-with-parsnip" class="section level3" number="15.3.4">
<h3>
<span class="header-section-number">15.3.4</span> Model specifications with parsnip<a class="anchor" aria-label="anchor" href="#model-specifications-with-parsnip"><i class="fas fa-link"></i></a>
</h3>
<p>We will specify our random forest model. This is where we tell the model whether to try any different combinations of the hyperparameters (i.e., whether to tune the model). In this case, we’re going to set the number of trees in our model to be 1,000, but we will tune 2 other hyperparameters. The <code>mtry</code> parameter controls how many variables we’ll include in each model, and the <code>min_n</code> hyperparameter controls tree complexity: it indicates the minimum number of data points needed in a node for that node to be split, so higher values of <code>min_n</code> will force trees to be less complex. Tuning both of these parameters will help us find a more predictive model. For the model specification, we also indicate that we want to run our random forest using the version of the algorithm as implemented by the <code>ranger</code> package, and we want to do classification as opposed to regression.</p>
<div class="sourceCode" id="cb370"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tune_spec</span> <span class="op">&lt;-</span> </span>
<span>    <span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html">rand_forest</a></span><span class="op">(</span>mtry <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>, min_n <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_engine.html">set_engine</a></span><span class="op">(</span><span class="st">"ranger"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>    <span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_args.html">set_mode</a></span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="workflow" class="section level3" number="15.3.5">
<h3>
<span class="header-section-number">15.3.5</span> Workflow<a class="anchor" aria-label="anchor" href="#workflow"><i class="fas fa-link"></i></a>
</h3>
<p>Next we set up our workflow. This is simply where we indicate what recipe and model we will use.</p>
<div class="sourceCode" id="cb371"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tune_wf</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">blgl_rec</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">tune_spec</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="tune-hyperparameters" class="section level3" number="15.3.6">
<h3>
<span class="header-section-number">15.3.6</span> Tune hyperparameters<a class="anchor" aria-label="anchor" href="#tune-hyperparameters"><i class="fas fa-link"></i></a>
</h3>
<p>Now we’re ready to tune the hyperparameters. We need to create a set of cross-validation resamples to use for tuning. This means we’ll divide our training data into 10 slices, and sequentially fit models with different hyperparameters using 9 of the slices, and testing it on the 10th slice. This is how we’ll figure out the best hyperparameters.</p>
<div class="sourceCode" id="cb372"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">234</span><span class="op">)</span></span>
<span><span class="va">blgl_folds</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">blgl_train</span>, v <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>We will use the <code>tune_grid</code> function to tune our model across a grid of hyperparameters (using <code>grid = 20</code> will automatically pick 20 grid points automatically, but these can also be chosen by the user).</p>
<p>We will use parallel processing to make this go faster, but note that this could take about 1-2 minutes, depending on your computer.</p>
<div class="sourceCode" id="cb373"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">doParallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/doParallel/man/registerDoParallel.html">registerDoParallel</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">345</span><span class="op">)</span></span>
<span><span class="va">tune_res</span> <span class="op">&lt;-</span> <span class="fu">tune_grid</span><span class="op">(</span></span>
<span>  <span class="va">tune_wf</span>,</span>
<span>  resamples <span class="op">=</span> <span class="va">blgl_folds</span>,</span>
<span>  grid <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">tune_res</span></span></code></pre></div>
<pre><code>## # Tuning results
## # 10-fold cross-validation 
## # A tibble: 10 × 4
##    splits            id     .metrics          .notes          
##    &lt;list&gt;            &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [959/107]&gt; Fold01 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  2 &lt;split [959/107]&gt; Fold02 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  3 &lt;split [959/107]&gt; Fold03 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  4 &lt;split [959/107]&gt; Fold04 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  5 &lt;split [959/107]&gt; Fold05 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  6 &lt;split [959/107]&gt; Fold06 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  7 &lt;split [960/106]&gt; Fold07 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  8 &lt;split [960/106]&gt; Fold08 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
##  9 &lt;split [960/106]&gt; Fold09 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;
## 10 &lt;split [960/106]&gt; Fold10 &lt;tibble [60 × 6]&gt; &lt;tibble [0 × 3]&gt;</code></pre>
<p>We can plot the accuracy of our models (using area under the curve, or “AUC”) to see which values of our hyperparameters are best. AUC is a score that indicates the balance between the sensitivity and specificity of a model, and thus is a good measure of model generalizability.</p>
<p>It appears that min_n values below 30 and mtry values between 4 and 6 are best.</p>
<div class="sourceCode" id="cb375"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tune_res</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">.metric</span> <span class="op">==</span> <span class="st">"roc_auc"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">mean</span>, <span class="va">min_n</span>, <span class="va">mtry</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span><span class="va">min_n</span><span class="op">:</span><span class="va">mtry</span>,</span>
<span>    values_to <span class="op">=</span> <span class="st">"value"</span>,</span>
<span>    names_to <span class="op">=</span> <span class="st">"parameter"</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">value</span>, <span class="va">mean</span>, color <span class="op">=</span> <span class="va">parameter</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>show.legend <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">parameter</span>, scales <span class="op">=</span> <span class="st">"free_x"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="st">"AUC"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="usace_R_training_files/figure-html/unnamed-chunk-74-1.png" width="600" height="70%"></div>
<p>This grid did not involve every combination of min_n and mtry but we can get an idea of what is going on. If we wanted we could test a narrower and more specific range of hyperparameters using the grid_regular() function.</p>
</div>
<div id="choosing-the-best-model" class="section level3" number="15.3.7">
<h3>
<span class="header-section-number">15.3.7</span> Choosing the best model<a class="anchor" aria-label="anchor" href="#choosing-the-best-model"><i class="fas fa-link"></i></a>
</h3>
<p>Now that we’ve tuned models with several different hyperparameters, we can select the best model with the select_best(), and then update our original model specification to create our final model specification.</p>
<div class="sourceCode" id="cb376"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">best_auc</span> <span class="op">&lt;-</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_res</span>, metric <span class="op">=</span> <span class="st">"roc_auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">final_rf</span> <span class="op">&lt;-</span> <span class="fu">finalize_model</span><span class="op">(</span></span>
<span>  <span class="va">tune_spec</span>,</span>
<span>  <span class="va">best_auc</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">final_rf</span></span></code></pre></div>
<pre><code>## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = 6
##   trees = 1000
##   min_n = 8
## 
## Computational engine: ranger</code></pre>
<p>This shows that our final model has an mtry value of 6 and a min_n value of 8.</p>
<p>To ultimately see how our good our model is, we want to evaluate predictions from the best model against the test dataset.</p>
<p>To do this, we make a final workflow with our original recipe and our best model <code>final_rf</code>. We can fit it one last time with the function last_fit(), which fits our best model on the entire training set and evaluates on the testing set, when provided with our initial data split.</p>
<div class="sourceCode" id="cb378"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">final_wf</span> <span class="op">&lt;-</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">blgl_rec</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">add_model</span><span class="op">(</span><span class="va">final_rf</span><span class="op">)</span></span>
<span></span>
<span><span class="va">final_res</span> <span class="op">&lt;-</span> <span class="va">final_wf</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">last_fit</span><span class="op">(</span><span class="va">blgl_split</span><span class="op">)</span></span>
<span></span>
<span><span class="va">final_res</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 3 × 4
##   .metric     .estimator .estimate .config             
##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy    binary        0.879  Preprocessor1_Model1
## 2 roc_auc     binary        0.916  Preprocessor1_Model1
## 3 brier_class binary        0.0925 Preprocessor1_Model1</code></pre>
<p>If we collect the metrics from our final model fit we see it has an ROC &gt; .91, where values over .9 are generally considered to be very good.</p>
<p>This suggests that we have a very predictive model for presence of bluegill and one that is not overfit.</p>
<p>Let’s bind our testing results back to the original test set, and make one more map. Where in our pool are there more or less incorrectly predicted trees?</p>
<div class="sourceCode" id="cb380"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">final_res</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">collect_predictions</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>correct <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span></span>
<span>    <span class="va">occ</span> <span class="op">==</span> <span class="va">.pred_class</span> <span class="op">~</span> <span class="st">"Correct"</span>,</span>
<span>    <span class="cn">TRUE</span> <span class="op">~</span> <span class="st">"Incorrect"</span></span>
<span>  <span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_cols.html">bind_cols</a></span><span class="op">(</span><span class="va">blgl_test</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">utm_e</span>, <span class="va">utm_n</span>, color <span class="op">=</span> <span class="va">correct</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">0.5</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>color <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gray80"</span>, <span class="st">"darkred"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">pool</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_void</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="usace_R_training_files/figure-html/unnamed-chunk-77-1.png" width="600" height="70%"></div>
</div>
<div id="examine-variable-importance-and-partial-dependence" class="section level3" number="15.3.8">
<h3>
<span class="header-section-number">15.3.8</span> Examine variable importance and partial dependence<a class="anchor" aria-label="anchor" href="#examine-variable-importance-and-partial-dependence"><i class="fas fa-link"></i></a>
</h3>
<p>We still don’t know what environmental factors matter to bluegill, but there are a couple of ways we can assess this.</p>
<p>First, we can see what variables are most important, using variable importance factors using the vip package.</p>
<div class="sourceCode" id="cb381"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">final_rf</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_engine.html">set_engine</a></span><span class="op">(</span><span class="st">"ranger"</span>, importance <span class="op">=</span> <span class="st">"permutation"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">occ</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="fu">juice</span><span class="op">(</span><span class="va">blgl_prep</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://koalaverse.github.io/vip/reference/vip.html">vip</a></span><span class="op">(</span>geom <span class="op">=</span> <span class="st">"point"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="usace_R_training_files/figure-html/unnamed-chunk-78-1.png" width="600" height="600"></div>
<p>This indicates that depth and current are far and away the most important factors determining the presence of bluegill compared to other factors.</p>
<p>We can also look at how these variables influence the probability of occurrence of bluegill using partial dependnece plots, implemeneted here with the DALEXtra package.</p>
<p>To make these plots, we first extract the a fitted workflow from the final model fit object.</p>
<p>Then we create an explainer object using the explain_tidymodels function. We need to provide this function with the final workflow, the data used in the model, other than the response variable `occ’ and the response variable, as an integer.</p>
<div class="sourceCode" id="cb382"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">final_fitted</span> <span class="op">&lt;-</span> <span class="va">final_res</span><span class="op">$</span><span class="va">.workflow</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">blgl_explainer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ModelOriented.github.io/DALEXtra/reference/explain_tidymodels.html">explain_tidymodels</a></span><span class="op">(</span></span>
<span>  <span class="va">final_fitted</span>,</span>
<span>  data <span class="op">=</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">blgl_train</span>, <span class="op">-</span><span class="va">occ</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">blgl_train</span><span class="op">$</span><span class="va">occ</span><span class="op">)</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Once we have the explainer object we can calculate the dependence of occupancy on depth. Here we’re including <code>pool</code> as a grouping variable to see if the effect of depth varies among pool.</p>
<div class="sourceCode" id="cb383"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdp_depth</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://modeloriented.github.io/DALEX/reference/model_profile.html">model_profile</a></span><span class="op">(</span></span>
<span>  <span class="va">blgl_explainer</span>,</span>
<span>  variables <span class="op">=</span> <span class="st">"depth"</span>,</span>
<span>  N <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  groups <span class="op">=</span> <span class="st">"pool"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now we can plot the partial dependence. We could simply run <code>plot(pdp_depth)</code> but we can also plot it manually to have more control over the plot. To do this we can extract the relevant portion of the pdp_depth object, and then plot with ggplot. Note that we filter this dataset to depths &lt; 5m, as there are only a couple of points in the dataset greater than this depth.</p>
<div class="sourceCode" id="cb384"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdp_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">pdp_depth</span><span class="op">$</span><span class="va">agr_profiles</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">`_x_`</span> <span class="op">&lt;</span> <span class="fl">5</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>`_label_` <span class="op">=</span> <span class="fu"><a href="https://stringr.tidyverse.org/reference/str_remove.html">str_remove</a></span><span class="op">(</span><span class="va">`_label_`</span>, <span class="st">"workflow_"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">pdp_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">`_x_`</span>, <span class="va">`_yhat_`</span>, color <span class="op">=</span> <span class="va">`_label_`</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>lwd <span class="op">=</span> <span class="fl">1.2</span>, alpha <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Depth"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Predicted occurrence probability"</span>,</span>
<span>    color <span class="op">=</span> <span class="st">"Period"</span>,</span>
<span>    title <span class="op">=</span> <span class="st">"Partial dependence plot for Bluegill occupancy"</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="usace_R_training_files/figure-html/unnamed-chunk-81-1.png" width="600" height="70%"></div>
<p>We can see that in general, increases in depths are associated with increased probability of bluegill presence, which holds across pools, although the pools appear to have different overall probabilities of bluegill occurrence. There is also a dip in probability at depths slightly below 1 m, but further investigation would be needed to see if this is biologically meaningful.</p>
</div>
</div>
<div id="summary-5" class="section level2" number="15.4">
<h2>
<span class="header-section-number">15.4</span> Summary<a class="anchor" aria-label="anchor" href="#summary-5"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Machine learning models can excel at prediction if there is adequate data, suggesting it has great potential value for USACE applications</li>
<li>The <code>tidymodels</code> package provides a complete and comprehensive framework for utilizing numerous machine learning algorithms and carrying out full analyses</li>
<li>Random forest is a powerful, accessible algorithm that can make highly accurate predictions based on tabular data</li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="generalized-additive-models.html"><span class="header-section-number">14</span> Generalized Additive Models</a></div>
<div class="next"><a href="boosted-regression-trees.html"><span class="header-section-number">16</span> Boosted Regression Trees</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#random-forest"><span class="header-section-number">15</span> Random Forest</a></li>
<li><a class="nav-link" href="#learning-objectives-8"><span class="header-section-number">15.1</span> Learning objectives</a></li>
<li>
<a class="nav-link" href="#background-1"><span class="header-section-number">15.2</span> Background</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#what-is-machine-learning"><span class="header-section-number">15.2.1</span> What is machine learning?</a></li>
<li><a class="nav-link" href="#when-is-it-most-useful"><span class="header-section-number">15.2.2</span> When is it most useful?</a></li>
<li><a class="nav-link" href="#can-i-do-machine-learning"><span class="header-section-number">15.2.3</span> Can I do machine learning</a></li>
<li><a class="nav-link" href="#what-programs-can-i-use-for-ml"><span class="header-section-number">15.2.4</span> What programs can I use for ML?</a></li>
<li><a class="nav-link" href="#how-does-random-forest-work"><span class="header-section-number">15.2.5</span> How does random forest Work</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#case-study"><span class="header-section-number">15.3</span> Case study</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#add-packages"><span class="header-section-number">15.3.1</span> Add packages</a></li>
<li><a class="nav-link" href="#data-partitioning"><span class="header-section-number">15.3.2</span> Data partitioning</a></li>
<li><a class="nav-link" href="#pre-processing-with-recipes"><span class="header-section-number">15.3.3</span> Pre-processing with recipes</a></li>
<li><a class="nav-link" href="#model-specifications-with-parsnip"><span class="header-section-number">15.3.4</span> Model specifications with parsnip</a></li>
<li><a class="nav-link" href="#workflow"><span class="header-section-number">15.3.5</span> Workflow</a></li>
<li><a class="nav-link" href="#tune-hyperparameters"><span class="header-section-number">15.3.6</span> Tune hyperparameters</a></li>
<li><a class="nav-link" href="#choosing-the-best-model"><span class="header-section-number">15.3.7</span> Choosing the best model</a></li>
<li><a class="nav-link" href="#examine-variable-importance-and-partial-dependence"><span class="header-section-number">15.3.8</span> Examine variable importance and partial dependence</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-5"><span class="header-section-number">15.4</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Using R for ecological modeling in USACE</strong>" was written by Ed Stowe. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
